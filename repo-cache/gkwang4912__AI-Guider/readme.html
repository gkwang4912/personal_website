<h1>AI-Guider (Code Alchemist)</h1>
<h2>1. 專案總覽 (Project Overview)</h2>
<p><strong>AI-Guider</strong> 是一個整合即時語音識別 (STT)、大型語言模型 (LLM) 與語音合成 (TTS) 的全端 AI 互動應用程式。
本專案旨在提供一個低延遲、具備豐富視覺效果（駭客任務風格）的語音對話系統，讓使用者能以自然的口語與 AI 導覽員進行互動。</p>
<ul>
<li><strong>解決問題</strong>：傳統文字聊天介面缺乏互動感，且即時語音對話常受限於延遲與機械音。本專案透過串流技術與高品質 TTS 解決此問題。</li>
<li><strong>目標用戶</strong>：需要展示 AI 語音互動能力的開發者、展場導覽系統、或對語音助理有興趣的技術人員。</li>
<li><strong>類型</strong>：Web Application (Client-Server 架構)。</li>
</ul>
<h2>2. 專案架構總覽 (Architecture Overview)</h2>
<p>本系統採用前後端分離架構，但由後端統一提供靜態檔案服務。</p>
<ul>
<li><strong>前端 (Frontend)</strong>：<ul>
<li>負責介面呈現、動畫 (Canvas) 與使用者輸入。</li>
<li>使用瀏覽器原生的 <strong>Web Speech API</strong> 進行語音識別 (STT)，將使用者語音轉為文字。</li>
<li>透過 API 發送文字給後端，並接收回傳的音訊串流進行播放。</li>
</ul>
</li>
<li><strong>後端 (Backend)</strong>：<ul>
<li>基於 <strong>Flask</strong> 框架。</li>
<li><strong>對話引擎</strong>：整合 <strong>Google Gemini</strong> 模型，負責生成自然語言回應。</li>
<li><strong>語音合成</strong>：整合 <strong>XTTS v2</strong> 模型，支援串流 (Streaming) 輸出，大幅降低首字延遲 (Time-to-First-Byte)。</li>
<li>包含 API Key 管理機制，確保高併發時的穩定性。</li>
</ul>
</li>
</ul>
<p><strong>資料流</strong>：
1.  [前端] 麥克風收音 -&gt; Web Speech API -&gt; 文字
2.  [前端] POST <code>/api/chat/stream</code> (帶文字) -&gt; [後端]
3.  [後端] Gemini 生成回應文字 -&gt; XTTS 轉換音訊 (Streaming) -&gt; [前端]
4.  [前端] 接收音訊 Chunk -&gt; 即時播放</p>
<h2>3. 資料夾結構說明 (Folder Structure)</h2>
<pre><code class="language-text">.
├── backend/                  # 後端核心程式碼
│   ├── __pycache__/         # Python 編譯快取
│   ├── outputs/             # (自動產生) 存放生成的 .wav 音訊檔
│   ├── api_keys.json        # Google Gemini API Keys 設定檔
│   ├── config.json          # AI 模型參數與 System Prompt 設定
│   ├── gemini_chat.py       # Gemini 模型串接與 API Key 輪詢邏輯
│   ├── Morgan Freeman.wav   # XTTS 用於聲音克隆的參考樣本
│   ├── requirements.txt     # Python 相依套件清單
│   ├── server.py            # Flask 伺服器入口點 (Entry Point)
│   ├── xtts_v2.py           # XTTS v2 模型封裝與串流邏輯
│   └── 指令.txt              # 備忘指令 (如 ngrok)
└── frontend/                 # 前端靜態資源
    ├── app.js               # 前端主要邏輯 (錄音、動畫、API 呼叫)
    ├── index.html           # 主頁面結構
    ├── sora_loop.mp4        # 待機或處理中播放的背景影片
    └── styles.css           # 樣式表 (Matrix 風格設計)
</code></pre>
<h2>4. 核心模組與重要檔案說明 (Key Modules &amp; Files)</h2>
<h3>Backend</h3>
<ul>
<li><strong><code>server.py</code></strong>:<ul>
<li>專案入口。啟動 Flask Server，設定 CORS。</li>
<li>提供 <code>/api/chat/stream</code> 等核心端點。</li>
<li>會在啟動時預先載入 XTTS 模型與計算 Speaker Embedding。</li>
<li>同時負責 serve <code>frontend/</code> 下的靜態檔案 (為了簡化部署)。</li>
</ul>
</li>
<li><strong><code>xtts_v2.py</code></strong>:<ul>
<li>封裝 <code>coqui-tts</code> 的 <code>Xtts</code> 模型。</li>
<li><code>XTTSStreamingTTS</code> 類別：實作了 <code>tts_stream</code> generator，能產生 byte chunks 供 Flask 串流回傳。</li>
<li><strong>重要</strong>：針對 Windows 環境已強制關閉 DeepSpeed (<code>use_deepspeed=False</code>) 以避免相容性問題。</li>
</ul>
</li>
<li><strong><code>gemini_chat.py</code></strong>:<ul>
<li>封裝 <code>google.generativeai</code>。</li>
<li><code>APIKeyManager</code> 類別：讀取 <code>api_keys.json</code>，實作 Round-Robin (輪詢) 機制，當某 Key 超額時自動切換。</li>
<li><code>chat_with_retry</code> 函式：包含錯誤重試邏輯。</li>
</ul>
</li>
</ul>
<h3>Frontend</h3>
<ul>
<li><strong><code>app.js</code></strong>:<ul>
<li><code>initSpeechRecognition()</code>: 初始化瀏覽器 STT。</li>
<li><code>AppState</code>: 管理狀態機 (IDLE, RECORDING, PROCESSING, PLAYING)。</li>
<li><code>MatrixBackground</code>: Canvas 繪製駭客任務背景動畫。</li>
<li><code>VisualizationAnimator</code>: 繪製錄音與播放時的聲波/視覺效果，以及隱藏的 <strong>Snake Game</strong> (貪吃蛇)。</li>
</ul>
</li>
<li><strong><code>index.html</code></strong>:<ul>
<li>包含所有 UI 元素的 DOM 結構。引用了 Google Fonts (Roboto Mono, Bebas Neue)。</li>
</ul>
</li>
</ul>
<h2>5. 安裝與環境需求 (Installation &amp; Requirements)</h2>
<h3>系統需求</h3>
<ul>
<li><strong>OS</strong>: Windows / Linux / macOS (本專案已針對 Windows 優化)</li>
<li><strong>Python</strong>: 3.10 或更高版本 (建議使用虛擬環境)</li>
<li><strong>GPU</strong>: 強烈建議具備 NVIDIA GPU (CUDA 支援)，否則 XTTS 生成速度會極慢。</li>
</ul>
<h3>安裝步驟</h3>
<ol>
<li>
<p><strong>安裝 Python 相依套件</strong>
    <code>bash
    cd backend
    pip install -r requirements.txt</code>
    <em>注意：若安裝 <code>coqui-tts</code> 遇到問題，請參考其官方文檔解決 PyTorch 版本相容性。</em></p>
</li>
<li>
<p><strong>設定 API Keys</strong></p>
<ul>
<li>編輯 <code>backend/api_keys.json</code>，填入有效的 Google Gemini API Keys。</li>
</ul>
</li>
</ol>
<h3>環境變數</h3>
<ul>
<li>本專案主要依賴 <code>config.json</code> 與 <code>api_keys.json</code>，不強制依賴系統環境變數。</li>
</ul>
<h2>6. 使用方式 (How to Use)</h2>
<h3>啟動服務</h3>
<ol>
<li>開啟終端機，進入 <code>backend</code> 資料夾：
    <code>bash
    cd backend</code></li>
<li>
<p>執行 Server：
    <code>bash
    python server.py</code>
    <em>首次執行會自動下載 XTTS 模型 (約數 GB)，請耐心等待。</em></p>
</li>
<li>
<p>看見以下訊息即啟動成功：
    <code>text
    啟動伺服器於 http://localhost:5000</code></p>
</li>
</ol>
<h3>操作流程</h3>
<ol>
<li>瀏覽器打開 <code>http://localhost:5000</code> (建議使用 Chrome 以獲得最佳 Web Speech API 支援)。</li>
<li>允許麥克風權限。</li>
<li>點擊畫面中央紅色的 <strong>"PRESS TO RECORD"</strong> 按鈕（或按住不放，視 app.js 邏輯而定，目前設為點擊切換）。</li>
<li>說話 (例如：「你好，請介紹你自己」)。</li>
<li>等待 AI 處理，語音將會自動播放。</li>
</ol>
<h2>7. 設定說明 (Configuration)</h2>
<ul>
<li>
<p><strong><code>backend/config.json</code></strong>:</p>
<ul>
<li><code>model</code>: 指定 Gemini 模型版本 (如 <code>gemini-2.0-flash</code>)。</li>
<li><code>system_prompt</code>: 定義 AI 的人格設定 (目前設定為自然口語、台灣用語)。</li>
<li><code>temperature</code>: 控制回應創造性 (0 為最穩定)。</li>
</ul>
</li>
<li>
<p><strong><code>backend/api_keys.json</code></strong>:</p>
<ul>
<li><code>api_keys</code>: 陣列結構，可填入多組 Key 做負載平衡。</li>
</ul>
</li>
<li>
<p><strong><code>backend/server.py</code></strong>:</p>
<ul>
<li><code>SPEAKER_WAV</code>: 指定 TTS 模仿的聲音樣本，預設為 <code>Morgan Freeman.wav</code>。</li>
</ul>
</li>
</ul>
<h2>8. 開發者指南 (Developer Guide)</h2>
<h3>新人上手建議</h3>
<ol>
<li>先確認 Backend 能夠獨立運作。可使用 Postman 測試 <code>POST http://localhost:5000/api/chat</code>。</li>
<li>XTTS 模型載入極吃記憶體，開發時請關閉不必要的應用程式。</li>
<li>前端動畫邏輯位於 <code>app.js</code> 的 <code>VisualizationAnimator</code> 類別，修改視覺效果請由此下手。</li>
</ol>
<h3>常見雷區</h3>
<ul>
<li><strong>CORS 問題</strong>：雖然 <code>server.py</code> 已設定 CORS，但在某些複雜網路環境 (ngrok) 下可能需手動調整 header。</li>
<li><strong>瀏覽器 STT 限制</strong>：Web Speech API 在非 Chrome 瀏覽器 (如 Firefox/Safari) 支援度不佳，甚至無法使用。</li>
<li><strong>Windows 路徑</strong>：Python 處理路徑時建議使用 <code>os.path.join</code>，避免斜線問題。</li>
</ul>
<h2>9. 已知限制與待辦事項 (Limitations &amp; TODO)</h2>
<ul>
<li>
<p><strong>限制 (Limitations)</strong>:</p>
<ul>
<li><strong>STT 依賴性</strong>：完全依賴客戶端瀏覽器的 STT 能力，若環境吵雜或瀏覽器不支援則無法輸入。</li>
<li><strong>初次延遲</strong>：XTTS 模型即使在 GPU 上，首句生成仍有輕微延遲。</li>
<li><strong>單一語者</strong>：目前 TTS 鎖定使用 <code>Morgan Freeman.wav</code> 的特徵，未開放前端動態切換語者。</li>
</ul>
</li>
<li>
<p><strong>待辦事項 (TODO)</strong>:</p>
<ul>
<li>[ ] 實作後端 Whisper STT 以取代不穩定的瀏覽器原生 STT。</li>
<li>[ ] 新增前端上傳音訊樣本以「複製聲音 (Clone Voice)」的功能 UI (後端 API 已預留 <code>/api/speaker/clone</code>)。</li>
<li>[ ] 優化 <code>gemini_chat.py</code> 的錯誤處理，增加網路斷線重連機制。</li>
<li>[ ] 前端增加對話歷史紀錄清單。</li>
</ul>
</li>
</ul>
<h2>10. 補充說明 (Notes)</h2>
<ul>
<li><strong>關於 XTTS v2</strong>: 這是一個多語言模型，支援中文 (zh-cn)，但因訓練資料特性，有時口音會偏向大陸腔調，可透過 Prompt 調整或更換微調模型改善。</li>
<li><strong>ngrok 使用</strong>: 若需開放外網存取 (HTTPS)，可參考 <code>backend/指令.txt</code> 中的指令：
    <code>ngrok http 5000 --url=polite-in-redfish.ngrok-free.app</code>
    這是因為 Web Speech API 在非 localhost 的 HTTP 環境下會被瀏覽器阻擋，必須走 HTTPS。</li>
</ul>