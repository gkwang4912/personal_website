<h1>MusicLDM Video Audio Processor</h1>
<h2>專案總覽 (Project Overview)</h2>
<p>本專案為一個基於 MusicLDM 擴散模型的影片音訊風格轉換處理工具。
其主要目的是自動從輸入影片中提取音訊，透過 Latent Diffusion Model (LDM) 進行加噪 (Add Noise) 與降噪 (Denoise) 重建，最後將處理後的音訊合併回影片中。
此工具適用於需要對影片配樂進行風格化處理或音訊重生成的開發者與研究人員。
本專案性質為：Tool / Script。</p>
<h2>系統架構說明 (Architecture Overview)</h2>
<p>本系統主要由三個 Python 腳本協同運作：<code>process_video.py</code> 作為核心控制器，負責檔案管理與流程調度；<code>add_noise.py</code> 負責將原始音訊轉換為 Noisy Latent；<code>denoise.py</code> 負責從 Noisy Latent 生成新的目標音訊。
系統依賴 FFmpeg 進行多媒體格式轉換與合併，並使用 <code>diffusers</code> 套件載入 <code>ucsd-reach/musicldm</code> 模型進行推理。</p>
<p>資料流向為：影片檔 -&gt; 原始 WAV -&gt; 切分片段 -&gt; 加噪 (Latent) -&gt; 降噪 (WAV) -&gt; 合併 WAV -&gt; 輸出影片。</p>
<pre><code class="language-mermaid">graph TD
    User[User] --&gt;|Input Video| InputDir[video_input/]
    User --&gt;|Execute| ProcessVideo[process_video.py]

    ProcessVideo --&gt;|Extract Audio| FFmpeg1[FFmpeg System]
    FFmpeg1 --&gt;|Raw WAV| TempAudio[output/temp_audio/]

    ProcessVideo --&gt;|Call| AddNoise[add_noise.py]
    TempAudio --&gt;|Read WAV| AddNoise
    AddNoise --&gt;|Load| Model[MusicLDM Pipeline]
    AddNoise --&gt;|Save Latent| NoisyLatents[output/noisy_latents/]

    ProcessVideo --&gt;|Call| Denoise[denoise.py]
    NoisyLatents --&gt;|Read Latent| Denoise
    Denoise --&gt;|Inference| Model
    Denoise --&gt;|Save Processed WAV| DenoisedParts[output/denoised_parts/]

    ProcessVideo --&gt;|Concat Audio| FinalAudio[Final Merged WAV]
    ProcessVideo --&gt;|Merge Audio/Video| FFmpeg2[FFmpeg System]
    InputDir --&gt;|Original Video Stream| FFmpeg2
    FinalAudio --&gt; FFmpeg2
    FFmpeg2 --&gt;|Result| OutputDir[output/video/]
</code></pre>
<h2>系統流程說明 (System Flow)</h2>
<p>主要執行流程由 <code>process_video.py</code> 控制，針對每個輸入影片執行完整的 ETL (Extract, Transform, Load) 流程。
關鍵步驟包含音訊長度切分 (Chunking)，以符合 MusicLDM 對輸入長度的限制 (約 10.24 秒)。</p>
<pre><code class="language-mermaid">flowchart TD
    Start([Start]) --&gt; CheckEnv{Check FFmpeg}
    CheckEnv -- No --&gt; Error[Print Error &amp; Exit]
    CheckEnv -- Yes --&gt; ScanDir[Scan video_input/]

    ScanDir --&gt; HasFiles{Files Found?}
    HasFiles -- No --&gt; End([End])
    HasFiles -- Yes --&gt; LoopVideo[For Each Video]

    LoopVideo --&gt; Extract[Extract Audio via FFmpeg]
    Extract --&gt; LoadSplit[Load &amp; Split into 10.24s Chunks]

    LoadSplit --&gt; LoopChunk[For Each Chunk]
    LoopChunk --&gt; SaveTemp[Save Temp WAV]
    SaveTemp --&gt; CallAddNoise[Call add_noise.py]
    CallAddNoise --&gt; GenLatent[Generate Noisy Latent .pt]
    GenLatent --&gt; CallDenoise[Call denoise.py]
    CallDenoise --&gt; GenAudio[Generate Denoised WAV]
    GenAudio --&gt; StorePart[Store in List]

    StorePart --&gt; LoopChunk
    LoopChunk -- All Chunks Done --&gt; MergeParts[Concatenate Audio Parts]
    MergeParts --&gt; MuxAV[Merge Video &amp; New Audio via FFmpeg]
    MuxAV --&gt; LoopVideo

    LoopVideo -- All Videos Done --&gt; Finish([Finish])
</code></pre>
<h2>資料夾結構說明 (Folder Structure)</h2>
<ul>
<li><code>./</code> (專案根目錄)<ul>
<li><code>process_video.py</code>: 主程式入口，負責批次處理影片與流程控制。</li>
<li><code>add_noise.py</code>: 功能模組，負責將音訊轉換為 Latent 並添加噪音。</li>
<li><code>denoise.py</code>: 功能模組，負責從 Latent 執行擴散降噪生成音訊。</li>
<li><code>MusicLDM/</code>: 包含專案相關庫或原始碼的目錄。</li>
<li><code>musicldm_environment.yml</code>: Conda 環境設定檔。</li>
<li><code>video_input/</code>: <strong>[輸入]</strong> 使用者需將待處理的影片檔案 (.mp4, .avi 等) 放入此處。</li>
<li><code>output/</code>: <strong>[輸出]</strong> 系統執行產生的所有輸出檔案。<ul>
<li><code>video/</code>: 最終合成的結果影片。</li>
<li><code>temp_audio/</code>: 提取出的原始音訊與暫存片段。</li>
<li><code>noisy_latents/</code>: 中間產物，加噪後的 Latent tensor (.pt)。</li>
<li><code>denoised_parts/</code>: 中間產物，分段處理後的音訊 (.wav)。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">檔案名稱</th>
<th style="text-align: left;">類型</th>
<th style="text-align: left;">功能職責</th>
<th style="text-align: left;">關鍵依賴</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>process_video.py</code></td>
<td style="text-align: left;">Controller</td>
<td style="text-align: left;">檢查環境、掃描檔案、調用 ffmpeg、切分音訊、整合子模組。</td>
<td style="text-align: left;"><code>subprocess</code>, <code>torchaudio</code>, <code>numpy</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>add_noise.py</code></td>
<td style="text-align: left;">Processor</td>
<td style="text-align: left;">載入音訊、重取樣、執行 SDEdit 的加噪步驟 (Forward Process)。</td>
<td style="text-align: left;"><code>diffusers.MusicLDMPipeline</code>, <code>torch</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>denoise.py</code></td>
<td style="text-align: left;">Processor</td>
<td style="text-align: left;">載入 Noisy Latent、執行 SDEdit 的降噪步驟 (Reverse Process)。</td>
<td style="text-align: left;"><code>diffusers.MusicLDMPipeline</code>, <code>torch</code></td>
</tr>
</tbody>
</table>
<p>模組關係圖：</p>
<pre><code class="language-mermaid">classDiagram
    class ProcessVideo {
        +VIDEO_INPUT_DIR : str
        +process_video(video_path)
        +extract_audio()
        +merge_audio_video()
    }
    class AddNoise {
        +add_noise_to_audio()
        +load_audio()
        +steps : int
    }
    class Denoise {
        +denoise_audio()
        +prompt : str
        +guidance_scale : float
    }

    ProcessVideo ..&gt; AddNoise : Imports &amp; Calls
    ProcessVideo ..&gt; Denoise : Imports &amp; Calls
    AddNoise ..&gt; HuggingFace : Uses MusicLDMPipeline
    Denoise ..&gt; HuggingFace : Uses MusicLDMPipeline

    class HuggingFace {
        diffusers
        ucsd-reach/musicldm
    }
</code></pre>
<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>
<h3>系統需求</h3>
<ul>
<li>OS: Windows / Linux / macOS</li>
<li>Python: 3.8+ (建議)</li>
<li>CUDA 支援 (建議用於加速 PyTorch 與 MusicLDM 推理)</li>
</ul>
<h3>外部工具</h3>
<ul>
<li><strong>FFmpeg</strong>: 必須安裝並設定於系統 PATH 環境變數中。用於音訊提取與影片合成。</li>
</ul>
<h3>Python 套件</h3>
<p>主要依賴 (參考 <code>musicldm_environment.yml</code>):
*   <code>torch</code>, <code>torchaudio</code>
*   <code>diffusers</code>
*   <code>transformers</code> (diffusers 依賴)
*   <code>scipy</code>, <code>numpy</code></p>
<h3>安裝步驟 (範例)</h3>
<pre><code class="language-bash"># 若使用 Conda
conda env create -f musicldm_environment.yml
conda activate musicldm

# 或手動安裝 pip 套件
pip install torch torchaudio diffusers transformers scipy numpy
</code></pre>
<h2>使用方式 (How to Use)</h2>
<ol>
<li><strong>準備影片</strong>: 將您的影片檔案 (.mp4, .avi, .mov, .mkv) 放入 <code>video_input/</code> 資料夾中。若資料夾不存在請自行建立。</li>
<li><strong>調整設定 (可選)</strong>: 開啟 <code>process_video.py</code> 修改開頭的設定區塊 (如 <code>PROMPT</code>, <code>NOISE_LEVEL</code>)。</li>
<li><strong>執行程式</strong>:
    <code>bash
    python process_video.py</code></li>
<li><strong>查看結果</strong>: 處理完成後，前往 <code>output/video/</code> 查看生成的 <code>_processed.mp4</code> 影片。</li>
</ol>
<h2>設定說明 (Configuration)</h2>
<p>所有可調整參數皆位於 Python 腳本開頭的「設定區塊」全域變數中。</p>
<p><strong><code>process_video.py</code> 主要設定:</strong>
*   <code>NOISE_LEVEL</code> (float): 預設 <code>0.3</code>。決定保留多少原始音訊特徵。值越高變化越大。
*   <code>STEPS</code> (int): 預設 <code>200</code>。擴散模型的採樣步數。
*   <code>PROMPT</code> (str): 預設 <code>"High quality music"</code>。引導生成風格的文字提示。
*   <code>NEGATIVE_PROMPT</code> (str): 預設 <code>"noise, low quality"</code>。
*   <code>GUIDANCE_SCALE</code> (float): 預設 <code>1.5</code>。Classifier-Free Guidance 強度。
*   <code>MODEL_ID</code> (str): 預設 <code>"ucsd-reach/musicldm"</code>。
*   <code>SEED</code> (int): 預設 <code>42</code>。固定種子以確保結果可重現。</p>
<p><strong>注意</strong>: <code>add_noise.py</code> 與 <code>denoise.py</code> 內亦有相同參數設定，若單獨執行這兩個腳本時需注意參數同步。但在透過 <code>process_video.py</code> 執行時，其參數主要由 <code>process_video.py</code> 定義與控制 (雖然代碼中目前是各個檔案獨立定義變數，修改時建議三者同步確認)。</p>
<h2>開發者指南 (Developer Guide)</h2>
<h3>建議閱讀順序</h3>
<ol>
<li><code>process_video.py</code>: 理解整體 ETL 流程與 FFmpeg 指令操作。</li>
<li><code>add_noise.py</code>: 理解如何使用 <code>MusicLDMPipeline</code> 取得 VAE Latent 並手動加噪。</li>
<li><code>denoise.py</code>: 理解如何將 Latent 傳回 Pipeline 並使用 <code>latents</code> 參數進行 SDEdit。</li>
</ol>
<h3>修改注意事項</h3>
<ul>
<li><strong>音訊長度</strong>: MusicLDM 模型通常針對 10.24 秒 (16k 取樣率) 進行訓練。<code>process_video.py</code> 中的 <code>chunk_samples</code> 設定與此相關，修改時需謹慎。</li>
<li><strong>記憶體使用</strong>: 載入 Diffusion Model 需要較大 VRAM。若遇 OOM (Out of Memory)，可嘗試降低 <code>chunk_samples</code> 或使用 CPU (但速度會極慢)。</li>
<li><strong>同步性</strong>: 目前 <code>add_noise.py</code> 和 <code>denoise.py</code> 的參數是寫死在各自檔案開頭的，<code>process_video.py</code> 雖然有定義常數但實際呼叫時並未完全覆蓋所有子模組的預設值 (除了透過函式參數傳遞的部分)。建議在 <code>process_video.py</code> 統一管理並傳遞所有參數。</li>
</ul>
<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>
<h3>限制</h3>
<ul>
<li><strong>音訊接縫</strong>: 由於採用切塊分別處理 (Chunking)，合併後的音訊在切分點可能會有不連續或爆音 (Clipping) 的聽感。</li>
<li><strong>執行速度</strong>: 依賴 GPU 運算，處理長影片會非常耗時。</li>
<li><strong>參數同步</strong>: 部分參數分散在三個檔案中，維護上較為不便。</li>
</ul>
<h3>TODO</h3>
<ul>
<li>[ ] 實作 Overlap-Add 機制以消除音訊切分處的接縫。</li>
<li>[ ] 將所有參數提取至獨立的 <code>config.yaml</code> 或 <code>config.py</code> 統一管理。</li>
<li>[ ] 增加批次處理時的進度條顯示 (tqdm)。</li>
<li>[ ] 支援更多音訊格式輸入。</li>
</ul>
<h2>補充說明 (Notes)</h2>
<ul>
<li>本專案生成的 <code>output/</code> 資料夾可能會佔用大量磁碟空間 (尤其是 Latent 檔案)，建議定期清理。</li>
<li>若遇到 FFmpeg 錯誤，請優先檢查 FFmpeg 版本與系統環境變數設定。</li>
</ul>