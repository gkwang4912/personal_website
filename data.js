window.SITE_DATA = {"experience": "﻿type,year,title,venue,link\n競賽參與,2026,第一屆飛馬獎-第一名 VibeCodingLab,@zz41354899和 @cecelove1209、@dsif2017,https://drive.google.com/drive/folders/1PPAXdPPkaxV6XVVBW-LuDjD-4i3xZ1cT?usp=sharing\n競賽參與,2025,2025台灣數位雙生學會學生競賽-評審特別獎,台灣數位雙生學會,https://drive.google.com/drive/folders/1sjnaFhf9eWZGdpioc8npH3G3frqI8M_k?usp=sharing\n論文發表,2025,建構生成式AI輔助數位學習數據分析及政策建議系統,自主學習節暨數位學習行為與成效分析研討會,https://drive.google.com/drive/folders/1h9j8nzDPRgeaKdC5tnDkdfRAm189gghG?usp=sharing\n論文發表,2024,基於RAG技術之對話機器人對於大學生資訊判準自我效能與系統滿意度之影響,自主學習節暨數位學習行為與成效分析研討會,https://drive.google.com/drive/folders/1092WN9ft_TUEYAFS6_8jjYsrpTOenir0?usp=sharing\n研究計畫,2024,大專學生研究計畫-探討推理型模型在培養運算思維中的應用與成效,國家科學及技術委員會,https://drive.google.com/drive/folders/1buZQzfRNBw2_VpjAMn27Z4dcQxCnwiJ4?usp=sharing\n\n\n\n", "projects": {"generated_at": "2026-02-28T16:29:52.997272+00:00", "count": 11, "repos": [{"owner": "gkwang4912", "repo": "AI-Guider", "slug": "gkwang4912__AI-Guider", "path": "repo-cache/gkwang4912__AI-Guider", "head": "8b3d79b5c470b355c9437da97109af7b75fb2cbd"}, {"owner": "gkwang4912", "repo": "AI-Gym-Coach-Pro", "slug": "gkwang4912__AI-Gym-Coach-Pro", "path": "repo-cache/gkwang4912__AI-Gym-Coach-Pro", "head": "2214580e3cbe29af3f56bdf61ef16866bbe84449"}, {"owner": "gkwang4912", "repo": "CNN-Digit-Recognition-System", "slug": "gkwang4912__CNN-Digit-Recognition-System", "path": "repo-cache/gkwang4912__CNN-Digit-Recognition-System", "head": "5fe1b519bc13eeb9cc9a1752e0ccbda73b55c0df"}, {"owner": "gkwang4912", "repo": "Educational-Data-Analysis-Project", "slug": "gkwang4912__Educational-Data-Analysis-Project", "path": "repo-cache/gkwang4912__Educational-Data-Analysis-Project", "head": "8c790dbeae56863192d31cde8e0c5800e11e1ac6"}, {"owner": "gkwang4912", "repo": "Multimodal-video-analysis-and-RAG-retrieval-system", "slug": "gkwang4912__Multimodal-video-analysis-and-RAG-retrieval-system", "path": "repo-cache/gkwang4912__Multimodal-video-analysis-and-RAG-retrieval-system", "head": "88bd64c108c50e2a36c4906bad45d2b2905d2ee0"}, {"owner": "gkwang4912", "repo": "Multimodal-Video-Analysis-and-RAG-Retrieval-System_V2", "slug": "gkwang4912__Multimodal-Video-Analysis-and-RAG-Retrieval-System_V2", "path": "repo-cache/gkwang4912__Multimodal-Video-Analysis-and-RAG-Retrieval-System_V2", "head": "93af0436970fb6e742b12184d7e73884c9352359"}, {"owner": "gkwang4912", "repo": "Musical-Emotion-Analysis-Project", "slug": "gkwang4912__Musical-Emotion-Analysis-Project", "path": "repo-cache/gkwang4912__Musical-Emotion-Analysis-Project", "head": "eab92556dc28fb37e7eb90bc34087a0718e062f9"}, {"owner": "gkwang4912", "repo": "MusicLDM-Video-Audio-Processor", "slug": "gkwang4912__MusicLDM-Video-Audio-Processor", "path": "repo-cache/gkwang4912__MusicLDM-Video-Audio-Processor", "head": "6c4915bb031d3d0c79ada0ed3038e51730d1193e"}, {"owner": "gkwang4912", "repo": "NTCU-Student-Association-Integration-Project", "slug": "gkwang4912__NTCU-Student-Association-Integration-Project", "path": "repo-cache/gkwang4912__NTCU-Student-Association-Integration-Project", "head": "cdfe810f68a3406c741fdd0a21d5e58f6b85a92a"}, {"owner": "gkwang4912", "repo": "Sentiment-Analysis-System", "slug": "gkwang4912__Sentiment-Analysis-System", "path": "repo-cache/gkwang4912__Sentiment-Analysis-System", "head": "65179392b2315865d7547806bb3e5d9bf7dd5177"}, {"owner": "gkwang4912", "repo": "VibeCodingLab", "slug": "gkwang4912__VibeCodingLab", "path": "repo-cache/gkwang4912__VibeCodingLab", "head": "3a2ab0d63a2e66bafc3a8d05401f93d0739a9194"}]}, "repo_files": {"gkwang4912__AI-Guider": {"readme": "<h1>AI-Guider (Code Alchemist)</h1>\n<h2>1. 專案總覽 (Project Overview)</h2>\n<p><strong>AI-Guider</strong> 是一個整合即時語音識別 (STT)、大型語言模型 (LLM) 與語音合成 (TTS) 的全端 AI 互動應用程式。\n本專案旨在提供一個低延遲、具備豐富視覺效果（駭客任務風格）的語音對話系統，讓使用者能以自然的口語與 AI 導覽員進行互動。</p>\n<ul>\n<li><strong>解決問題</strong>：傳統文字聊天介面缺乏互動感，且即時語音對話常受限於延遲與機械音。本專案透過串流技術與高品質 TTS 解決此問題。</li>\n<li><strong>目標用戶</strong>：需要展示 AI 語音互動能力的開發者、展場導覽系統、或對語音助理有興趣的技術人員。</li>\n<li><strong>類型</strong>：Web Application (Client-Server 架構)。</li>\n</ul>\n<h2>2. 專案架構總覽 (Architecture Overview)</h2>\n<p>本系統採用前後端分離架構，但由後端統一提供靜態檔案服務。</p>\n<ul>\n<li><strong>前端 (Frontend)</strong>：<ul>\n<li>負責介面呈現、動畫 (Canvas) 與使用者輸入。</li>\n<li>使用瀏覽器原生的 <strong>Web Speech API</strong> 進行語音識別 (STT)，將使用者語音轉為文字。</li>\n<li>透過 API 發送文字給後端，並接收回傳的音訊串流進行播放。</li>\n</ul>\n</li>\n<li><strong>後端 (Backend)</strong>：<ul>\n<li>基於 <strong>Flask</strong> 框架。</li>\n<li><strong>對話引擎</strong>：整合 <strong>Google Gemini</strong> 模型，負責生成自然語言回應。</li>\n<li><strong>語音合成</strong>：整合 <strong>XTTS v2</strong> 模型，支援串流 (Streaming) 輸出，大幅降低首字延遲 (Time-to-First-Byte)。</li>\n<li>包含 API Key 管理機制，確保高併發時的穩定性。</li>\n</ul>\n</li>\n</ul>\n<p><strong>資料流</strong>：\n1.  [前端] 麥克風收音 -&gt; Web Speech API -&gt; 文字\n2.  [前端] POST <code>/api/chat/stream</code> (帶文字) -&gt; [後端]\n3.  [後端] Gemini 生成回應文字 -&gt; XTTS 轉換音訊 (Streaming) -&gt; [前端]\n4.  [前端] 接收音訊 Chunk -&gt; 即時播放</p>\n<h2>3. 資料夾結構說明 (Folder Structure)</h2>\n<pre><code class=\"language-text\">.\n├── backend/                  # 後端核心程式碼\n│   ├── __pycache__/         # Python 編譯快取\n│   ├── outputs/             # (自動產生) 存放生成的 .wav 音訊檔\n│   ├── api_keys.json        # Google Gemini API Keys 設定檔\n│   ├── config.json          # AI 模型參數與 System Prompt 設定\n│   ├── gemini_chat.py       # Gemini 模型串接與 API Key 輪詢邏輯\n│   ├── Morgan Freeman.wav   # XTTS 用於聲音克隆的參考樣本\n│   ├── requirements.txt     # Python 相依套件清單\n│   ├── server.py            # Flask 伺服器入口點 (Entry Point)\n│   ├── xtts_v2.py           # XTTS v2 模型封裝與串流邏輯\n│   └── 指令.txt              # 備忘指令 (如 ngrok)\n└── frontend/                 # 前端靜態資源\n    ├── app.js               # 前端主要邏輯 (錄音、動畫、API 呼叫)\n    ├── index.html           # 主頁面結構\n    ├── sora_loop.mp4        # 待機或處理中播放的背景影片\n    └── styles.css           # 樣式表 (Matrix 風格設計)\n</code></pre>\n<h2>4. 核心模組與重要檔案說明 (Key Modules &amp; Files)</h2>\n<h3>Backend</h3>\n<ul>\n<li><strong><code>server.py</code></strong>:<ul>\n<li>專案入口。啟動 Flask Server，設定 CORS。</li>\n<li>提供 <code>/api/chat/stream</code> 等核心端點。</li>\n<li>會在啟動時預先載入 XTTS 模型與計算 Speaker Embedding。</li>\n<li>同時負責 serve <code>frontend/</code> 下的靜態檔案 (為了簡化部署)。</li>\n</ul>\n</li>\n<li><strong><code>xtts_v2.py</code></strong>:<ul>\n<li>封裝 <code>coqui-tts</code> 的 <code>Xtts</code> 模型。</li>\n<li><code>XTTSStreamingTTS</code> 類別：實作了 <code>tts_stream</code> generator，能產生 byte chunks 供 Flask 串流回傳。</li>\n<li><strong>重要</strong>：針對 Windows 環境已強制關閉 DeepSpeed (<code>use_deepspeed=False</code>) 以避免相容性問題。</li>\n</ul>\n</li>\n<li><strong><code>gemini_chat.py</code></strong>:<ul>\n<li>封裝 <code>google.generativeai</code>。</li>\n<li><code>APIKeyManager</code> 類別：讀取 <code>api_keys.json</code>，實作 Round-Robin (輪詢) 機制，當某 Key 超額時自動切換。</li>\n<li><code>chat_with_retry</code> 函式：包含錯誤重試邏輯。</li>\n</ul>\n</li>\n</ul>\n<h3>Frontend</h3>\n<ul>\n<li><strong><code>app.js</code></strong>:<ul>\n<li><code>initSpeechRecognition()</code>: 初始化瀏覽器 STT。</li>\n<li><code>AppState</code>: 管理狀態機 (IDLE, RECORDING, PROCESSING, PLAYING)。</li>\n<li><code>MatrixBackground</code>: Canvas 繪製駭客任務背景動畫。</li>\n<li><code>VisualizationAnimator</code>: 繪製錄音與播放時的聲波/視覺效果，以及隱藏的 <strong>Snake Game</strong> (貪吃蛇)。</li>\n</ul>\n</li>\n<li><strong><code>index.html</code></strong>:<ul>\n<li>包含所有 UI 元素的 DOM 結構。引用了 Google Fonts (Roboto Mono, Bebas Neue)。</li>\n</ul>\n</li>\n</ul>\n<h2>5. 安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li><strong>OS</strong>: Windows / Linux / macOS (本專案已針對 Windows 優化)</li>\n<li><strong>Python</strong>: 3.10 或更高版本 (建議使用虛擬環境)</li>\n<li><strong>GPU</strong>: 強烈建議具備 NVIDIA GPU (CUDA 支援)，否則 XTTS 生成速度會極慢。</li>\n</ul>\n<h3>安裝步驟</h3>\n<ol>\n<li>\n<p><strong>安裝 Python 相依套件</strong>\n    <code>bash\n    cd backend\n    pip install -r requirements.txt</code>\n    <em>注意：若安裝 <code>coqui-tts</code> 遇到問題，請參考其官方文檔解決 PyTorch 版本相容性。</em></p>\n</li>\n<li>\n<p><strong>設定 API Keys</strong></p>\n<ul>\n<li>編輯 <code>backend/api_keys.json</code>，填入有效的 Google Gemini API Keys。</li>\n</ul>\n</li>\n</ol>\n<h3>環境變數</h3>\n<ul>\n<li>本專案主要依賴 <code>config.json</code> 與 <code>api_keys.json</code>，不強制依賴系統環境變數。</li>\n</ul>\n<h2>6. 使用方式 (How to Use)</h2>\n<h3>啟動服務</h3>\n<ol>\n<li>開啟終端機，進入 <code>backend</code> 資料夾：\n    <code>bash\n    cd backend</code></li>\n<li>\n<p>執行 Server：\n    <code>bash\n    python server.py</code>\n    <em>首次執行會自動下載 XTTS 模型 (約數 GB)，請耐心等待。</em></p>\n</li>\n<li>\n<p>看見以下訊息即啟動成功：\n    <code>text\n    啟動伺服器於 http://localhost:5000</code></p>\n</li>\n</ol>\n<h3>操作流程</h3>\n<ol>\n<li>瀏覽器打開 <code>http://localhost:5000</code> (建議使用 Chrome 以獲得最佳 Web Speech API 支援)。</li>\n<li>允許麥克風權限。</li>\n<li>點擊畫面中央紅色的 <strong>\"PRESS TO RECORD\"</strong> 按鈕（或按住不放，視 app.js 邏輯而定，目前設為點擊切換）。</li>\n<li>說話 (例如：「你好，請介紹你自己」)。</li>\n<li>等待 AI 處理，語音將會自動播放。</li>\n</ol>\n<h2>7. 設定說明 (Configuration)</h2>\n<ul>\n<li>\n<p><strong><code>backend/config.json</code></strong>:</p>\n<ul>\n<li><code>model</code>: 指定 Gemini 模型版本 (如 <code>gemini-2.0-flash</code>)。</li>\n<li><code>system_prompt</code>: 定義 AI 的人格設定 (目前設定為自然口語、台灣用語)。</li>\n<li><code>temperature</code>: 控制回應創造性 (0 為最穩定)。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>backend/api_keys.json</code></strong>:</p>\n<ul>\n<li><code>api_keys</code>: 陣列結構，可填入多組 Key 做負載平衡。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>backend/server.py</code></strong>:</p>\n<ul>\n<li><code>SPEAKER_WAV</code>: 指定 TTS 模仿的聲音樣本，預設為 <code>Morgan Freeman.wav</code>。</li>\n</ul>\n</li>\n</ul>\n<h2>8. 開發者指南 (Developer Guide)</h2>\n<h3>新人上手建議</h3>\n<ol>\n<li>先確認 Backend 能夠獨立運作。可使用 Postman 測試 <code>POST http://localhost:5000/api/chat</code>。</li>\n<li>XTTS 模型載入極吃記憶體，開發時請關閉不必要的應用程式。</li>\n<li>前端動畫邏輯位於 <code>app.js</code> 的 <code>VisualizationAnimator</code> 類別，修改視覺效果請由此下手。</li>\n</ol>\n<h3>常見雷區</h3>\n<ul>\n<li><strong>CORS 問題</strong>：雖然 <code>server.py</code> 已設定 CORS，但在某些複雜網路環境 (ngrok) 下可能需手動調整 header。</li>\n<li><strong>瀏覽器 STT 限制</strong>：Web Speech API 在非 Chrome 瀏覽器 (如 Firefox/Safari) 支援度不佳，甚至無法使用。</li>\n<li><strong>Windows 路徑</strong>：Python 處理路徑時建議使用 <code>os.path.join</code>，避免斜線問題。</li>\n</ul>\n<h2>9. 已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<ul>\n<li>\n<p><strong>限制 (Limitations)</strong>:</p>\n<ul>\n<li><strong>STT 依賴性</strong>：完全依賴客戶端瀏覽器的 STT 能力，若環境吵雜或瀏覽器不支援則無法輸入。</li>\n<li><strong>初次延遲</strong>：XTTS 模型即使在 GPU 上，首句生成仍有輕微延遲。</li>\n<li><strong>單一語者</strong>：目前 TTS 鎖定使用 <code>Morgan Freeman.wav</code> 的特徵，未開放前端動態切換語者。</li>\n</ul>\n</li>\n<li>\n<p><strong>待辦事項 (TODO)</strong>:</p>\n<ul>\n<li>[ ] 實作後端 Whisper STT 以取代不穩定的瀏覽器原生 STT。</li>\n<li>[ ] 新增前端上傳音訊樣本以「複製聲音 (Clone Voice)」的功能 UI (後端 API 已預留 <code>/api/speaker/clone</code>)。</li>\n<li>[ ] 優化 <code>gemini_chat.py</code> 的錯誤處理，增加網路斷線重連機制。</li>\n<li>[ ] 前端增加對話歷史紀錄清單。</li>\n</ul>\n</li>\n</ul>\n<h2>10. 補充說明 (Notes)</h2>\n<ul>\n<li><strong>關於 XTTS v2</strong>: 這是一個多語言模型，支援中文 (zh-cn)，但因訓練資料特性，有時口音會偏向大陸腔調，可透過 Prompt 調整或更換微調模型改善。</li>\n<li><strong>ngrok 使用</strong>: 若需開放外網存取 (HTTPS)，可參考 <code>backend/指令.txt</code> 中的指令：\n    <code>ngrok http 5000 --url=polite-in-redfish.ngrok-free.app</code>\n    這是因為 Web Speech API 在非 localhost 的 HTTP 環境下會被瀏覽器阻擋，必須走 HTTPS。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "AI-Guider", "generated_at": "2026-02-28T16:29:52.886721+00:00", "head": "8b3d79b5c470b355c9437da97109af7b75fb2cbd"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"backend", "children": [{"type": "file", "name": "\\346\\214\\207\\344\\273\\244.txt\""}]}, {"type": "dir", "name": "backend", "children": [{"type": "file", "name": "api_keys.json"}, {"type": "file", "name": "config.json"}, {"type": "file", "name": "gemini_chat.py"}, {"type": "file", "name": "Morgan Freeman.wav"}, {"type": "file", "name": "requirements.txt"}, {"type": "file", "name": "server.py"}, {"type": "file", "name": "xtts_v2.py"}]}, {"type": "dir", "name": "frontend", "children": [{"type": "file", "name": "app.js"}, {"type": "file", "name": "index.html"}, {"type": "file", "name": "sora_loop.mp4"}, {"type": "file", "name": "styles.css"}]}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__AI-Gym-Coach-Pro": {"readme": "<h1>AI Gym Coach Pro</h1>\n<h2>1. 專案總覽 (Project Overview)</h2>\n<p><strong>AI Gym Coach Pro</strong> 是一個基於網頁的即時健身動作偵測與輔助應用程式。\n本專案利用電腦視覺技術（Computer Vision），透過使用者的一般視訊鏡頭（Webcam）即時分析使用者的健身動作（目前專注於啞鈴彎舉 Dumbbell Curls），並提供與專業教練相似的即時數據回饋。</p>\n<ul>\n<li><strong>解決問題</strong>：提供居家健身者即時的動作標準度檢測、次數計算與速度監控，避免因動作不標準受傷或訓練效率低落。</li>\n<li><strong>目標用戶</strong>：居家健身愛好者、需要自動化計數的健身人士。</li>\n<li><strong>專案類型</strong>：Web Application (Browser-based Client + Python Backend)。</li>\n</ul>\n<h2>2. 專案架構總覽 (Architecture Overview)</h2>\n<p>本專案採用 Client-Server 架構，透過 WebSocket 進行高頻率的雙向影像與數據傳輸。</p>\n<h3>高層次架構</h3>\n<ol>\n<li>\n<p><strong>前端 (Client)</strong>：</p>\n<ul>\n<li>負責擷取使用者視訊鏡頭影像（Webcam）。</li>\n<li>將影像縮小並轉碼為 Base64 字串，透過 WebSocket (<code>socket.io</code>) 發送至後端。</li>\n<li>接收後端處理後的「骨架疊加影像」與「分析數據（角度、次數、速度）」。</li>\n<li>即時更新儀表板 UI。</li>\n</ul>\n</li>\n<li>\n<p><strong>後端 (Server)</strong>：</p>\n<ul>\n<li>基於 Flask 與 Flask-SocketIO 運行。</li>\n<li>接收影像後，使用 <strong>MediaPipe Pose</strong> 模型進行人體骨架關鍵點偵測。</li>\n<li><strong>邏輯運算核心</strong>：計算手肘角度、判斷動作階段（舉起/放下）、計算動作速度。</li>\n<li>將繪製好骨架的影像與 JSON 格式的統計數據回傳給前端。</li>\n</ul>\n</li>\n</ol>\n<h3>資料流 (Data Flow)</h3>\n<ol>\n<li><strong>Input</strong>: Browser Webcam Capture -&gt; Canvas Context -&gt; Base64 JPEG.</li>\n<li><strong>Transport</strong>: Socket.IO (<code>process_frame</code> event).</li>\n<li><strong>Process</strong>: Python <code>cv2</code> decode -&gt; <code>mediapipe</code> inference -&gt; State Machine Update -&gt; <code>cv2</code> draw.</li>\n<li><strong>Output</strong>: Base64 processed image + JSON Stats -&gt; Socket.IO (<code>response</code> event) -&gt; Update Browser DOM &amp; Canvas.</li>\n</ol>\n<h2>3. 資料夾結構說明 (Folder Structure)</h2>\n<pre><code class=\"language-text\">.\n├── templates/\n│   └── index.html      # 前端單頁應用程式入口，包含所有的 HTML/CSS/JS\n├── requirements.txt    # Python 相依套件清單\n└── web_app.py          # 後端主程式，包含 API、Socket 服務與影像處理邏輯\n</code></pre>\n<ul>\n<li><strong><code>templates/</code></strong>: 存放 Flask 的 Jinja2 樣板檔案，目前僅有一個 <code>index.html</code> 作為主要介面。</li>\n<li><strong><code>web_app.py</code></strong>: 專案的核心入口點，負責啟動 Web Server 與處理所有核心業務邏輯。</li>\n<li><strong><code>requirements.txt</code></strong>: 定義專案運行所需的 Python 函式庫版本。</li>\n</ul>\n<h2>4. 核心模組與重要檔案說明 (Key Modules &amp; Files)</h2>\n<h3><code>web_app.py</code></h3>\n<p>後端核心檔案，職責如下：\n- <strong>Flask Server 初始化</strong>: 設定 Web Server 與 WebSocket (<code>Flask-SocketIO</code>)。\n- <strong><code>handle_frame(data)</code></strong>: \n    - WebSocket 事件處理函式。\n    - 負責解碼圖片、呼叫 MediaPipe、計算運動幾何（角度）、更新計數器狀態。\n    - 實作「過快警示」與「動作範圍（ROM）」判斷邏輯。\n- <strong><code>calculate_angle(a, b, c)</code></strong>: \n    - 計算三點（肩膀、手肘、手腕）之間的夾角，用於判斷手臂彎曲程度。\n- <strong>全域變數 <code>hands</code></strong>: \n    - 儲存左手與右手目前的狀態（次數、是否在頂點、速度計算用的時間戳記）。</p>\n<h3><code>templates/index.html</code></h3>\n<p>前端單一整合檔案，職責如下：\n- <strong>UI 呈現</strong>: \n    - 使用 CSS Grid 佈局，包含霓虹風格（Neon Style）與掃描線特效（Scanline Effect）。\n    - 顯示左右手的即時數據卡片（Reps, Angle, Speed）。\n- <strong>影像擷取邏輯</strong>: \n    - 使用 <code>navigator.mediaDevices.getUserMedia</code> 取得權限。\n    - 透過 <code>Canvas</code> 進行影像鏡像翻轉（Mirroring）處理。\n- <strong>傳輸控制</strong>: \n    - 使用 <code>setInterval</code> 以約 12 FPS (80ms) 的頻率發送影像至後端，平衡即時性與頻寬。</p>\n<h2>5. 安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li><strong>OS</strong>: Windows / macOS / Linux (開發環境為 Windows)。</li>\n<li><strong>Python</strong>: 建議 Python 3.8 ~ 3.10。</li>\n<li><strong>硬體</strong>: 必須連接 Webcam。</li>\n</ul>\n<h3>相依套件</h3>\n<p>請見 <code>requirements.txt</code>，主要包含：\n- <code>flask</code>, <code>flask-socketio</code>: Web 框架與 WebSocket 支援。\n- <code>opencv-python</code>: 影像處理。\n- <code>mediapipe</code>: 骨架偵測模型。\n- <code>protobuf&lt;4.0.0</code>: <strong>重要</strong>，MediaPipe 對 Protobuf 版本有特定限制。\n- <code>eventlet</code>: 用於 SocketIO 的非同步網路庫。</p>\n<h3>安裝指令</h3>\n<pre><code class=\"language-bash\">pip install -r requirements.txt\n</code></pre>\n<h2>6. 使用方式 (How to Use)</h2>\n<h3>1. 啟動伺服器</h3>\n<p>在專案根目錄執行：</p>\n<pre><code class=\"language-bash\">python web_app.py\n</code></pre>\n<p>成功啟動後，終端機將顯示：<code>啟動 Web AI Gym Coach on port 5001...</code></p>\n<h3>2. 開啟應用程式</h3>\n<ol>\n<li>開啟瀏覽器（建議 Chrome 或 Edge）。</li>\n<li>前往 <code>http://localhost:5001 /</code> 或 <code>http://127.0.0.1:5001</code>。</li>\n<li>瀏覽器會詢問「使用相機權限」，請點選「允許」。</li>\n</ol>\n<h3>3. 開始運動</h3>\n<ol>\n<li>站在距離鏡頭約 1.5 ~ 2 公尺處，確保上半身與手臂完整入鏡。</li>\n<li>系統會自動偵測並在畫面上繪製骨架。</li>\n<li>開始做「啞鈴彎舉」動作：<ul>\n<li>手臂放下（角度 &gt; 140度）。</li>\n<li>手臂舉起（角度 &lt; 130度，且手腕高於鼻子水平線）。</li>\n</ul>\n</li>\n<li>介面將即時更新次數、速度與動作建議（如 \"Too Fast!\", \"Too Low!\"）。</li>\n</ol>\n<h2>7. 設定說明 (Configuration)</h2>\n<p>目前專案採 <strong>Code-First Configuration</strong>，設定值直接定義於 <code>web_app.py</code> 頂部常數中：</p>\n<ul>\n<li><strong>動作門檻值</strong>:<ul>\n<li><code>ARM_UP_ANGLE = 140</code>: 手臂伸直的角度判定點。</li>\n<li><code>ARM_DOWN_ANGLE = 130</code>: 手臂彎曲的角度判定點。</li>\n<li><strong>注意</strong>: 程式碼邏輯中，變數命名可能與直觀相反（UP/DOWN 對應角度數值），需參考 <code>calculate_angle</code> 的回傳值。</li>\n</ul>\n</li>\n<li><strong>速度限制</strong>:<ul>\n<li><code>SPEED_LIMIT = 1.8</code>: 若動作速度數值超過此值，會觸發 \"太快!\" 警告。</li>\n</ul>\n</li>\n<li><strong>字型設定</strong>:<ul>\n<li><code>FONT_CANDIDATES</code>: 支援 <code>msjh.ttc</code> (微軟正黑體) 等，若找不到會自動 fallback 到預設字型。</li>\n</ul>\n</li>\n<li><strong>連線設定</strong>:<ul>\n<li>預設 Port: <code>5001</code></li>\n<li>預設 Host: <code>0.0.0.0</code> (允許區網連線)</li>\n</ul>\n</li>\n</ul>\n<h2>8. 開發者指南 (Developer Guide)</h2>\n<h3>給新人的建議</h3>\n<ol>\n<li><strong>鏡像問題</strong>: <ul>\n<li>前端在 <code>ctx.scale(-1, 1)</code> 做了鏡像翻轉顯示給使用者看。</li>\n<li>傳給後端的影像也是鏡像後的。</li>\n<li>後端 MediaPipe 偵測到的 <code>Left</code> 實際上是使用者的「左手」（因為是鏡像），但若沒有鏡像，通常畫面左邊是使用者的右手。請注意左右手標籤在 UI 上的對應。</li>\n</ul>\n</li>\n<li><strong>字型路徑</strong>:<ul>\n<li><code>web_app.py</code> 中寫死了一些 Windows 常見字型路徑 (<code>C:\\Windows\\Fonts</code>)。若在 Linux docker 中部署，中文顯示可能會失效，需確認字型檔存在或修改路徑。</li>\n</ul>\n</li>\n</ol>\n<h3>常見修正建議</h3>\n<ul>\n<li>若要調整判定嚴格度，請修改 <code>web_app.py</code> 第 48-50 行的 <code>ANGLE</code> 常數。</li>\n<li>若要修改前端 UI 更新頻率，請修改 <code>index.html</code> 第 362 行的 <code>80</code> (毫秒)。</li>\n</ul>\n<h2>9. 已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<h3>已知限制 (Confirmed Limitations)</h3>\n<ol>\n<li><strong>狀態並發問題 (Concurrency Issue)</strong>:<ul>\n<li><strong>嚴重</strong>: 後端使用全域變數 <code>hands</code> (<code>global hands</code>, line 65) 儲存運動狀態。</li>\n<li><strong>影響</strong>: 若同時有多個瀏覽器開啟網頁，所有人的動作會混雜計算在同一個變數中，導致計數亂跳。</li>\n<li><strong>解法</strong>: 需將狀態改為 <code>session</code> based 或以 <code>socket.id</code> 為 key 的字典來隔離不同使用者。</li>\n</ul>\n</li>\n<li><strong>效能瓶頸</strong>:<ul>\n<li>每一幀圖片都經過 Base64 編碼/解碼並透過 WebSocket 傳輸，頻寬消耗極大且延遲較高。</li>\n<li>較好的做法是：前端僅傳送 Landmarks 或後端僅回傳數據，影像由前端自行繪製。</li>\n</ul>\n</li>\n<li><strong>依賴版本</strong>:<ul>\n<li><code>metrics</code> 計算依賴 <code>time.time()</code>，若系統時間跳變可能導致速度計算異常（出現極大值）。</li>\n</ul>\n</li>\n</ol>\n<h3>TODO / FIXME</h3>\n<ul>\n<li><strong>FIXME</strong>: 將全域 <code>hands</code> 變數重構為 Session-scoped 變數，支援多人同時使用。</li>\n<li><strong>TODO</strong>: 將硬編碼的參數（角度、Port、速度限制）移至 <code>.env</code> 或獨立 config 檔。</li>\n<li><strong>TODO</strong>: 前端 <code>video</code> 元素目前是 <code>opacity: 0</code> 隱藏，僅用 Canvas 繪圖，可考慮 WebGL 優化渲染效能。</li>\n<li><strong>尚未實作</strong>: <code>cv2_add_chinese_text</code> 雖然有定義，但在主要繪圖邏輯中大部分被註解或只使用英文 (OpenCV <code>putText</code> / <code>line</code>)，目前中文回饋主要依賴前端 DOM 顯示。</li>\n</ul>\n<h2>10. 補充說明 (Notes)</h2>\n<ul>\n<li><strong>環境變數</strong>: 程式碼中強制設定了 <code>os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"</code> (Line 4)，這是為了解決某些版本 protobuf 與 mediapipe 的相容性崩潰問題，<strong>請勿移除</strong>。</li>\n<li><strong>中文字型</strong>: 程式碼嘗試載入系統中文字型，主要是為了在 OpenCV 圖片上壓上中文浮水印，但目前主要資訊回饋已移至 HTML UI 層，圖片上的文字非必要功能。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "AI-Gym-Coach-Pro", "generated_at": "2026-02-28T16:29:52.898900+00:00", "head": "2214580e3cbe29af3f56bdf61ef16866bbe84449"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "templates", "children": [{"type": "file", "name": "index.html"}]}, {"type": "file", "name": "README.md"}, {"type": "file", "name": "requirements.txt"}, {"type": "file", "name": "web_app.py"}]}}, "gkwang4912__CNN-Digit-Recognition-System": {"readme": "<h1>CNN Digit Recognition System (五碼數字辨識系統)</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案是一個基於卷積神經網路 (CNN) 的數字辨識系統，專門設計用於辨識特定格式的圖片（例如水錶或電錶的五位數讀數）。系統包含完整的訓練流程與推論展示工具。</p>\n<ul>\n<li><strong>專案用途</strong>：自動化識別含有 5 位數字的圖片。</li>\n<li><strong>解決的問題</strong>：將特定裁切範圍內的影像數據轉換為數位格式。</li>\n<li><strong>使用對象</strong>：開發者、數據分析師或自動化與 IoT 串接人員。</li>\n<li><strong>專案性質</strong>：Service / Tool (機器學習模型訓練與推論工具)。</li>\n</ul>\n<hr />\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統分為「訓練 (Training)」與「推論 (Inference)」兩大階段。核心採用 TensorFlow/Keras 建立的 CNN 模型。</p>\n<h3>模組職責</h3>\n<ul>\n<li><strong>Data Preprocessing</strong>: 負責將原始大圖依據固定座標切割為 5 等份，並進行灰階化與正規化。</li>\n<li><strong>CNN Model</strong>: 卷積神經網路，負責特徵提取與數字分類 (0-9)。</li>\n<li><strong>Storage</strong>: 儲存處理後的圖片 (<code>processed_images</code>) 與訓練好的模型 (<code>.h5</code>)。</li>\n</ul>\n<h3>系統架構圖</h3>\n<pre><code class=\"language-mermaid\">graph TD\n    subgraph Data_Preparation [資料準備與預處理]\n        Raw[原始圖片 dataset_folder] --&gt;|Split Logic| Cropped[切割圖片 processed_images]\n        Cropped --&gt;|Label Parsing| LabeledData[標註數據]\n        LabeledData --&gt;|Grayscale + Resize + Norm| Tensor[&quot;輸入張量 (28x28x1)&quot;]\n    end\n\n    subgraph Training_Core [模型訓練核心 cnn.py]\n        Tensor --&gt;|Batch Input| CNN[CNN 模型架構]\n        CNN --&gt;|Backpropagation| Weights[更新權重]\n        Weights --&gt;|Save| H5File[digit_recognition_model.h5]\n    end\n\n    subgraph Inference_Service [推論應用 testModel.py]\n        TestImg[測試圖片] --&gt;|Same Split Logic| TestSlices[切割後影像 split_images]\n        TestSlices --&gt;|Preprocess| ReadyData[預處理後影像]\n        H5File --&gt;|Load| LoadedModel[載入模型]\n        ReadyData --&gt;|Predict| LoadedModel\n        LoadedModel --&gt;|Output| FinalRes[預測結果字串]\n        LoadedModel --&gt;|Viz| Plot[Matplotlib 視覺化]\n    end\n</code></pre>\n<hr />\n<h2>系統流程說明 (System Flow)</h2>\n<h3>1. 訓練流程 (Training Pipeline) - <code>cnn.py</code></h3>\n<p>程式會讀取 <code>dataset_folder</code> 中的圖片，根據檔名解析出正確答案 (Label)，切割後即時餵入模型進行訓練。</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start([啟動 cnn.py]) --&gt; Scan{掃描 dataset_folder}\n    Scan --&gt;|發現圖片| ParseName[解析檔名取得 Label]\n    ParseName --&gt; Crop[依固定座標切割為 5 張]\n    Crop --&gt; Preprocess[&quot;轉灰階 -&gt; Resize(28x28) -&gt; Normalize&quot;]\n    Preprocess --&gt; TrainStep[&quot;模型訓練 (Fit)&quot;]\n    TrainStep --&gt; Scan\n    Scan --&gt;|無更多圖片| Save[儲存模型 digit_recognition_model.h5]\n    Save --&gt; End([結束])\n</code></pre>\n<h3>2. 推論流程 (Inference Pipeline) - <code>testModel.py</code></h3>\n<p>載入已訓練的模型，對單張測試圖片進行相同的切割與處理，最後輸出五位數結果並顯示信心分數。</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant User\n    participant Script as testModel.py\n    participant Model as Loaded Model\n    participant FS as File System\n\n    User-&gt;&gt;Script: 執行程式 (指定測試圖)\n    Script-&gt;&gt;FS: 載入 digit_recognition_model.h5\n    Script-&gt;&gt;FS: 讀取測試圖片\n    Script-&gt;&gt;Script: 執行 split_image (切割成5份)\n    loop 每一個切片\n        Script-&gt;&gt;Script: 預處理 (Gray/Resize/Norm)\n        Script-&gt;&gt;Model: Predict (預測)\n        Model--&gt;&gt;Script: 回傳機率分佈\n        Script-&gt;&gt;Script: 取得最大機率數字 (Argmax)\n    end\n    Script-&gt;&gt;User: 顯示 Matplotlib 結果圖表\n    Script-&gt;&gt;User: Print 最終合併數字 (例如 &quot;12345&quot;)\n</code></pre>\n<hr />\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<pre><code class=\"language-text\">.\n├── cnn.py                      # [核心] 模型訓練腳本\n├── testModel.py                # [核心] 模型測試與推論腳本\n├── test.py                     # [工具] GPU 環境測試工具\n├── digit_recognition_model.h5  # [產出] 訓練完成的模型檔\n├── dataset_folder/             # [資料] 存放原始訓練圖片\n├── processed_images/           # [中間產物] cnn.py 執行過中產生的切割圖片\n├── split_images/               # [中間產物] testModel.py 執行時產生的測試切片\n└── README.md                   # 專案說明文件\n</code></pre>\n<hr />\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">檔案名稱</th>\n<th style=\"text-align: left;\">類型</th>\n<th style=\"text-align: left;\">職責與功能</th>\n<th style=\"text-align: left;\">關聯模組</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>cnn.py</strong></td>\n<td style=\"text-align: left;\">Training Script</td>\n<td style=\"text-align: left;\">定義 CNN 架構、讀取 <code>dataset_folder</code>、執行圖片切割資料擴增、訓練並儲存模型。</td>\n<td style=\"text-align: left;\"><code>dataset_folder</code>, <code>processed_images</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>testModel.py</strong></td>\n<td style=\"text-align: left;\">Inference Script</td>\n<td style=\"text-align: left;\">載入 <code>.h5</code> 模型、讀取單張圖片進行預測、使用 Matplotlib 繪製結果。</td>\n<td style=\"text-align: left;\"><code>digit_recognition_model.h5</code>, <code>split_images</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>dataset_folder/</strong></td>\n<td style=\"text-align: left;\">Directory</td>\n<td style=\"text-align: left;\">放置訓練用的原始圖片。檔名格式嚴格要求：<code>前綴_時間戳_標籤數字.jpg</code> (程式會取第3部分作為 Label)。</td>\n<td style=\"text-align: left;\">被 <code>cnn.py</code> 讀取</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li><strong>OS</strong>: Windows (目前環境) / Linux / macOS</li>\n<li><strong>Python Version</strong>: 3.8+</li>\n</ul>\n<h3>核心相依套件 (Dependencies)</h3>\n<p>請確保安裝以下 Python 套件：</p>\n<pre><code class=\"language-bash\">pip install tensorflow numpy opencv-python matplotlib pillow\n</code></pre>\n<h3>環境變數</h3>\n<ul>\n<li>本專案主要依賴相對路徑，無需設定特殊環境變數。</li>\n<li>若有 GPU，<code>tensorflow</code> 會自動偵測 (可使用 <code>test.py</code> 驗證)。</li>\n</ul>\n<hr />\n<h2>使用方式 (How to Use)</h2>\n<h3>1. 準備訓練資料</h3>\n<p>將原始圖片放入 <code>dataset_folder</code> 中。\n- <strong>檔名命名規則</strong>：必須包含三個透過底線 <code>_</code> 分隔的區塊，例如 <code>DeviceA_20230101_12345.jpg</code>。\n    - 程式邏輯：<code>filename.split(\"_\")[2]</code> 被視為正確答案 (Label string)。</p>\n<h3>2. 訓練模型</h3>\n<p>執行以下指令開始訓練：</p>\n<pre><code class=\"language-bash\">python cnn.py\n</code></pre>\n<ul>\n<li>程式會自動切割圖片並儲存至 <code>processed_images</code>。</li>\n<li>訓練完成後會生成 <code>digit_recognition_model.h5</code>。</li>\n</ul>\n<h3>3. 執行測試 (推論)</h3>\n<p>修改 <code>testModel.py</code> 中的 <code>test_image_path</code> 變數指向你想測試的圖片，然後執行：</p>\n<pre><code class=\"language-bash\">python testModel.py\n</code></pre>\n<ul>\n<li>將會跳出視窗顯示 5 張切割圖及其預測結果。</li>\n<li>Console 會印出最終辨識出的數字串。</li>\n</ul>\n<hr />\n<h2>設定說明 (Configuration)</h2>\n<p>本專案將設定直接寫於程式碼開頭的變數中，主要可調整項目如下：</p>\n<h3>cnn.py</h3>\n<pre><code class=\"language-python\">input_folder = &quot;dataset_folder&quot;      # 訓練資料來源\noutput_folder = &quot;processed_images&quot;   # 切割圖存檔區\nmodel_path = &quot;digit_recognition_model.h5&quot;\n# 切割參數 (位於 split_image 函式內)\nstart, end, num_slices = 7, 83, 5    # X 軸切割起始點與份數\n</code></pre>\n<h3>testModel.py</h3>\n<pre><code class=\"language-python\">test_image_path = &quot;...&quot;              # 指定要測試的圖片路徑\nrcParams['font.family'] = 'Microsoft JhengHei' # 圖表字型設定\n</code></pre>\n<hr />\n<h2>開發者指南 (Developer Guide)</h2>\n<h3>建議閱讀順序</h3>\n<ol>\n<li><strong><code>cnn.py</code> 圖像處理函式</strong>：理解 <code>split_image</code> 如何運作，這是資料正確性的關鍵。</li>\n<li><strong><code>cnn.py</code> 模型架構</strong>：目前的 CNN 為 2 層 Conv2D + 2 層 Dense，可視需求加深。</li>\n<li><strong><code>testModel.py</code></strong>：理解如何載入模型並對新資料進行相同的預處理。</li>\n</ol>\n<h3>修改注意事項</h3>\n<ul>\n<li><strong>切割座標 (Hardcoded Crops)</strong>：目前的切割範圍 <code>start=7, end=83</code> 是寫死的。若更換攝影機角度或圖片解析度改變，<strong>必須</strong>重新校正這些數值，否則數字會被切壞。</li>\n<li><strong>檔名依賴</strong>：訓練資料的 Label 來自檔名解析，請勿隨意更改訓練圖片的命名格式。</li>\n</ul>\n<hr />\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<h3>限制 (Limitations)</h3>\n<ol>\n<li><strong>固定解析度與位置</strong>：極度依賴輸入圖片的特定格式與數字位置，缺乏定位 (Localization) 機制（如 YOLO）。如果數字偏移，識別率會大幅下降。</li>\n<li><strong>訓練方式</strong>：目前採用「逐檔讀取 -&gt; 切割 -&gt; Fit」的迴路，而非標準的「準備好所有 Dataset -&gt; Model.fit」。若資料量變大，效率可能不佳。</li>\n</ol>\n<h3>待辦事項 (TODO)</h3>\n<ul>\n<li>[ ] 將切割參數 (<code>start</code>, <code>end</code>) 提取至設定檔，避免 Hardcode。</li>\n<li>[ ] 加入自動定位數字區域的功能 (由固定切割改為動態偵測)。</li>\n<li>[ ] 優化訓練 Pipeline，支援 Batch Loading 以提升訓練效率。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "CNN-Digit-Recognition-System", "generated_at": "2026-02-28T16:29:52.908445+00:00", "head": "5fe1b519bc13eeb9cc9a1752e0ccbda73b55c0df"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "dataset_folder", "children": [{"type": "file", "name": "20250219_075132_29545.jpg"}, {"type": "file", "name": "20250219_075133_38930.jpg"}, {"type": "file", "name": "20250219_075148_38378.jpg"}, {"type": "file", "name": "20250219_075156_19660.jpg"}, {"type": "file", "name": "20250219_075538_76590.jpg"}]}, {"type": "dir", "name": "processed_images", "children": [{"type": "file", "name": "0_20250219_075132_2.jpg"}, {"type": "file", "name": "0_20250219_075133_3.jpg"}, {"type": "file", "name": "0_20250219_075148_3.jpg"}, {"type": "file", "name": "0_20250219_075156_1.jpg"}, {"type": "file", "name": "0_20250219_075538_7.jpg"}]}, {"type": "dir", "name": "split_images", "children": [{"type": "file", "name": "0_20250219_082720_9.jpg"}, {"type": "file", "name": "1_20250219_082720_7.jpg"}, {"type": "file", "name": "2_20250219_082720_9.jpg"}, {"type": "file", "name": "3_20250219_082720_1.jpg"}, {"type": "file", "name": "4_20250219_082720_9.jpg"}]}, {"type": "file", "name": "20250219_082720_97919.jpg"}, {"type": "file", "name": "cnn.py"}, {"type": "file", "name": "digit_recognition_model.h5"}, {"type": "file", "name": "README.md"}, {"type": "file", "name": "testModel.py"}]}}, "gkwang4912__Educational-Data-Analysis-Project": {"readme": "<h1>教育數據分析專案 (Educational Data Analysis Project)</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案為一套針對教育場域數據的分析工具集，主要用於處理學生之學習歷程資料。\n- <strong>解決的問題</strong>：自動化處理大量的學生作答紀錄、學期成績數據以及影片學習行為日誌，將原始數據轉化為可視化的統計報表與行為轉移圖。\n- <strong>使用對象</strong>：教育研究者、教師或系統管理員。\n- <strong>專案性質</strong>：多模組數據分析腳本 (Data Analysis Scripts)。</p>\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統由三個獨立但互補的分析模組組成，核心依賴為 Python 數據科學生態系 (Pandas, NetworkX, Matplotlib)。系統讀取 Excel 格式的原始資料，經過清洗與運算後，輸出統計報表與視覺化圖表。</p>\n<p><strong>模組職責：</strong>\n1. <strong>作答分析模組</strong>：解析練習題作答字串，計算答對率與填答時間。\n2. <strong>成績比較模組</strong>：針對不同學校進行學科成績的統計比較 (平均、標準差、及格率)。\n3. <strong>行為分析模組</strong>：利用馬可夫鏈 (Markov Chain) 概念，分析學生在觀看教學影片時的操作行為轉移路徑。</p>\n<p>本專案已結案，其中所暴露的Token、API_KEY皆以失效，無需擔心</p>\n<pre><code class=\"language-mermaid\">graph TD\n    Input[原始資料 Excel] --&gt; |讀取| Scripts{Python 分析腳本}\n\n    subgraph Core_Modules [核心分析模組]\n        Scripts --&gt; |解析| M1[作答狀況分析]\n        Scripts --&gt; |統計| M2[學期成績比較]\n        Scripts --&gt; |建模| M3[影片行為轉移分析]\n    end\n\n    M1 --&gt; |Pandas/OpenPyXL| Out1[練習題統計報表 .xlsx]\n    M2 --&gt; |Pandas| Out2[學校分析結果 .xlsx]\n    M3 --&gt; |Pandas| Out3[行為轉移矩陣 .xlsx]\n\n    Out3 --&gt; |NetworkX/Matplotlib| Plot[繪圖模組]\n    Plot --&gt; Out4[行為轉移圖 .png]\n</code></pre>\n<h2>系統流程說明 (System Flow)</h2>\n<p>以下顯示三個主要功能的執行流程：</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start((開始)) --&gt; Choose{選擇功能}\n\n    %% 流程 1: 作答分析\n    Choose --&gt; |作答分析| P1[執行 練習題.py]\n    P1 --&gt; Read1[讀取 作答狀況.xlsx]\n    Read1 --&gt; Parse[解析作答字串 '1@XX@0...']\n    Parse --&gt; Calc1[計算每題正確率]\n    Calc1 --&gt; Export1[輸出 練習題.xlsx]\n\n    %% 流程 2: 成績分析\n    Choose --&gt; |成績比較| P2[執行 學校比較.py]\n    P2 --&gt; Read2[讀取 學期成績.xlsx]\n    Read2 --&gt; Group[依 學校代碼 分組]\n    Group --&gt; Stat[計算 平均/標準差/及格率]\n    Stat --&gt; Export2[輸出 學校分析結果.xlsx]\n\n    %% 流程 3: 行為分析\n    Choose --&gt; |行為分析| P3[執行 行為分析.py]\n    P3 --&gt; Read3[讀取 操作影片行為.xlsx]\n    Read3 --&gt; Clean[清洗時間戳記 &amp; 排序]\n    Clean --&gt; Matrix[計算行為轉移矩陣]\n    Matrix --&gt; Export3[輸出 轉移矩陣_各影片/]\n    Export3 --&gt; P4[執行 繪圖.py]\n    P4 --&gt; Draw[繪製 NetworkX 有向圖]\n    Draw --&gt; Export4[輸出 事件轉移圖_各影片/*.png]\n</code></pre>\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<p>本專案的主要程式碼位於 <code>期末成果/本地</code> 資料夾中。</p>\n<pre><code class=\"language-text\">Web-Programming/\n├── 期末成果/\n│   └── 本地/              &lt;-- 核心程式碼目錄\n│       ├── 1_作答狀況/\n│       │   ├── 練習題.py       # 分析練習題作答結果的主程式\n│       │   └── 作答狀況.xlsx    # 輸入資料範例\n│       ├── 2_學期成績/\n│       │   ├── 學校比較.py     # 比較各校成績的主程式\n│       │   └── 學期成績.xlsx    # 輸入資料範例\n│       └── 3_操作影片行為/\n│           ├── 行為分析.py     # 計算行為轉移矩陣的主程式\n│           ├── 繪圖.py        # 繪製行為流向圖的輔助程式\n│           ├── 操作影片行為.xlsx # 輸入資料範例\n│           ├── 轉移機率矩陣_各影片/ # (自動產生) 存放中間產出的 Excel 矩陣\n│           └── 事件轉移圖_各影片/   # (自動產生) 存放最終視覺化圖片\n└── README.md              # 本專案說明文件\n</code></pre>\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">檔案路徑</th>\n<th style=\"text-align: left;\">模組名稱</th>\n<th style=\"text-align: left;\">功能職責</th>\n<th style=\"text-align: left;\">關聯依賴</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>1_作答狀況/練習題.py</code></td>\n<td style=\"text-align: left;\">Quiz Analyzer</td>\n<td style=\"text-align: left;\">解析 <code>@XX@</code> 分隔的作答字串，產出各科與各題的答對率報表。</td>\n<td style=\"text-align: left;\"><code>pandas</code>, <code>openpyxl</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>2_學期成績/學校比較.py</code></td>\n<td style=\"text-align: left;\">School Comparator</td>\n<td style=\"text-align: left;\">清洗國英數三科成績，依學校代碼分組計算統計量。</td>\n<td style=\"text-align: left;\"><code>pandas</code>, <code>openpyxl</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>3_操作影片行為/行為分析.py</code></td>\n<td style=\"text-align: left;\">Behavior Modeler</td>\n<td style=\"text-align: left;\">追蹤影片操作序列 (如 Play -&gt; Pause)，計算下一動作的條件機率 (Transition Probability)。</td>\n<td style=\"text-align: left;\"><code>pandas</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>3_操作影片行為/繪圖.py</code></td>\n<td style=\"text-align: left;\">Graph Visualizer</td>\n<td style=\"text-align: left;\">讀取轉移矩陣，繪製節點 (行為) 與邊 (機率) 的有向圖。</td>\n<td style=\"text-align: left;\"><code>networkx</code>, <code>matplotlib</code></td>\n</tr>\n</tbody>\n</table>\n<pre><code class=\"language-mermaid\">classDiagram\n    direction RL\n    class BehaviorAnalysis {\n        Input: 操作影片行為.xlsx\n        Output: 轉移機率矩陣\n        +clean_data()\n        +calculate_transition_prob()\n    }\n    class GraphPlotter {\n        Input: 轉移機率矩陣\n        Output: .png Images\n        +build_digraph()\n        +draw_network()\n    }\n\n    BehaviorAnalysis ..&gt; GraphPlotter : 資料流向\n</code></pre>\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li><strong>OS</strong>: Windows / macOS / Linux</li>\n<li><strong>Python Version</strong>: Python 3.8+</li>\n</ul>\n<h3>相依套件</h3>\n<p>請確保安裝以下 Python 套件：</p>\n<pre><code class=\"language-bash\">pip install pandas openpyxl matplotlib networkx\n</code></pre>\n<h3>環境變數</h3>\n<ul>\n<li>本專案主要使用相對路徑讀取同一目錄下的 Excel 檔案，無需設定特殊環境變數。</li>\n</ul>\n<h2>使用方式 (How to Use)</h2>\n<h3>1. 分析作答狀況</h3>\n<p>進入對應資料夾並執行腳本：</p>\n<pre><code class=\"language-bash\">cd &quot;期末成果/本地/1_作答狀況&quot;\npython 練習題.py\n</code></pre>\n<blockquote>\n<p><strong>結果</strong>：產生 <code>練習題.xlsx</code>。</p>\n</blockquote>\n<h3>2. 分析學期成績</h3>\n<pre><code class=\"language-bash\">cd &quot;期末成果/本地/2_學期成績&quot;\npython 學校比較.py\n</code></pre>\n<blockquote>\n<p><strong>結果</strong>：產生 <code>學校分析結果.xlsx</code>。</p>\n</blockquote>\n<h3>3. 分析影片操作行為</h3>\n<p>步驟一：產生矩陣</p>\n<pre><code class=\"language-bash\">cd &quot;期末成果/本地/3_操作影片行為&quot;\npython 行為分析.py\n</code></pre>\n<blockquote>\n<p><strong>結果</strong>：於 <code>轉移機率矩陣_各影片/</code> 資料夾中產生多個 Excel 檔。</p>\n</blockquote>\n<p>步驟二：繪製圖表</p>\n<pre><code class=\"language-bash\">python 繪圖.py\n</code></pre>\n<blockquote>\n<p><strong>結果</strong>：於 <code>事件轉移圖_各影片/</code> 資料夾中產生 PNG 圖片。</p>\n</blockquote>\n<h2>設定說明 (Configuration)</h2>\n<p>本專案多數設定採 <strong>Hardcoded</strong> 方式直接寫於程式碼中，若需調整請修改 <code>.py</code> 檔：</p>\n<ul>\n<li><strong>輸入檔名</strong>：預設為 <code>作答狀況.xlsx</code>, <code>學期成績.xlsx</code> 等，需至各 script 開頭修改 <code>pd.read_excel()</code> 的路徑。</li>\n<li><strong>及格標準</strong>：<code>學校比較.py</code> 中預設 <code>pass_score = 60</code>。</li>\n<li><strong>作答分隔符</strong>：<code>練習題.py</code> 中預設使用 <code>@XX@</code> 作為切割符號。</li>\n<li><strong>繪圖參數</strong>：<code>繪圖.py</code> 中可調整 <code>figsize</code> (圖片大小) 或 <code>k</code> (Spring Layout 彈力係數)。</li>\n</ul>\n<h2>開發者指南 (Developer Guide)</h2>\n<ol>\n<li><strong>建議閱讀順序</strong>：</li>\n<li>先閱讀 <code>練習題.py</code> 理解基礎的 Pandas 資料清洗邏輯。</li>\n<li>再閱讀 <code>行為分析.py</code> 理解如何處理時間序列數據。</li>\n<li>\n<p>最後研究 <code>繪圖.py</code> 學習 NetworkX 的圖形繪製。</p>\n</li>\n<li>\n<p><strong>修改注意事項</strong>：</p>\n</li>\n<li>修改 Excel 輸出格式時，請保留 <code>openpyxl</code> 的欄寬自動調整程式碼，以維持報表可讀性。</li>\n<li><code>繪圖.py</code> 依賴 <code>行為分析.py</code> 的輸出檔名格式與欄位結構，修改前者時需同步測試後者。</li>\n</ol>\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<ul>\n<li><strong>路徑限制</strong>：程式碼使用相對路徑，必須在該 <code>.py</code> 檔案所在目錄下執行指令，否則會找不到 Excel 檔。</li>\n<li><strong>資料格式依賴</strong>：對 Excel 欄位名稱高度依賴 (如 \"影片瀏覽流水號\", \"執行影片操作的時間戳記\")，欄位更名會導致程式錯誤。</li>\n<li><strong>字型問題</strong>：<code>Matplotlib</code> 繪圖時若遇中文標籤，在無適當字型設定的環境下可能會顯示亂碼 (豆腐塊)。</li>\n</ul>\n<h2>補充說明 (Notes)</h2>\n<ul>\n<li><code>三種分析程式.txt</code> 紀錄了相關 Web 服務的部署 URL (例如 <code>analyze-behavior</code> 等)，可能為本機分析腳本的雲端版本或前端介面。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "Educational-Data-Analysis-Project", "generated_at": "2026-02-28T16:29:52.918319+00:00", "head": "8c790dbeae56863192d31cde8e0c5800e11e1ac6"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"\\346\\234\\200\\347\\265\\202\\346\\210\\220\\346\\236\\234", "children": [{"type": "dir", "name": "\\345\\211\\215\\347\\253\\257\\347\\266\\262\\351\\240\\201\\345\\216\\237\\345\\247\\213\\347\\242\\274", "children": [{"type": "dir", "name": "css", "children": [{"type": "file", "name": "style.css\""}]}, {"type": "dir", "name": "js", "children": [{"type": "file", "name": "script.js\""}]}, {"type": "file", "name": "dashboard.html\""}]}, {"type": "dir", "name": "\\345\\276\\214\\347\\253\\257\\346\\234\\215\\345\\213\\231\\347\\250\\213\\345\\274\\217", "children": [{"type": "dir", "name": "analyze_behavior", "children": [{"type": "file", "name": "analyze_behavior.py\""}, {"type": "file", "name": "Dockerfile\""}, {"type": "file", "name": "requirements.txt\""}]}, {"type": "dir", "name": "analyze_practice", "children": [{"type": "file", "name": "analyze_practice.py\""}, {"type": "file", "name": "Dockerfile\""}, {"type": "file", "name": "requirements.txt\""}]}, {"type": "dir", "name": "analyze_school", "children": [{"type": "file", "name": "analyze_school.py\""}, {"type": "file", "name": "Dockerfile\""}, {"type": "file", "name": "requirements.txt\""}]}, {"type": "dir", "name": "loadAnalyze", "children": [{"type": "file", "name": "app.py\""}, {"type": "file", "name": "Dockerfile\""}, {"type": "file", "name": "requirements.txt\""}]}]}, {"type": "file", "name": "\\346\\234\\237\\346\\234\\253\\347\\260\\241\\345\\240\\261.pdf\""}, {"type": "file", "name": "\\347\\266\\262\\347\\253\\231\\351\\200\\243\\347\\265\\220.docx\""}]}, {"type": "dir", "name": "\"\\346\\234\\237\\344\\270\\255\\345\\240\\261\\345\\221\\212", "children": [{"type": "file", "name": "\\346\\234\\237\\344\\270\\255\\345\\240\\261\\345\\221\\212.pdf\""}, {"type": "file", "name": "\\346\\234\\237\\344\\270\\255\\345\\240\\261\\345\\221\\212.pptx\""}, {"type": "file", "name": "\\346\\234\\237\\344\\270\\255\\345\\240\\261\\345\\221\\212.txt\""}]}, {"type": "dir", "name": "\"\\346\\234\\237\\346\\234\\253\\346\\210\\220\\346\\236\\234", "children": [{"type": "dir", "name": "\\346\\234\\254\\345\\234\\260", "children": [{"type": "dir", "name": "1_\\344\\275\\234\\347\\255\\224\\347\\213\\200\\346\\263\\201", "children": [{"type": "file", "name": "\\344\\275\\234\\347\\255\\224\\347\\213\\200\\346\\263\\201.xlsx\""}, {"type": "file", "name": "\\347\\267\\264\\347\\277\\222\\351\\241\\214.py\""}, {"type": "file", "name": "\\347\\267\\264\\347\\277\\222\\351\\241\\214.xlsx\""}]}, {"type": "dir", "name": "2_\\345\\255\\270\\346\\234\\237\\346\\210\\220\\347\\270\\276", "children": [{"type": "file", "name": "\\345\\255\\270\\346\\240\\241\\345\\210\\206\\346\\236\\220\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "\\345\\255\\270\\346\\240\\241\\346\\257\\224\\350\\274\\203.py\""}]}, {"type": "dir", "name": "3_\\346\\223\\215\\344\\275\\234\\345\\275\\261\\347\\211\\207\\350\\241\\214\\347\\202\\272", "children": [{"type": "dir", "name": "\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226_\\345\\220\\204\\345\\275\\261\\347\\211\\207", "children": [{"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932045_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932104_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97967614_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97968472_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97978630_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.png\""}]}, {"type": "dir", "name": "\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243_\\345\\220\\204\\345\\275\\261\\347\\211\\207", "children": [{"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932045_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932104_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97967614_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97968472_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97978630_\\350\\275\\211\\347\\247\\273\\346\\251\\237\\347\\216\\207\\347\\237\\251\\351\\231\\243.xlsx\""}]}, {"type": "file", "name": "\\347\\271\\252\\345\\234\\226.py\""}, {"type": "file", "name": "\\350\\241\\214\\347\\202\\272\\345\\210\\206\\346\\236\\220.py\""}]}]}, {"type": "dir", "name": "\\350\\263\\207\\346\\226\\231\\344\\270\\212\\345\\202\\263", "children": [{"type": "file", "name": "1_\\345\\255\\270\\346\\240\\241\\345\\210\\206\\346\\236\\220\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "2_\\347\\267\\264\\347\\277\\222\\351\\241\\214.xlsx\""}, {"type": "file", "name": "3_\\345\\275\\261\\347\\211\\207\\346\\223\\215\\344\\275\\234\\350\\275\\211\\347\\247\\273\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\344\\275\\234\\347\\255\\224\\347\\213\\200\\346\\263\\201.xlsx\""}, {"type": "file", "name": "upload.py\""}]}, {"type": "dir", "name": "\\351\\233\\262\\347\\253\\257\\350\\263\\207\\346\\226\\231", "children": [{"type": "dir", "name": "1_\\344\\275\\234\\347\\255\\224\\347\\213\\200\\346\\263\\201", "children": [{"type": "file", "name": "\\347\\267\\264\\347\\277\\222\\351\\241\\214.py\""}, {"type": "file", "name": "\\347\\267\\264\\347\\277\\222\\351\\241\\214.xlsx\""}]}, {"type": "dir", "name": "2_\\345\\255\\270\\346\\234\\237\\346\\210\\220\\347\\270\\276", "children": [{"type": "file", "name": "\\345\\255\\270\\346\\240\\241\\345\\210\\206\\346\\236\\220\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "\\345\\255\\270\\346\\240\\241\\346\\257\\224\\350\\274\\203.py\""}]}, {"type": "dir", "name": "3_\\346\\223\\215\\344\\275\\234\\345\\275\\261\\347\\211\\207\\350\\241\\214\\347\\202\\272", "children": [{"type": "dir", "name": "\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226_\\345\\220\\204\\345\\275\\261\\347\\211\\207", "children": [{"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932045_\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97932104_\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97967614_\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97968472_\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226.png\""}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207_97978630_\\344\\272\\213\\344\\273\\266\\350\\275\\211\\347\\247\\273\\345\\234\\226.png\""}]}, {"type": "file", "name": "\\345\\275\\261\\347\\211\\207\\346\\223\\215\\344\\275\\234\\350\\275\\211\\347\\247\\273\\347\\237\\251\\351\\231\\243.xlsx\""}, {"type": "file", "name": "\\347\\271\\252\\345\\234\\226.py\""}, {"type": "file", "name": "\\350\\241\\214\\347\\202\\272\\345\\210\\206\\346\\236\\220.py\""}]}]}, {"type": "file", "name": "\\346\\265\\201\\347\\250\\213\\345\\234\\226.drawio\""}, {"type": "file", "name": "\\346\\265\\201\\347\\250\\213\\345\\234\\226.png\""}]}, {"type": "dir", "name": "\"\\347\\266\\262\\351\\240\\201", "children": [{"type": "file", "name": "dashboard.html\""}]}, {"type": "file", "name": "\"\\344\\270\\211\\347\\250\\256\\345\\210\\206\\346\\236\\220\\347\\250\\213\\345\\274\\217.txt\""}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__Multimodal-video-analysis-and-RAG-retrieval-system": {"readme": "<h1>Multimodal Video Analysis and RAG Retrieval System</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案是一個整合 <strong>多模態影片分析 (Multimodal Video Analysis)</strong> 與 <strong>檢索增強生成 (RAG, Retrieval-Augmented Generation)</strong> 的智慧問答系統。</p>\n<ul>\n<li><strong>專案用途</strong>: 自動化處理長影片，提取關鍵視覺與聽覺資訊，並允許使用者透過自然語言進行內容檢索與問答。</li>\n<li><strong>解決的問題</strong>: 解決傳統影片搜尋僅能針對標題或標籤，無法深入影片內容（如特定對話、畫面細節）進行精確檢索的問題。</li>\n<li><strong>使用對象</strong>: 需快速檢索大量影片內容的研究人員、媒體工作者或檔案管理員。</li>\n<li><strong>專案性質</strong>: Full-stack Application (Python Backend Services + Flask Web App).</li>\n</ul>\n<hr />\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統採用模組化設計，分為 <strong>資料處理管線 (Data Pipeline)</strong> 與 <strong>應用服務層 (Application Layer)</strong>。</p>\n<ul>\n<li><strong>資料處理管線</strong>: 負責非同步處理影片，包含電腦視覺分析 (TransNetV2, YOLOv8) 與語音轉錄 (Whisper)。</li>\n<li><strong>向量資料庫</strong>: 使用 FAISS 儲存 High-dimensional Embeddings (CLIP)，SQLite 儲存 Metadata。</li>\n<li><strong>應用服務</strong>: Flask 提供 RESTful API 與 Web UI，整合 LM Studio 進行大型語言模型推論。</li>\n</ul>\n<pre><code class=\"language-mermaid\">graph TD\n    User[&quot;使用者 (Browser)&quot;] &lt;--&gt; WebUI[&quot;Web Interface (Flask)&quot;]\n\n    subgraph &quot;Application Layer&quot;\n        WebUI &lt;--&gt; Server[server.py]\n        Server &lt;--&gt; QueryEngine[rag_query.py]\n    end\n\n    subgraph &quot;Data Storage&quot;\n        QueryEngine &lt;--&gt; FAISS[(&quot;FAISS Index&quot;)]\n        QueryEngine &lt;--&gt; SQLite[(&quot;SQLite Metadata&quot;)]\n    end\n\n    subgraph &quot;External AI Services&quot;\n        QueryEngine &lt;--&gt; LMStudio[&quot;LM Studio API&quot;]\n        DataPipeline --&gt; CLIP[&quot;CLIP Processor&quot;]\n    end\n\n    subgraph &quot;Data Processing Pipeline (Offline)&quot;\n        VideoFile[&quot;Video File (.mp4)&quot;] --&gt; Stage1[&quot;1. Visual Analysis&quot;]\n        VideoFile --&gt; Stage2[&quot;2. Audio Transcription&quot;]\n        Stage1 &amp; Stage2 --&gt; Stage3[&quot;3. Alignment &amp; Screenshot&quot;]\n        Stage3 --&gt; Stage5[&quot;5. RAG Ingestion&quot;]\n        Stage5 --&gt; FAISS\n        Stage5 --&gt; SQLite\n    end\n</code></pre>\n<hr />\n<h2>系統流程說明 (System Flow)</h2>\n<p>系統運作分為 <strong>離線建立索引 (Indexing Phase)</strong> 與 <strong>線上檢索 (Query Phase)</strong> 兩大階段。</p>\n<h3>1. 離線處理流程 (Indexing)</h3>\n<pre><code class=\"language-mermaid\">flowchart LR\n    Start[&quot;Input Video&quot;] --&gt; A[analyze.py]\n    Start --&gt; B[transcribe.py]\n\n    subgraph &quot;Visual Analysis&quot;\n    A --&gt;|TransNetV2| Scenes[&quot;Scene Cuts&quot;]\n    A --&gt;|YOLOv8| Objects[&quot;Object Events&quot;]\n    end\n\n    subgraph &quot;Audio Analysis&quot;\n    B --&gt;|Whisper| Text[&quot;Transcript CSV&quot;]\n    end\n\n    Scenes &amp; Objects &amp; Text --&gt; C[extract_screenshots.py]\n    C --&gt;|Time Mapping| D[&quot;Aligned Captions &amp; Images&quot;]\n\n    D --&gt; E[rag_ingest.py]\n    E --&gt;|CLIP Encoding| F[&quot;Vector DB (FAISS) + Metadata (SQLite)&quot;]\n</code></pre>\n<h3>2. 線上檢索流程 (Query)</h3>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant User\n    participant WebUI\n    participant Server\n    participant DB as FAISS/SQLite\n    participant LLM as LM Studio\n\n    User-&gt;&gt;WebUI: 輸入問題 (e.g., &quot;太空人在做什麼?&quot;)\n    WebUI-&gt;&gt;Server: POST /api/chat\n    Server-&gt;&gt;DB: 1. 搜尋相關文字 (Text Embeddings)\n    Server-&gt;&gt;DB: 2. 搜尋相關圖片 (Image Embeddings)\n    DB--&gt;&gt;Server: 返回 Top-K 文字與圖片路徑\n    Server-&gt;&gt;LLM: 3. 建構 Prompt (包含問題 + 檢索到的上下文 + 圖片)\n    LLM--&gt;&gt;Server: 生成回答\n    Server--&gt;&gt;WebUI: 返回 JSON (Answer + Source Metadata)\n    WebUI--&gt;&gt;User: 顯示回答與參考畫面\n</code></pre>\n<hr />\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<pre><code>Project Root\n├── 1_關鍵偵擷取/              # [視覺模組] 影片切割與物件偵測\n│   ├── analyze.py           # 主程式：整合 TransNetV2 與 YOLOv8\n│   ├── TransNetV2/          # (依賴) 場景偵測模型\n│   └── keyframes/           # (產出) 偵測到的關鍵影格圖片\n│\n├── 2_逐字稿擷取/              # [語音模組] 影片轉文字\n│   ├── transcribe.py        # 主程式：呼叫 OpenAI Whisper\n│   └── transcript.csv       # (產出) 包含時間戳記的逐字稿\n│\n├── 3_逐字稿圖片擷取/          # [整合模組] 圖文對齊\n│   ├── extract_screenshots.py # 主程式：依據 transcript 時間擷取圖片\n│   └── screenshots/         # (產出) 對應每一句對話的截圖\n│\n├── 5_RAG_database/          # [檢索模組] RAG 核心與網頁伺服器\n│   ├── input/               # [資料源] 需手動匯集前述步驟的產出至此\n│   ├── rag_ingest.py        # 建置程式：讀取 input/ 建立向量索引\n│   ├── rag_query.py         # 檢索核心：負責搜尋 FAISS 與呼叫 LLM\n│   ├── server.py            # 網頁後端：Flask Entry Point\n│   ├── static/              # 前端靜態資源 (CSS, JS)\n│   ├── templates/           # 前端 HTML 樣板\n│   ├── rag_mm.db            # (產出) SQLite 資料庫\n│   └── *.index              # (產出) FAISS 向量索引檔\n│\n└── README.md                # 專案說明文件\n</code></pre>\n<hr />\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">檔案名稱</th>\n<th style=\"text-align: left;\">所屬模組</th>\n<th style=\"text-align: left;\">職責 (Responsibility)</th>\n<th style=\"text-align: left;\">依賴關係</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>analyze.py</strong></td>\n<td style=\"text-align: left;\">關鍵偵擷取</td>\n<td style=\"text-align: left;\">執行 TransNetV2 偵測場景切換，執行 YOLOv8 追蹤物件。輸出 CSV 報告與關鍵影格。</td>\n<td style=\"text-align: left;\"><code>tensorflow</code>, <code>ultralytics</code>, <code>ffmpeg-python</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>transcribe.py</strong></td>\n<td style=\"text-align: left;\">逐字稿擷取</td>\n<td style=\"text-align: left;\">載入 Whisper 模型將音訊轉為帶時間戳的文字。</td>\n<td style=\"text-align: left;\"><code>openai-whisper</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>extract_screenshots.py</strong></td>\n<td style=\"text-align: left;\">整合模組</td>\n<td style=\"text-align: left;\">讀取 <code>transcript.csv</code>，利用 OpenCV 依據 <code>Start/End Time</code> 從影片截圖。</td>\n<td style=\"text-align: left;\"><code>opencv-python</code>, <code>pandas</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>rag_ingest.py</strong></td>\n<td style=\"text-align: left;\">RAG 資料庫</td>\n<td style=\"text-align: left;\">讀取圖像與文字，使用 CLIP 模型計算 Embeddings，寫入 FAISS 與 SQLite。</td>\n<td style=\"text-align: left;\"><code>transformers</code>, <code>faiss-cpu</code>, <code>torch</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>rag_query.py</strong></td>\n<td style=\"text-align: left;\">RAG 資料庫</td>\n<td style=\"text-align: left;\">提供 <code>query_rag_api</code> 函數。執行向量相似度搜尋，並封裝 Context 發送給 LM Studio。</td>\n<td style=\"text-align: left;\"><code>openai</code>, <code>faiss-cpu</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>server.py</strong></td>\n<td style=\"text-align: left;\">Web 介面</td>\n<td style=\"text-align: left;\">Flask Server，提供 API Endpoints 與渲染前端頁面。</td>\n<td style=\"text-align: left;\"><code>flask</code></td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li><strong>OS</strong>: Windows 10/11 (本專案路徑結構基於 Windows)</li>\n<li><strong>Python</strong>: 3.8 ~ 3.10</li>\n<li><strong>GPU (Optional)</strong>: 強烈建議使用 NVIDIA GPU 加速 Whisper 與 Embedding 計算。</li>\n</ul>\n<h3>外部依賴</h3>\n<ol>\n<li><strong>FFmpeg</strong>: 必須安裝並加入系統 PATH。</li>\n<li><strong>LM Studio</strong>: 必須安裝並運行 Local Inference Server。<ul>\n<li><strong>Model</strong>: 建議使用 Vision-Language Model (如 <code>Qwen2-VL</code>, <code>LLaVA</code>)。</li>\n<li><strong>Port</strong>: 預設 <code>1234</code>。</li>\n</ul>\n</li>\n</ol>\n<h3>Python 套件安裝</h3>\n<pre><code class=\"language-bash\">pip install -r requirements.txt\n# 或手動安裝核心套件：\npip install openai-whisper ultralytics opencv-python pandas numpy tqdm flask faiss-cpu transformers torch pillow ffmpeg-python openai\n</code></pre>\n<p><em>(註: 若使用 GPU，請將 <code>faiss-cpu</code> 替換為 <code>faiss-gpu</code>，並安裝對應 CUDA 版本的 PyTorch)</em></p>\n<hr />\n<h2>使用方式 (How to Use)</h2>\n<p>本系統設計為<strong>依序執行 (Sequential Execution)</strong>。假設您的來源影片為 <code>test.mp4</code>。</p>\n<h3>Phase 1: 資料前處理 (Data Preprocessing)</h3>\n<ol>\n<li><strong>視覺分析</strong>:\n    <code>bash\n    cd 1_關鍵偵擷取\n    # 放入 test.mp4\n    python analyze.py test.mp4</code></li>\n<li><strong>語音轉錄</strong>:\n    <code>bash\n    cd ../2_逐字稿擷取\n    # 放入/參照 test.mp4\n    python transcribe.py</code></li>\n<li><strong>圖文對齊</strong>:\n    <code>bash\n    cd ../3_逐字稿圖片擷取\n    # 需有 test.mp4 與 transcript.csv\n    python extract_screenshots.py</code></li>\n</ol>\n<h3>Phase 2: RAG 系統建置 (RAG Setup)</h3>\n<ol>\n<li><strong>資料彙整</strong>:<ul>\n<li>將步驟 1 產出的 <code>keyframes/</code> 圖片</li>\n<li>將步驟 3 產出的 <code>screenshots/</code> 圖片與 <code>transcript.csv</code></li>\n<li>全部複製到 <code>5_RAG_database/input/</code> 資料夾中。</li>\n</ul>\n</li>\n<li><strong>建立索引</strong>:\n    <code>bash\n    cd ../5_RAG_database\n    python rag_ingest.py</code></li>\n</ol>\n<h3>Phase 3: 啟動服務 (Start Server)</h3>\n<ol>\n<li>開啟 <strong>LM Studio</strong>，Start Server (Port 1234)。</li>\n<li>啟動 Flask App:\n    <code>bash\n    python server.py</code></li>\n<li>瀏覽器開啟 <code>http://127.0.0.1:5000</code> 即可開始問答。</li>\n</ol>\n<hr />\n<h2>設定說明 (Configuration)</h2>\n<p>主要設定位於各 Python 腳本的開頭全域變數區塊：</p>\n<ul>\n<li><strong><code>5_RAG_database/rag_query.py</code></strong>:<ul>\n<li><code>LM_STUDIO_URL</code>: LLM API 地址 (預設 <code>http://127.0.0.1:1234/v1</code>)</li>\n<li><code>CLIP_MODEL_NAME</code>: 使用的 Embedding 模型 (預設 <code>openai/clip-vit-base-patch32</code>)</li>\n<li><code>TOP_K_TEXT</code> / <code>TOP_K_IMAGE</code>: 檢索返回的筆數。</li>\n</ul>\n</li>\n<li><strong><code>2_逐字稿擷取/transcribe.py</code></strong>:<ul>\n<li><code>model = whisper.load_model(\"large\")</code>: 可改為 <code>medium</code> 或 <code>small</code> 以節省資源。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2>開發者指南 (Developer Guide)</h2>\n<h3>建議閱讀順序</h3>\n<ol>\n<li><strong><code>rag_ingest.py</code></strong>: 理解資料如何被向量化與儲存 (資料結構核心)。</li>\n<li><strong><code>rag_query.py</code></strong>: 理解檢索邏輯與 Prompt Engineering (應用核心)。</li>\n<li><strong><code>analyze.py</code></strong>: 理解非結構化影像資料的處理來源。</li>\n</ol>\n<h3>擴充建議</h3>\n<ul>\n<li><strong>更換 Vector DB</strong>: 目前使用本地 FAISS 檔案索引，若資料量大可升級為 ChromaDB 或 Qdrant。</li>\n<li><strong>多影片支援</strong>: 目前流程針對單一影片設計 (<code>test.mp4</code>)。若要支援多影片，需修改 <code>ingest</code> 邏輯以在 Metadata 中區分 Video ID。</li>\n</ul>\n<hr />\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<ul>\n<li><strong>[Limitation] 單一影片流程</strong>: 腳本目前高度耦合於單一 <code>test.mp4</code> 檔名，批次處理需手動介入。</li>\n<li><strong>[Limitation] 本地路徑相依</strong>: 部分程式碼 (如 <code>analyze.py</code>) 寫死了 conda library 路徑 (<code>C:\\Users\\ASUS\\miniconda3...</code>)，在其他機器需修改。</li>\n<li><strong>[TODO] 自動化 Pipeline</strong>: 目前步驟 1~5 需手動執行與複製檔案，建議撰寫 <code>run_all.bat</code> 或 <code>main.py</code> 串接全流程。</li>\n<li><strong>[TODO] 錯誤處理</strong>: 目前若 LM Studio 未開啟，Server 會直接報錯，需增加優雅的連線重試機制。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "Multimodal-video-analysis-and-RAG-retrieval-system", "generated_at": "2026-02-28T16:29:52.934638+00:00", "head": "88bd64c108c50e2a36c4906bad45d2b2905d2ee0"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"1_\\351\\227\\234\\351\\215\\265\\345\\201\\265\\346\\223\\267\\345\\217\\226", "children": [{"type": "dir", "name": "keyframes", "children": [{"type": "file", "name": "frame_000000_Scene_Cut.jpg\""}, {"type": "file", "name": "frame_001184_Scene_Cut.jpg\""}, {"type": "file", "name": "frame_001185_Object_Appeared.jpg\""}, {"type": "file", "name": "frame_003078_Object_Appeared.jpg\""}, {"type": "file", "name": "frame_011983_Scene_Cut.jpg\""}]}, {"type": "file", "name": "analyze.py\""}, {"type": "file", "name": "requirements.txt\""}, {"type": "file", "name": "test.mp4\""}, {"type": "file", "name": "test_analysis.csv\""}, {"type": "file", "name": "yolov8n.pt\""}]}, {"type": "dir", "name": "\"2_\\351\\200\\220\\345\\255\\227\\347\\250\\277\\346\\223\\267\\345\\217\\226", "children": [{"type": "file", "name": "test.mp4\""}, {"type": "file", "name": "transcribe.py\""}, {"type": "file", "name": "transcript.csv\""}]}, {"type": "dir", "name": "\"3_\\351\\200\\220\\345\\255\\227\\347\\250\\277\\345\\234\\226\\347\\211\\207\\346\\223\\267\\345\\217\\226", "children": [{"type": "dir", "name": "screenshots", "children": [{"type": "file", "name": "img_100_end.jpg\""}, {"type": "file", "name": "img_100_start.jpg\""}, {"type": "file", "name": "img_101_end.jpg\""}, {"type": "file", "name": "img_101_start.jpg\""}, {"type": "file", "name": "img_102_end.jpg\""}, {"type": "file", "name": "img_102_start.jpg\""}, {"type": "file", "name": "img_103_end.jpg\""}, {"type": "file", "name": "img_103_start.jpg\""}, {"type": "file", "name": "img_104_end.jpg\""}, {"type": "file", "name": "img_104_start.jpg\""}, {"type": "file", "name": "img_105_end.jpg\""}, {"type": "file", "name": "img_105_start.jpg\""}, {"type": "file", "name": "img_106_end.jpg\""}, {"type": "file", "name": "img_106_start.jpg\""}, {"type": "file", "name": "img_107_end.jpg\""}, {"type": "file", "name": "img_107_start.jpg\""}, {"type": "file", "name": "img_108_end.jpg\""}, {"type": "file", "name": "img_108_start.jpg\""}, {"type": "file", "name": "img_109_end.jpg\""}, {"type": "file", "name": "img_109_start.jpg\""}, {"type": "file", "name": "img_10_end.jpg\""}, {"type": "file", "name": "img_10_start.jpg\""}, {"type": "file", "name": "img_110_end.jpg\""}, {"type": "file", "name": "img_110_start.jpg\""}, {"type": "file", "name": "img_111_end.jpg\""}, {"type": "file", "name": "img_111_start.jpg\""}, {"type": "file", "name": "img_112_end.jpg\""}, {"type": "file", "name": "img_112_start.jpg\""}, {"type": "file", "name": "img_113_end.jpg\""}, {"type": "file", "name": "img_113_start.jpg\""}, {"type": "file", "name": "img_114_end.jpg\""}, {"type": "file", "name": "img_114_start.jpg\""}, {"type": "file", "name": "img_115_end.jpg\""}, {"type": "file", "name": "img_115_start.jpg\""}, {"type": "file", "name": "img_116_end.jpg\""}, {"type": "file", "name": "img_116_start.jpg\""}, {"type": "file", "name": "img_117_end.jpg\""}, {"type": "file", "name": "img_117_start.jpg\""}, {"type": "file", "name": "img_118_end.jpg\""}, {"type": "file", "name": "img_118_start.jpg\""}, {"type": "file", "name": "img_119_end.jpg\""}, {"type": "file", "name": "img_119_start.jpg\""}, {"type": "file", "name": "img_11_end.jpg\""}, {"type": "file", "name": "img_11_start.jpg\""}, {"type": "file", "name": "img_120_end.jpg\""}, {"type": "file", "name": "img_120_start.jpg\""}, {"type": "file", "name": "img_121_end.jpg\""}, {"type": "file", "name": "img_121_start.jpg\""}, {"type": "file", "name": "img_122_end.jpg\""}, {"type": "file", "name": "img_122_start.jpg\""}, {"type": "file", "name": "img_123_end.jpg\""}, {"type": "file", "name": "img_123_start.jpg\""}, {"type": "file", "name": "img_124_end.jpg\""}, {"type": "file", "name": "img_124_start.jpg\""}, {"type": "file", "name": "img_125_end.jpg\""}, {"type": "file", "name": "img_125_start.jpg\""}, {"type": "file", "name": "img_126_end.jpg\""}, {"type": "file", "name": "img_126_start.jpg\""}, {"type": "file", "name": "img_127_end.jpg\""}, {"type": "file", "name": "img_127_start.jpg\""}, {"type": "file", "name": "img_128_end.jpg\""}, {"type": "file", "name": "img_128_start.jpg\""}, {"type": "file", "name": "img_129_end.jpg\""}, {"type": "file", "name": "img_129_start.jpg\""}, {"type": "file", "name": "img_12_end.jpg\""}, {"type": "file", "name": "img_12_start.jpg\""}, {"type": "file", "name": "img_130_end.jpg\""}, {"type": "file", "name": "img_130_start.jpg\""}, {"type": "file", "name": "img_131_end.jpg\""}, {"type": "file", "name": "img_131_start.jpg\""}, {"type": "file", "name": "img_132_end.jpg\""}, {"type": "file", "name": "img_132_start.jpg\""}, {"type": "file", "name": "img_133_end.jpg\""}, {"type": "file", "name": "img_133_start.jpg\""}, {"type": "file", "name": "img_134_end.jpg\""}, {"type": "file", "name": "img_134_start.jpg\""}, {"type": "file", "name": "img_135_end.jpg\""}, {"type": "file", "name": "img_135_start.jpg\""}, {"type": "file", "name": "img_136_end.jpg\""}, {"type": "file", "name": "img_136_start.jpg\""}, {"type": "file", "name": "img_137_end.jpg\""}, {"type": "file", "name": "img_137_start.jpg\""}, {"type": "file", "name": "img_138_end.jpg\""}, {"type": "file", "name": "img_138_start.jpg\""}, {"type": "file", "name": "img_139_end.jpg\""}, {"type": "file", "name": "img_139_start.jpg\""}, {"type": "file", "name": "img_13_end.jpg\""}, {"type": "file", "name": "img_13_start.jpg\""}, {"type": "file", "name": "img_140_end.jpg\""}, {"type": "file", "name": "img_140_start.jpg\""}, {"type": "file", "name": "img_141_end.jpg\""}, {"type": "file", "name": "img_141_start.jpg\""}, {"type": "file", "name": "img_142_end.jpg\""}, {"type": "file", "name": "img_142_start.jpg\""}, {"type": "file", "name": "img_143_end.jpg\""}, {"type": "file", "name": "img_143_start.jpg\""}, {"type": "file", "name": "img_144_end.jpg\""}, {"type": "file", "name": "img_144_start.jpg\""}, {"type": "file", "name": "img_145_end.jpg\""}, {"type": "file", "name": "img_145_start.jpg\""}, {"type": "file", "name": "img_146_end.jpg\""}, {"type": "file", "name": "img_146_start.jpg\""}, {"type": "file", "name": "img_147_end.jpg\""}, {"type": "file", "name": "img_147_start.jpg\""}, {"type": "file", "name": "img_148_end.jpg\""}, {"type": "file", "name": "img_148_start.jpg\""}, {"type": "file", "name": "img_149_end.jpg\""}, {"type": "file", "name": "img_149_start.jpg\""}, {"type": "file", "name": "img_14_end.jpg\""}, {"type": "file", "name": "img_14_start.jpg\""}, {"type": "file", "name": "img_150_end.jpg\""}, {"type": "file", "name": "img_150_start.jpg\""}, {"type": "file", "name": "img_151_end.jpg\""}, {"type": "file", "name": "img_151_start.jpg\""}, {"type": "file", "name": "img_152_end.jpg\""}, {"type": "file", "name": "img_152_start.jpg\""}, {"type": "file", "name": "img_153_end.jpg\""}, {"type": "file", "name": "img_153_start.jpg\""}, {"type": "file", "name": "img_154_end.jpg\""}, {"type": "file", "name": "img_154_start.jpg\""}, {"type": "file", "name": "img_155_end.jpg\""}, {"type": "file", "name": "img_155_start.jpg\""}, {"type": "file", "name": "img_156_end.jpg\""}, {"type": "file", "name": "img_156_start.jpg\""}, {"type": "file", "name": "img_157_end.jpg\""}, {"type": "file", "name": "img_157_start.jpg\""}, {"type": "file", "name": "img_158_end.jpg\""}, {"type": "file", "name": "img_158_start.jpg\""}, {"type": "file", "name": "img_159_end.jpg\""}, {"type": "file", "name": "img_159_start.jpg\""}, {"type": "file", "name": "img_15_end.jpg\""}, {"type": "file", "name": "img_15_start.jpg\""}, {"type": "file", "name": "img_160_end.jpg\""}, {"type": "file", "name": "img_160_start.jpg\""}, {"type": "file", "name": "img_161_end.jpg\""}, {"type": "file", "name": "img_161_start.jpg\""}, {"type": "file", "name": "img_162_end.jpg\""}, {"type": "file", "name": "img_162_start.jpg\""}, {"type": "file", "name": "img_163_end.jpg\""}, {"type": "file", "name": "img_163_start.jpg\""}, {"type": "file", "name": "img_164_end.jpg\""}, {"type": "file", "name": "img_164_start.jpg\""}, {"type": "file", "name": "img_165_end.jpg\""}, {"type": "file", "name": "img_165_start.jpg\""}, {"type": "file", "name": "img_166_end.jpg\""}, {"type": "file", "name": "img_166_start.jpg\""}, {"type": "file", "name": "img_167_end.jpg\""}, {"type": "file", "name": "img_167_start.jpg\""}, {"type": "file", "name": "img_168_end.jpg\""}, {"type": "file", "name": "img_168_start.jpg\""}, {"type": "file", "name": "img_169_end.jpg\""}, {"type": "file", "name": "img_169_start.jpg\""}, {"type": "file", "name": "img_16_end.jpg\""}, {"type": "file", "name": "img_16_start.jpg\""}, {"type": "file", "name": "img_170_end.jpg\""}, {"type": "file", "name": "img_170_start.jpg\""}, {"type": "file", "name": "img_171_end.jpg\""}, {"type": "file", "name": "img_171_start.jpg\""}, {"type": "file", "name": "img_172_end.jpg\""}, {"type": "file", "name": "img_172_start.jpg\""}, {"type": "file", "name": "img_17_end.jpg\""}, {"type": "file", "name": "img_17_start.jpg\""}, {"type": "file", "name": "img_18_end.jpg\""}, {"type": "file", "name": "img_18_start.jpg\""}, {"type": "file", "name": "img_19_end.jpg\""}, {"type": "file", "name": "img_19_start.jpg\""}, {"type": "file", "name": "img_1_end.jpg\""}, {"type": "file", "name": "img_1_start.jpg\""}, {"type": "file", "name": "img_20_end.jpg\""}, {"type": "file", "name": "img_20_start.jpg\""}, {"type": "file", "name": "img_21_end.jpg\""}, {"type": "file", "name": "img_21_start.jpg\""}, {"type": "file", "name": "img_22_end.jpg\""}, {"type": "file", "name": "img_22_start.jpg\""}, {"type": "file", "name": "img_23_end.jpg\""}, {"type": "file", "name": "img_23_start.jpg\""}, {"type": "file", "name": "img_24_end.jpg\""}, {"type": "file", "name": "img_24_start.jpg\""}, {"type": "file", "name": "img_25_end.jpg\""}, {"type": "file", "name": "img_25_start.jpg\""}, {"type": "file", "name": "img_26_end.jpg\""}, {"type": "file", "name": "img_26_start.jpg\""}, {"type": "file", "name": "img_27_end.jpg\""}, {"type": "file", "name": "img_27_start.jpg\""}, {"type": "file", "name": "img_28_end.jpg\""}, {"type": "file", "name": "img_28_start.jpg\""}, {"type": "file", "name": "img_29_end.jpg\""}, {"type": "file", "name": "img_29_start.jpg\""}, {"type": "file", "name": "img_2_end.jpg\""}, {"type": "file", "name": "img_2_start.jpg\""}, {"type": "file", "name": "img_30_end.jpg\""}, {"type": "file", "name": "img_30_start.jpg\""}, {"type": "file", "name": "img_31_end.jpg\""}, {"type": "file", "name": "img_31_start.jpg\""}, {"type": "file", "name": "img_32_end.jpg\""}, {"type": "file", "name": "img_32_start.jpg\""}, {"type": "file", "name": "img_33_end.jpg\""}, {"type": "file", "name": "img_33_start.jpg\""}, {"type": "file", "name": "img_34_end.jpg\""}, {"type": "file", "name": "img_34_start.jpg\""}, {"type": "file", "name": "img_35_end.jpg\""}, {"type": "file", "name": "img_35_start.jpg\""}, {"type": "file", "name": "img_36_end.jpg\""}, {"type": "file", "name": "img_36_start.jpg\""}, {"type": "file", "name": "img_37_end.jpg\""}, {"type": "file", "name": "img_37_start.jpg\""}, {"type": "file", "name": "img_38_end.jpg\""}, {"type": "file", "name": "img_38_start.jpg\""}, {"type": "file", "name": "img_39_end.jpg\""}, {"type": "file", "name": "img_39_start.jpg\""}, {"type": "file", "name": "img_3_end.jpg\""}, {"type": "file", "name": "img_3_start.jpg\""}, {"type": "file", "name": "img_40_end.jpg\""}, {"type": "file", "name": "img_40_start.jpg\""}, {"type": "file", "name": "img_41_end.jpg\""}, {"type": "file", "name": "img_41_start.jpg\""}, {"type": "file", "name": "img_42_end.jpg\""}, {"type": "file", "name": "img_42_start.jpg\""}, {"type": "file", "name": "img_43_end.jpg\""}, {"type": "file", "name": "img_43_start.jpg\""}, {"type": "file", "name": "img_44_end.jpg\""}, {"type": "file", "name": "img_44_start.jpg\""}, {"type": "file", "name": "img_45_end.jpg\""}, {"type": "file", "name": "img_45_start.jpg\""}, {"type": "file", "name": "img_46_end.jpg\""}, {"type": "file", "name": "img_46_start.jpg\""}, {"type": "file", "name": "img_47_end.jpg\""}, {"type": "file", "name": "img_47_start.jpg\""}, {"type": "file", "name": "img_48_end.jpg\""}, {"type": "file", "name": "img_48_start.jpg\""}, {"type": "file", "name": "img_49_end.jpg\""}, {"type": "file", "name": "img_49_start.jpg\""}, {"type": "file", "name": "img_4_end.jpg\""}, {"type": "file", "name": "img_4_start.jpg\""}, {"type": "file", "name": "img_50_end.jpg\""}, {"type": "file", "name": "img_50_start.jpg\""}, {"type": "file", "name": "img_51_end.jpg\""}, {"type": "file", "name": "img_51_start.jpg\""}, {"type": "file", "name": "img_52_end.jpg\""}, {"type": "file", "name": "img_52_start.jpg\""}, {"type": "file", "name": "img_53_end.jpg\""}, {"type": "file", "name": "img_53_start.jpg\""}, {"type": "file", "name": "img_54_end.jpg\""}, {"type": "file", "name": "img_54_start.jpg\""}, {"type": "file", "name": "img_55_end.jpg\""}, {"type": "file", "name": "img_55_start.jpg\""}, {"type": "file", "name": "img_56_end.jpg\""}, {"type": "file", "name": "img_56_start.jpg\""}, {"type": "file", "name": "img_57_end.jpg\""}, {"type": "file", "name": "img_57_start.jpg\""}, {"type": "file", "name": "img_58_end.jpg\""}, {"type": "file", "name": "img_58_start.jpg\""}, {"type": "file", "name": "img_59_end.jpg\""}, {"type": "file", "name": "img_59_start.jpg\""}, {"type": "file", "name": "img_5_end.jpg\""}, {"type": "file", "name": "img_5_start.jpg\""}, {"type": "file", "name": "img_60_end.jpg\""}, {"type": "file", "name": "img_60_start.jpg\""}, {"type": "file", "name": "img_61_end.jpg\""}, {"type": "file", "name": "img_61_start.jpg\""}, {"type": "file", "name": "img_62_end.jpg\""}, {"type": "file", "name": "img_62_start.jpg\""}, {"type": "file", "name": "img_63_end.jpg\""}, {"type": "file", "name": "img_63_start.jpg\""}, {"type": "file", "name": "img_64_end.jpg\""}, {"type": "file", "name": "img_64_start.jpg\""}, {"type": "file", "name": "img_65_end.jpg\""}, {"type": "file", "name": "img_65_start.jpg\""}, {"type": "file", "name": "img_66_end.jpg\""}, {"type": "file", "name": "img_66_start.jpg\""}, {"type": "file", "name": "img_67_end.jpg\""}, {"type": "file", "name": "img_67_start.jpg\""}, {"type": "file", "name": "img_68_end.jpg\""}, {"type": "file", "name": "img_68_start.jpg\""}, {"type": "file", "name": "img_69_end.jpg\""}, {"type": "file", "name": "img_69_start.jpg\""}, {"type": "file", "name": "img_6_end.jpg\""}, {"type": "file", "name": "img_6_start.jpg\""}, {"type": "file", "name": "img_70_end.jpg\""}, {"type": "file", "name": "img_70_start.jpg\""}, {"type": "file", "name": "img_71_end.jpg\""}, {"type": "file", "name": "img_71_start.jpg\""}, {"type": "file", "name": "img_72_end.jpg\""}, {"type": "file", "name": "img_72_start.jpg\""}, {"type": "file", "name": "img_73_end.jpg\""}, {"type": "file", "name": "img_73_start.jpg\""}, {"type": "file", "name": "img_74_end.jpg\""}, {"type": "file", "name": "img_74_start.jpg\""}, {"type": "file", "name": "img_75_end.jpg\""}, {"type": "file", "name": "img_75_start.jpg\""}, {"type": "file", "name": "img_76_end.jpg\""}, {"type": "file", "name": "img_76_start.jpg\""}, {"type": "file", "name": "img_77_end.jpg\""}, {"type": "file", "name": "img_77_start.jpg\""}, {"type": "file", "name": "img_78_end.jpg\""}, {"type": "file", "name": "img_78_start.jpg\""}, {"type": "file", "name": "img_79_end.jpg\""}, {"type": "file", "name": "img_79_start.jpg\""}, {"type": "file", "name": "img_7_end.jpg\""}, {"type": "file", "name": "img_7_start.jpg\""}, {"type": "file", "name": "img_80_end.jpg\""}, {"type": "file", "name": "img_80_start.jpg\""}, {"type": "file", "name": "img_81_end.jpg\""}, {"type": "file", "name": "img_81_start.jpg\""}, {"type": "file", "name": "img_82_end.jpg\""}, {"type": "file", "name": "img_82_start.jpg\""}, {"type": "file", "name": "img_83_end.jpg\""}, {"type": "file", "name": "img_83_start.jpg\""}, {"type": "file", "name": "img_84_end.jpg\""}, {"type": "file", "name": "img_84_start.jpg\""}, {"type": "file", "name": "img_85_end.jpg\""}, {"type": "file", "name": "img_85_start.jpg\""}, {"type": "file", "name": "img_86_end.jpg\""}, {"type": "file", "name": "img_86_start.jpg\""}, {"type": "file", "name": "img_87_end.jpg\""}, {"type": "file", "name": "img_87_start.jpg\""}, {"type": "file", "name": "img_88_end.jpg\""}, {"type": "file", "name": "img_88_start.jpg\""}, {"type": "file", "name": "img_89_end.jpg\""}, {"type": "file", "name": "img_89_start.jpg\""}, {"type": "file", "name": "img_8_end.jpg\""}, {"type": "file", "name": "img_8_start.jpg\""}, {"type": "file", "name": "img_90_end.jpg\""}, {"type": "file", "name": "img_90_start.jpg\""}, {"type": "file", "name": "img_91_end.jpg\""}, {"type": "file", "name": "img_91_start.jpg\""}, {"type": "file", "name": "img_92_end.jpg\""}, {"type": "file", "name": "img_92_start.jpg\""}, {"type": "file", "name": "img_93_end.jpg\""}, {"type": "file", "name": "img_93_start.jpg\""}, {"type": "file", "name": "img_94_end.jpg\""}, {"type": "file", "name": "img_94_start.jpg\""}, {"type": "file", "name": "img_95_end.jpg\""}, {"type": "file", "name": "img_95_start.jpg\""}, {"type": "file", "name": "img_96_end.jpg\""}, {"type": "file", "name": "img_96_start.jpg\""}, {"type": "file", "name": "img_97_end.jpg\""}, {"type": "file", "name": "img_97_start.jpg\""}, {"type": "file", "name": "img_98_end.jpg\""}, {"type": "file", "name": "img_98_start.jpg\""}, {"type": "file", "name": "img_99_end.jpg\""}, {"type": "file", "name": "img_99_start.jpg\""}, {"type": "file", "name": "img_9_end.jpg\""}, {"type": "file", "name": "img_9_start.jpg\""}]}, {"type": "file", "name": "extract_screenshots.py\""}, {"type": "file", "name": "test.mp4\""}, {"type": "file", "name": "transcript.csv\""}]}, {"type": "dir", "name": "5_RAG_database", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "rag_query.cpython-310.pyc"}, {"type": "file", "name": "rag_query.cpython-311.pyc"}]}, {"type": "dir", "name": "input", "children": [{"type": "dir", "name": "keyframes", "children": [{"type": "file", "name": "frame_000000_Scene_Cut.jpg"}, {"type": "file", "name": "frame_001184_Scene_Cut.jpg"}, {"type": "file", "name": "frame_001185_Object_Appeared.jpg"}, {"type": "file", "name": "frame_003078_Object_Appeared.jpg"}, {"type": "file", "name": "frame_011983_Scene_Cut.jpg"}]}, {"type": "dir", "name": "screenshots", "children": [{"type": "file", "name": "img_100_end.jpg"}, {"type": "file", "name": "img_100_start.jpg"}, {"type": "file", "name": "img_101_end.jpg"}, {"type": "file", "name": "img_101_start.jpg"}, {"type": "file", "name": "img_102_end.jpg"}, {"type": "file", "name": "img_102_start.jpg"}, {"type": "file", "name": "img_103_end.jpg"}, {"type": "file", "name": "img_103_start.jpg"}, {"type": "file", "name": "img_104_end.jpg"}, {"type": "file", "name": "img_104_start.jpg"}, {"type": "file", "name": "img_105_end.jpg"}, {"type": "file", "name": "img_105_start.jpg"}, {"type": "file", "name": "img_106_end.jpg"}, {"type": "file", "name": "img_106_start.jpg"}, {"type": "file", "name": "img_107_end.jpg"}, {"type": "file", "name": "img_107_start.jpg"}, {"type": "file", "name": "img_108_end.jpg"}, {"type": "file", "name": "img_108_start.jpg"}, {"type": "file", "name": "img_109_end.jpg"}, {"type": "file", "name": "img_109_start.jpg"}, {"type": "file", "name": "img_10_end.jpg"}, {"type": "file", "name": "img_10_start.jpg"}, {"type": "file", "name": "img_110_end.jpg"}, {"type": "file", "name": "img_110_start.jpg"}, {"type": "file", "name": "img_111_end.jpg"}, {"type": "file", "name": "img_111_start.jpg"}, {"type": "file", "name": "img_112_end.jpg"}, {"type": "file", "name": "img_112_start.jpg"}, {"type": "file", "name": "img_113_end.jpg"}, {"type": "file", "name": "img_113_start.jpg"}, {"type": "file", "name": "img_114_end.jpg"}, {"type": "file", "name": "img_114_start.jpg"}, {"type": "file", "name": "img_115_end.jpg"}, {"type": "file", "name": "img_115_start.jpg"}, {"type": "file", "name": "img_116_end.jpg"}, {"type": "file", "name": "img_116_start.jpg"}, {"type": "file", "name": "img_117_end.jpg"}, {"type": "file", "name": "img_117_start.jpg"}, {"type": "file", "name": "img_118_end.jpg"}, {"type": "file", "name": "img_118_start.jpg"}, {"type": "file", "name": "img_119_end.jpg"}, {"type": "file", "name": "img_119_start.jpg"}, {"type": "file", "name": "img_11_end.jpg"}, {"type": "file", "name": "img_11_start.jpg"}, {"type": "file", "name": "img_120_end.jpg"}, {"type": "file", "name": "img_120_start.jpg"}, {"type": "file", "name": "img_121_end.jpg"}, {"type": "file", "name": "img_121_start.jpg"}, {"type": "file", "name": "img_122_end.jpg"}, {"type": "file", "name": "img_122_start.jpg"}, {"type": "file", "name": "img_123_end.jpg"}, {"type": "file", "name": "img_123_start.jpg"}, {"type": "file", "name": "img_124_end.jpg"}, {"type": "file", "name": "img_124_start.jpg"}, {"type": "file", "name": "img_125_end.jpg"}, {"type": "file", "name": "img_125_start.jpg"}, {"type": "file", "name": "img_126_end.jpg"}, {"type": "file", "name": "img_126_start.jpg"}, {"type": "file", "name": "img_127_end.jpg"}, {"type": "file", "name": "img_127_start.jpg"}, {"type": "file", "name": "img_128_end.jpg"}, {"type": "file", "name": "img_128_start.jpg"}, {"type": "file", "name": "img_129_end.jpg"}, {"type": "file", "name": "img_129_start.jpg"}, {"type": "file", "name": "img_12_end.jpg"}, {"type": "file", "name": "img_12_start.jpg"}, {"type": "file", "name": "img_130_end.jpg"}, {"type": "file", "name": "img_130_start.jpg"}, {"type": "file", "name": "img_131_end.jpg"}, {"type": "file", "name": "img_131_start.jpg"}, {"type": "file", "name": "img_132_end.jpg"}, {"type": "file", "name": "img_132_start.jpg"}, {"type": "file", "name": "img_133_end.jpg"}, {"type": "file", "name": "img_133_start.jpg"}, {"type": "file", "name": "img_134_end.jpg"}, {"type": "file", "name": "img_134_start.jpg"}, {"type": "file", "name": "img_135_end.jpg"}, {"type": "file", "name": "img_135_start.jpg"}, {"type": "file", "name": "img_136_end.jpg"}, {"type": "file", "name": "img_136_start.jpg"}, {"type": "file", "name": "img_137_end.jpg"}, {"type": "file", "name": "img_137_start.jpg"}, {"type": "file", "name": "img_138_end.jpg"}, {"type": "file", "name": "img_138_start.jpg"}, {"type": "file", "name": "img_139_end.jpg"}, {"type": "file", "name": "img_139_start.jpg"}, {"type": "file", "name": "img_13_end.jpg"}, {"type": "file", "name": "img_13_start.jpg"}, {"type": "file", "name": "img_140_end.jpg"}, {"type": "file", "name": "img_140_start.jpg"}, {"type": "file", "name": "img_141_end.jpg"}, {"type": "file", "name": "img_141_start.jpg"}, {"type": "file", "name": "img_142_end.jpg"}, {"type": "file", "name": "img_142_start.jpg"}, {"type": "file", "name": "img_143_end.jpg"}, {"type": "file", "name": "img_143_start.jpg"}, {"type": "file", "name": "img_144_end.jpg"}, {"type": "file", "name": "img_144_start.jpg"}, {"type": "file", "name": "img_145_end.jpg"}, {"type": "file", "name": "img_145_start.jpg"}, {"type": "file", "name": "img_146_end.jpg"}, {"type": "file", "name": "img_146_start.jpg"}, {"type": "file", "name": "img_147_end.jpg"}, {"type": "file", "name": "img_147_start.jpg"}, {"type": "file", "name": "img_148_end.jpg"}, {"type": "file", "name": "img_148_start.jpg"}, {"type": "file", "name": "img_149_end.jpg"}, {"type": "file", "name": "img_149_start.jpg"}, {"type": "file", "name": "img_14_end.jpg"}, {"type": "file", "name": "img_14_start.jpg"}, {"type": "file", "name": "img_150_end.jpg"}, {"type": "file", "name": "img_150_start.jpg"}, {"type": "file", "name": "img_151_end.jpg"}, {"type": "file", "name": "img_151_start.jpg"}, {"type": "file", "name": "img_152_end.jpg"}, {"type": "file", "name": "img_152_start.jpg"}, {"type": "file", "name": "img_153_end.jpg"}, {"type": "file", "name": "img_153_start.jpg"}, {"type": "file", "name": "img_154_end.jpg"}, {"type": "file", "name": "img_154_start.jpg"}, {"type": "file", "name": "img_155_end.jpg"}, {"type": "file", "name": "img_155_start.jpg"}, {"type": "file", "name": "img_156_end.jpg"}, {"type": "file", "name": "img_156_start.jpg"}, {"type": "file", "name": "img_157_end.jpg"}, {"type": "file", "name": "img_157_start.jpg"}, {"type": "file", "name": "img_158_end.jpg"}, {"type": "file", "name": "img_158_start.jpg"}, {"type": "file", "name": "img_159_end.jpg"}, {"type": "file", "name": "img_159_start.jpg"}, {"type": "file", "name": "img_15_end.jpg"}, {"type": "file", "name": "img_15_start.jpg"}, {"type": "file", "name": "img_160_end.jpg"}, {"type": "file", "name": "img_160_start.jpg"}, {"type": "file", "name": "img_161_end.jpg"}, {"type": "file", "name": "img_161_start.jpg"}, {"type": "file", "name": "img_162_end.jpg"}, {"type": "file", "name": "img_162_start.jpg"}, {"type": "file", "name": "img_163_end.jpg"}, {"type": "file", "name": "img_163_start.jpg"}, {"type": "file", "name": "img_164_end.jpg"}, {"type": "file", "name": "img_164_start.jpg"}, {"type": "file", "name": "img_165_end.jpg"}, {"type": "file", "name": "img_165_start.jpg"}, {"type": "file", "name": "img_166_end.jpg"}, {"type": "file", "name": "img_166_start.jpg"}, {"type": "file", "name": "img_167_end.jpg"}, {"type": "file", "name": "img_167_start.jpg"}, {"type": "file", "name": "img_168_end.jpg"}, {"type": "file", "name": "img_168_start.jpg"}, {"type": "file", "name": "img_169_end.jpg"}, {"type": "file", "name": "img_169_start.jpg"}, {"type": "file", "name": "img_16_end.jpg"}, {"type": "file", "name": "img_16_start.jpg"}, {"type": "file", "name": "img_170_end.jpg"}, {"type": "file", "name": "img_170_start.jpg"}, {"type": "file", "name": "img_171_end.jpg"}, {"type": "file", "name": "img_171_start.jpg"}, {"type": "file", "name": "img_172_end.jpg"}, {"type": "file", "name": "img_172_start.jpg"}, {"type": "file", "name": "img_17_end.jpg"}, {"type": "file", "name": "img_17_start.jpg"}, {"type": "file", "name": "img_18_end.jpg"}, {"type": "file", "name": "img_18_start.jpg"}, {"type": "file", "name": "img_19_end.jpg"}, {"type": "file", "name": "img_19_start.jpg"}, {"type": "file", "name": "img_1_end.jpg"}, {"type": "file", "name": "img_1_start.jpg"}, {"type": "file", "name": "img_20_end.jpg"}, {"type": "file", "name": "img_20_start.jpg"}, {"type": "file", "name": "img_21_end.jpg"}, {"type": "file", "name": "img_21_start.jpg"}, {"type": "file", "name": "img_22_end.jpg"}, {"type": "file", "name": "img_22_start.jpg"}, {"type": "file", "name": "img_23_end.jpg"}, {"type": "file", "name": "img_23_start.jpg"}, {"type": "file", "name": "img_24_end.jpg"}, {"type": "file", "name": "img_24_start.jpg"}, {"type": "file", "name": "img_25_end.jpg"}, {"type": "file", "name": "img_25_start.jpg"}, {"type": "file", "name": "img_26_end.jpg"}, {"type": "file", "name": "img_26_start.jpg"}, {"type": "file", "name": "img_27_end.jpg"}, {"type": "file", "name": "img_27_start.jpg"}, {"type": "file", "name": "img_28_end.jpg"}, {"type": "file", "name": "img_28_start.jpg"}, {"type": "file", "name": "img_29_end.jpg"}, {"type": "file", "name": "img_29_start.jpg"}, {"type": "file", "name": "img_2_end.jpg"}, {"type": "file", "name": "img_2_start.jpg"}, {"type": "file", "name": "img_30_end.jpg"}, {"type": "file", "name": "img_30_start.jpg"}, {"type": "file", "name": "img_31_end.jpg"}, {"type": "file", "name": "img_31_start.jpg"}, {"type": "file", "name": "img_32_end.jpg"}, {"type": "file", "name": "img_32_start.jpg"}, {"type": "file", "name": "img_33_end.jpg"}, {"type": "file", "name": "img_33_start.jpg"}, {"type": "file", "name": "img_34_end.jpg"}, {"type": "file", "name": "img_34_start.jpg"}, {"type": "file", "name": "img_35_end.jpg"}, {"type": "file", "name": "img_35_start.jpg"}, {"type": "file", "name": "img_36_end.jpg"}, {"type": "file", "name": "img_36_start.jpg"}, {"type": "file", "name": "img_37_end.jpg"}, {"type": "file", "name": "img_37_start.jpg"}, {"type": "file", "name": "img_38_end.jpg"}, {"type": "file", "name": "img_38_start.jpg"}, {"type": "file", "name": "img_39_end.jpg"}, {"type": "file", "name": "img_39_start.jpg"}, {"type": "file", "name": "img_3_end.jpg"}, {"type": "file", "name": "img_3_start.jpg"}, {"type": "file", "name": "img_40_end.jpg"}, {"type": "file", "name": "img_40_start.jpg"}, {"type": "file", "name": "img_41_end.jpg"}, {"type": "file", "name": "img_41_start.jpg"}, {"type": "file", "name": "img_42_end.jpg"}, {"type": "file", "name": "img_42_start.jpg"}, {"type": "file", "name": "img_43_end.jpg"}, {"type": "file", "name": "img_43_start.jpg"}, {"type": "file", "name": "img_44_end.jpg"}, {"type": "file", "name": "img_44_start.jpg"}, {"type": "file", "name": "img_45_end.jpg"}, {"type": "file", "name": "img_45_start.jpg"}, {"type": "file", "name": "img_46_end.jpg"}, {"type": "file", "name": "img_46_start.jpg"}, {"type": "file", "name": "img_47_end.jpg"}, {"type": "file", "name": "img_47_start.jpg"}, {"type": "file", "name": "img_48_end.jpg"}, {"type": "file", "name": "img_48_start.jpg"}, {"type": "file", "name": "img_49_end.jpg"}, {"type": "file", "name": "img_49_start.jpg"}, {"type": "file", "name": "img_4_end.jpg"}, {"type": "file", "name": "img_4_start.jpg"}, {"type": "file", "name": "img_50_end.jpg"}, {"type": "file", "name": "img_50_start.jpg"}, {"type": "file", "name": "img_51_end.jpg"}, {"type": "file", "name": "img_51_start.jpg"}, {"type": "file", "name": "img_52_end.jpg"}, {"type": "file", "name": "img_52_start.jpg"}, {"type": "file", "name": "img_53_end.jpg"}, {"type": "file", "name": "img_53_start.jpg"}, {"type": "file", "name": "img_54_end.jpg"}, {"type": "file", "name": "img_54_start.jpg"}, {"type": "file", "name": "img_55_end.jpg"}, {"type": "file", "name": "img_55_start.jpg"}, {"type": "file", "name": "img_56_end.jpg"}, {"type": "file", "name": "img_56_start.jpg"}, {"type": "file", "name": "img_57_end.jpg"}, {"type": "file", "name": "img_57_start.jpg"}, {"type": "file", "name": "img_58_end.jpg"}, {"type": "file", "name": "img_58_start.jpg"}, {"type": "file", "name": "img_59_end.jpg"}, {"type": "file", "name": "img_59_start.jpg"}, {"type": "file", "name": "img_5_end.jpg"}, {"type": "file", "name": "img_5_start.jpg"}, {"type": "file", "name": "img_60_end.jpg"}, {"type": "file", "name": "img_60_start.jpg"}, {"type": "file", "name": "img_61_end.jpg"}, {"type": "file", "name": "img_61_start.jpg"}, {"type": "file", "name": "img_62_end.jpg"}, {"type": "file", "name": "img_62_start.jpg"}, {"type": "file", "name": "img_63_end.jpg"}, {"type": "file", "name": "img_63_start.jpg"}, {"type": "file", "name": "img_64_end.jpg"}, {"type": "file", "name": "img_64_start.jpg"}, {"type": "file", "name": "img_65_end.jpg"}, {"type": "file", "name": "img_65_start.jpg"}, {"type": "file", "name": "img_66_end.jpg"}, {"type": "file", "name": "img_66_start.jpg"}, {"type": "file", "name": "img_67_end.jpg"}, {"type": "file", "name": "img_67_start.jpg"}, {"type": "file", "name": "img_68_end.jpg"}, {"type": "file", "name": "img_68_start.jpg"}, {"type": "file", "name": "img_69_end.jpg"}, {"type": "file", "name": "img_69_start.jpg"}, {"type": "file", "name": "img_6_end.jpg"}, {"type": "file", "name": "img_6_start.jpg"}, {"type": "file", "name": "img_70_end.jpg"}, {"type": "file", "name": "img_70_start.jpg"}, {"type": "file", "name": "img_71_end.jpg"}, {"type": "file", "name": "img_71_start.jpg"}, {"type": "file", "name": "img_72_end.jpg"}, {"type": "file", "name": "img_72_start.jpg"}, {"type": "file", "name": "img_73_end.jpg"}, {"type": "file", "name": "img_73_start.jpg"}, {"type": "file", "name": "img_74_end.jpg"}, {"type": "file", "name": "img_74_start.jpg"}, {"type": "file", "name": "img_75_end.jpg"}, {"type": "file", "name": "img_75_start.jpg"}, {"type": "file", "name": "img_76_end.jpg"}, {"type": "file", "name": "img_76_start.jpg"}, {"type": "file", "name": "img_77_end.jpg"}, {"type": "file", "name": "img_77_start.jpg"}, {"type": "file", "name": "img_78_end.jpg"}, {"type": "file", "name": "img_78_start.jpg"}, {"type": "file", "name": "img_79_end.jpg"}, {"type": "file", "name": "img_79_start.jpg"}, {"type": "file", "name": "img_7_end.jpg"}, {"type": "file", "name": "img_7_start.jpg"}, {"type": "file", "name": "img_80_end.jpg"}, {"type": "file", "name": "img_80_start.jpg"}, {"type": "file", "name": "img_81_end.jpg"}, {"type": "file", "name": "img_81_start.jpg"}, {"type": "file", "name": "img_82_end.jpg"}, {"type": "file", "name": "img_82_start.jpg"}, {"type": "file", "name": "img_83_end.jpg"}, {"type": "file", "name": "img_83_start.jpg"}, {"type": "file", "name": "img_84_end.jpg"}, {"type": "file", "name": "img_84_start.jpg"}, {"type": "file", "name": "img_85_end.jpg"}, {"type": "file", "name": "img_85_start.jpg"}, {"type": "file", "name": "img_86_end.jpg"}, {"type": "file", "name": "img_86_start.jpg"}, {"type": "file", "name": "img_87_end.jpg"}, {"type": "file", "name": "img_87_start.jpg"}, {"type": "file", "name": "img_88_end.jpg"}, {"type": "file", "name": "img_88_start.jpg"}, {"type": "file", "name": "img_89_end.jpg"}, {"type": "file", "name": "img_89_start.jpg"}, {"type": "file", "name": "img_8_end.jpg"}, {"type": "file", "name": "img_8_start.jpg"}, {"type": "file", "name": "img_90_end.jpg"}, {"type": "file", "name": "img_90_start.jpg"}, {"type": "file", "name": "img_91_end.jpg"}, {"type": "file", "name": "img_91_start.jpg"}, {"type": "file", "name": "img_92_end.jpg"}, {"type": "file", "name": "img_92_start.jpg"}, {"type": "file", "name": "img_93_end.jpg"}, {"type": "file", "name": "img_93_start.jpg"}, {"type": "file", "name": "img_94_end.jpg"}, {"type": "file", "name": "img_94_start.jpg"}, {"type": "file", "name": "img_95_end.jpg"}, {"type": "file", "name": "img_95_start.jpg"}, {"type": "file", "name": "img_96_end.jpg"}, {"type": "file", "name": "img_96_start.jpg"}, {"type": "file", "name": "img_97_end.jpg"}, {"type": "file", "name": "img_97_start.jpg"}, {"type": "file", "name": "img_98_end.jpg"}, {"type": "file", "name": "img_98_start.jpg"}, {"type": "file", "name": "img_99_end.jpg"}, {"type": "file", "name": "img_99_start.jpg"}, {"type": "file", "name": "img_9_end.jpg"}, {"type": "file", "name": "img_9_start.jpg"}]}, {"type": "file", "name": "transcript.csv"}]}, {"type": "dir", "name": "static", "children": [{"type": "file", "name": "script.js"}, {"type": "file", "name": "style.css"}]}, {"type": "dir", "name": "templates", "children": [{"type": "file", "name": "index.html"}]}, {"type": "file", "name": "image.index"}, {"type": "file", "name": "rag_ingest.py"}, {"type": "file", "name": "rag_mm.db"}, {"type": "file", "name": "rag_query.py"}, {"type": "file", "name": "requirements.txt"}, {"type": "file", "name": "server.py"}, {"type": "file", "name": "text.index"}]}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__Multimodal-Video-Analysis-and-RAG-Retrieval-System_V2": {"readme": "<h1>影片逐字稿理解系統</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案為一套整合「影片內容理解」與「語意搜尋」的系統。使用者可上傳影片檔案，系統會自動進行語者分離逐字稿轉錄、關鍵畫面截圖，並建立 RAG (Retrieval-Augmented Generation) 向量資料庫。使用者後續可透過自然語言搜尋影片特定片段，系統將回傳對應的逐字稿、時間戳記以及該時間點的畫面截圖。</p>\n<p>解決的問題：解決長影片難以快速檢索特定內容的痛點，透過語意搜尋取代傳統的關鍵字搜尋。\n使用對象：需整理大量訪談、會議記錄或教學影片的使用者。\n專案性質：Web Application (Service)</p>\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統採用 Client-Server 架構。前端為單頁式應用 (SPA)，負責檔案上傳與搜尋介面展示；後端使用 Flask 框架作為 API 伺服器，並協調各個核心處理模組。資料流以檔案系統為基礎，透過 CSV 進行模組間的資料傳遞，最終整合至 SQLite 與 FAISS 向量索引中。</p>\n<h3>模組職責</h3>\n<ul>\n<li><strong>Server (Flask):</strong> 接收請求、協調背景任務、提供 API 介面。</li>\n<li><strong>Transcribe Module:</strong> 負責影片音訊提取與呼叫 OpenAI GPT-4o API 進行轉錄。</li>\n<li><strong>Screenshot Module:</strong> 依據轉錄的時間戳記，使用 OpenCV 擷取影片畫面。</li>\n<li><strong>RAG Module:</strong> 使用 CLIP 模型將文字轉為向量，並建立 FAISS 索引與 SQLite Metadata 資料庫。</li>\n</ul>\n<h3>系統架構圖</h3>\n<pre><code class=\"language-mermaid\">graph TD\n    User[&quot;使用者&quot;] --&gt;|&quot;上傳影片/搜尋&quot;| Frontend[&quot;前端介面 (HTML/JS)&quot;]\n    Frontend &lt;--&gt;|&quot;HTTP API&quot;| Backend[&quot;後端伺服器 (Flask)&quot;]\n\n    subgraph &quot;核心處理模組 (Core Modules)&quot;\n        Backend --&gt;|&quot;1. 呼叫&quot;| Transcribe[&quot;轉錄模組 (transcribe.py)&quot;]\n        Backend --&gt;|&quot;2. 呼叫&quot;| Screenshot[&quot;截圖模組 (extract_screenshots.py)&quot;]\n        Backend --&gt;|&quot;3. 呼叫&quot;| RAG_Ingest[&quot;索引模組 (rag_ingest.py)&quot;]\n        Backend --&gt;|&quot;4. 查詢&quot;| RAG_Query[&quot;搜尋模組 (rag_query.py)&quot;]\n    end\n\n    subgraph &quot;外部服務 &amp; 模型 (External)&quot;\n        Transcribe --&gt;|&quot;API Request&quot;| OpenAI[&quot;OpenAI GPT-4o API&quot;]\n        RAG_Ingest --&gt;|&quot;Load&quot;| CLIP[&quot;CLIP Model (Local)&quot;]\n        RAG_Query --&gt;|&quot;Load&quot;| CLIP\n    end\n\n    subgraph &quot;資料存儲 (Storage)&quot;\n        Transcribe --&gt;|&quot;Write&quot;| CSV[&quot;transcripts.csv&quot;]\n        Screenshot --&gt;|&quot;Update&quot;| CSV\n        Screenshot --&gt;|&quot;Save&quot;| Img[&quot;Images&quot;]\n        RAG_Ingest --&gt;|&quot;Read&quot;| CSV\n        RAG_Ingest --&gt;|&quot;Build&quot;| DB[(&quot;SQLite + FAISS&quot;)]\n        RAG_Query --&gt;|&quot;Query&quot;| DB\n    end\n</code></pre>\n<h2>系統流程說明 (System Flow)</h2>\n<p>系統運作主要分為「資料處理 (Ingestion)」與「搜尋 (Retrieval)」兩個階段。上傳影片後，系統會自動在背景執行處理流程。</p>\n<h3>主要執行流程</h3>\n<ol>\n<li><strong>上傳與音訊提取：</strong> 接收影片，使用 ffmpeg 提取 m4a 音訊。</li>\n<li><strong>逐字稿轉錄：</strong> 將音訊送至 OpenAI GPT-4o-transcribe-diarize 模型，取得含時間戳記與語者標記的文字。</li>\n<li><strong>畫面擷取：</strong> 讀取轉錄結果，針對每一段對話的開始與結束時間進行截圖。</li>\n<li><strong>向量建置：</strong> 讀取最終 CSV，將文字內容通過 CLIP 模型轉為向量，存入 FAISS 索引，並將 Metadata 存入 SQLite。</li>\n</ol>\n<h3>處理流程圖</h3>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start([開始: 上傳影片]) --&gt; Upload{檢查檔案格式}\n    Upload -- 合格 --&gt; Save[儲存至 input/]\n    Upload -- 不合格 --&gt; Error([返回錯誤])\n\n    Save --&gt; ExtractAudio[ffmpeg 提取音訊]\n    ExtractAudio --&gt; CallOpenAI[OpenAI API 轉錄]\n    CallOpenAI --&gt; GenCSV[生成 transcripts.csv]\n\n    GenCSV --&gt; ReadCSV[讀取逐字稿]\n    ReadCSV --&gt; ExtractFrames[OpenCV 擷取截圖]\n    ExtractFrames --&gt; UpdateCSV[更新 CSV 增加圖片路徑]\n\n    UpdateCSV --&gt; GenEmbedding[CLIP 模型生成向量]\n    GenEmbedding --&gt; BuildIndex[建立 FAISS 索引]\n    GenEmbedding --&gt; SaveDB[寫入 SQLite DB]\n\n    SaveDB --&gt; End([結束: 等待搜尋])\n</code></pre>\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<pre><code class=\"language-text\">/ (Root)\n├── 1_逐字稿擷取/            # 轉錄模組目錄\n│   ├── transcribe.py       # 核心轉錄邏輯，包含 ffmpeg 呼叫與 OpenAI API 串接\n│   └── api_key.json        # OpenAI API 金鑰設定檔\n├── 2_逐字稿圖片擷取/        # 截圖模組目錄\n│   └── extract_screenshots.py # 讀取 CSV 並使用 OpenCV 截圖\n├── 3_RAG_database/         # RAG 資料庫模組目錄\n│   ├── rag_ingest.py       # 建立向量資料庫索引 (Ingestion)\n│   └── rag_query.py        # 執行語意搜尋 (Retrieval)\n├── 4_server/               # 後端伺服器目錄\n│   ├── server.py           # Flask 主程式，定義 API Endpoint\n│   └── requirements.txt    # Python 相依套件清單\n├── 5_frontend/             # 前端靜態資源目錄\n│   ├── index.html          # 主頁面結構\n│   ├── app.js              # 前端邏輯 (API 呼叫、狀態輪詢)\n│   └── styles.css          # 樣式表\n├── input/                  # 影片輸入目錄 (使用者上傳暫存)\n└── output/                 # 系統輸出目錄\n    ├── screenshots/        # 存放所有截圖檔案\n    ├── transcripts.csv     # 核心資料檔 (含文字、時間、圖片路徑)\n    ├── rag_mm.db           # SQLite Metadata 資料庫\n    └── transcript.index    # FAISS 向量索引檔\n</code></pre>\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<h3>模組關係圖</h3>\n<pre><code class=\"language-mermaid\">classDiagram\n    class Server {\n        +process_video()\n        +search()\n        +serve_static()\n    }\n    class Transcribe {\n        +extract_audio_from_video()\n        +transcribe_audio_gpt4o()\n        +save_to_csv()\n    }\n    class Screenshot {\n        +extract_frames()\n    }\n    class RAG_Ingest {\n        +ingest()\n        +get_text_embedding()\n    }\n    class RAG_Query {\n        +search()\n    }\n\n    Server ..&gt; Transcribe : 1. 呼叫\n    Server ..&gt; Screenshot : 2. 呼叫\n    Server ..&gt; RAG_Ingest : 3. 呼叫\n    Server ..&gt; RAG_Query : 4. 搜尋\n    Transcribe --|&gt; Screenshot : 產出 CSV\n    Screenshot --|&gt; RAG_Ingest : 產出完整 CSV\n</code></pre>\n<ul>\n<li><strong>server.py</strong>: 整合中心，管理 <code>processing_status</code> 狀態，並依序動態載入執行 <code>transcribe</code>、<code>extract_screenshots</code> 與 <code>rag_ingest</code>。</li>\n<li><strong>transcribe.py</strong>: 負責與 OpenAI 溝通。特點是實作了大型音訊檔案分割 (<code>split_audio</code>) 機制，避免超過 API 限制。</li>\n<li><strong>extract_screenshots.py</strong>: 影格處理核心。讀取 CSV 後，計算毫秒級時間點，精準擷取對話開始與結束畫面。</li>\n<li><strong>rag_ingest.py</strong>: 資料庫建置者。使用 <code>openai/clip-vit-base-patch32</code> 模型將文字向量化，這是搜尋功能的基礎。</li>\n</ul>\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li>作業系統：Windows (程式碼中包含對 Windows 路徑與 ffmpeg 指令的特定處理)</li>\n<li>Python 版本：3.8+</li>\n</ul>\n<h3>外部工具</h3>\n<ul>\n<li><strong>ffmpeg</strong>: 必須安裝並加入系統 PATH 環境變數，用於音訊提取。</li>\n</ul>\n<h3>Python 相依套件</h3>\n<p>請參閱 <code>4_server/requirements.txt</code>，主要包含：\n- flask, flask-cors (Web Server)\n- openai, requests (API Client)\n- opencv-python (Image Processing)\n- torch, transformers (AI Model)\n- faiss-cpu (Vector Index)\n- pillow (Image utility)</p>\n<h3>環境變數與設定</h3>\n<ul>\n<li><strong>OpenAI API Key</strong>: 必須設定於 <code>1_逐字稿擷取/api_key.json</code>。格式如下：\n  <code>json\n  {\n      \"openai\": {\n          \"api_key\": \"YOUR_API_KEY\"\n      }\n  }</code></li>\n</ul>\n<h2>使用方式 (How to Use)</h2>\n<h3>啟動系統</h3>\n<ol>\n<li>開啟終端機，切換至 <code>4_server</code> 目錄。</li>\n<li>執行伺服器：\n   <code>bash\n   python server.py</code></li>\n<li>伺服器將啟動於 <code>http://localhost:5000</code>。</li>\n</ol>\n<h3>操作流程</h3>\n<ol>\n<li><strong>開啟瀏覽器</strong>：存取 <code>http://localhost:5000</code>。</li>\n<li><strong>上傳影片</strong>：點擊上傳按鈕選擇影片檔案。</li>\n<li><strong>等待處理</strong>：介面會顯示目前進度 (轉錄 -&gt; 截圖 -&gt; 建立索引)。</li>\n<li><strong>搜尋內容</strong>：處理完成後，於搜尋框輸入自然語言 (例如：「提到人工智慧的地方」)。</li>\n<li><strong>檢視結果</strong>：系統列出相關片段，包含文字與對應截圖。</li>\n</ol>\n<h2>設定說明 (Configuration)</h2>\n<ul>\n<li><strong>API Key</strong>: 修改 <code>1_逐字稿擷取/api_key.json</code>。</li>\n<li><strong>CLIP 模型</strong>: 於 <code>rag_ingest.py</code> 與 <code>rag_query.py</code> 中定義 <code>CLIP_MODEL_NAME = \"openai/clip-vit-base-patch32\"</code>，可依需求更換 HuggingFace 模型。</li>\n<li><strong>搜尋結果數量</strong>: 於 <code>rag_query.py</code> 中定義 <code>TOP_K = 5</code>，控制預設回傳筆數。</li>\n<li><strong>截圖解析度</strong>: 依賴原始影片解析度，<code>extract_screenshots.py</code> 直接儲存原始影格。</li>\n</ul>\n<h2>開發者指南 (Developer Guide)</h2>\n<h3>建議閱讀順序</h3>\n<ol>\n<li><code>4_server/server.py</code>: 理解整體調度邏輯與 API 定義。</li>\n<li><code>1_逐字稿擷取/transcribe.py</code>: 理解如何處理音訊與串接 OpenAI。</li>\n<li><code>3_RAG_database/rag_ingest.py</code>: 理解向量資料庫的結構。</li>\n</ol>\n<h3>修改注意事項</h3>\n<ul>\n<li><strong>路徑處理</strong>: 專案大量使用相對路徑 (<code>Path(__file__).parent</code>) 定位跨目錄檔案，移動檔案時需特別注意路徑參照。</li>\n<li><strong>動態載入</strong>: <code>server.py</code> 使用 <code>importlib</code> 動態載入模組，修改模組檔名需同步更新 server 程式碼。</li>\n<li><strong>Windows 相容性</strong>: FAISS 在 Windows 寫入索引時有路徑編碼問題，程式碼中已包含 <code>os.chdir</code> 的 workaround，請勿移除。</li>\n</ul>\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<h3>限制 (Limitations)</h3>\n<ul>\n<li><strong>檔案大小</strong>: <code>transcribe.py</code> 內建分割邏輯處理超過 25MB 的音訊，但極大檔案可能導致處理時間過長。</li>\n<li><strong>單一執行緒</strong>: <code>server.py</code> 使用全域 <code>processing_status</code> 變數且未實作 Job Queue，同一時間只能處理一個影片上傳任務。</li>\n<li><strong>ffmpeg 相依</strong>: 必須預先手動安裝 ffmpeg，無自動安裝機制。</li>\n</ul>\n<h3>待辦事項 (TODO)</h3>\n<ul>\n<li>實作多人多工佇列 (Queue System)。</li>\n<li>增加對更多影片格式的錯誤處理。</li>\n<li>優化 CLIP 模型載入速度 (目前每次查詢或建立索引時皆重新載入模型)。</li>\n</ul>\n<h2>補充說明 (Notes)</h2>\n<ul>\n<li><code>output/</code> 資料夾中的 <code>transcripts.csv</code> 是系統的核心資料交換中心。若需手動修正逐字稿，可直接編輯此 CSV，但需確保格式正確，並重新執行 <code>rag_ingest.py</code> 以更新索引。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "Multimodal-Video-Analysis-and-RAG-Retrieval-System_V2", "generated_at": "2026-02-28T16:29:52.945142+00:00", "head": "93af0436970fb6e742b12184d7e73884c9352359"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"1_\\351\\200\\220\\345\\255\\227\\347\\250\\277\\346\\223\\267\\345\\217\\226", "children": [{"type": "file", "name": "api_key.json\""}, {"type": "file", "name": "transcribe.py\""}]}, {"type": "dir", "name": "\"2_\\351\\200\\220\\345\\255\\227\\347\\250\\277\\345\\234\\226\\347\\211\\207\\346\\223\\267\\345\\217\\226", "children": [{"type": "file", "name": "extract_screenshots.py\""}]}, {"type": "dir", "name": "3_RAG_database", "children": [{"type": "file", "name": "rag_ingest.py"}, {"type": "file", "name": "rag_query.py"}]}, {"type": "dir", "name": "4_server", "children": [{"type": "file", "name": "server.py"}]}, {"type": "dir", "name": "5_frontend", "children": [{"type": "file", "name": "app.js"}, {"type": "file", "name": "index.html"}, {"type": "file", "name": "styles.css"}]}, {"type": "file", "name": "README.md"}, {"type": "file", "name": "requirements.txt"}]}}, "gkwang4912__Musical-Emotion-Analysis-Project": {"readme": "<h1>Musical Emotion Analysis Project</h1>\n<h2>專案總覽（Project Overview）</h2>\n<p>本專案是一個音樂特徵提取與視覺化工具，旨在分析音訊檔案的情感相關特徵。\n專案分為兩個主要階段：特徵提取與資料視覺化。\n- <strong>用途</strong>：自動化提取音訊的數值特徵（MFCC, Chroma, Spectral Contrast）並生成對應的統計圖表。\n- <strong>解決的問題</strong>：將非結構化的音訊數據轉換為可分析的結構化 CSV 數據，並提供視覺化圖表以輔助分析。\n- <strong>使用對象</strong>：資料科學家、音樂情感分析研究人員。\n- <strong>專案性質</strong>：Analysis Tool / Script Collection</p>\n<h2>系統架構說明（Architecture Overview）</h2>\n<p>本系統由兩個獨立的 Python 腳本組成，透過 CSV 檔案進行資料傳遞。<code>1_抓取特徵</code> 負責處理原始音訊，<code>2_視覺化</code> 負責讀取處理後的數據並繪圖。</p>\n<h3>系統架構圖</h3>\n<pre><code class=\"language-mermaid\">graph TD\n    subgraph &quot;Phase 1: Feature Extraction&quot;\n        AudioFiles[&quot;Audio Files&lt;br/&gt;(wav, mp3, etc.)&quot;] --&gt;|Input| Extractor[get_features.py]\n        Extractor --&gt;|Process| Librosa[Librosa Library]\n        Librosa --&gt;|Return Features| Extractor\n        Extractor --&gt;|Write| CSV[batch_audio_features.csv]\n    end\n\n    subgraph &quot;Phase 2: Visualization&quot;\n        CSV --&gt;|Read| Visualizer[image.py]\n        Visualizer --&gt;|Generate| Plots[&quot;Feature Plots&lt;br/&gt;(Bar Charts)&quot;]\n        Visualizer --&gt;|Save| OutputDir[audio_feature_plots/]\n    end\n</code></pre>\n<h2>系統流程說明（System Flow）</h2>\n<p>系統執行流程依序分為「特徵提取」與「視覺化」兩個步驟。</p>\n<h3>主要處理流程</h3>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start([Start]) --&gt; Step1_Start\n\n    subgraph &quot;Step 1: Feature Extraction (get_features.py)&quot;\n        Step1_Start[Scan '音檔' Folder] --&gt; CheckExt{Valid Extension?}\n        CheckExt -- Yes --&gt; LoadAudio[&quot;Load Audio&lt;br/&gt;(Max 30s)&quot;]\n        CheckExt -- No --&gt; SkipFile[Skip File]\n        LoadAudio --&gt; CalcMFCC[&quot;Calculate MFCC&lt;br/&gt;(Mean of 13 dims)&quot;]\n        CalcMFCC --&gt; CalcChroma[&quot;Calculate Chroma&lt;br/&gt;(Mean of 12 dims)&quot;]\n        CalcChroma --&gt; CalcContrast[&quot;Calculate Spectral Contrast&lt;br/&gt;(Mean of 7 dims)&quot;]\n        CalcContrast --&gt; Aggregate[Aggregate Features]\n        Aggregate --&gt; WriteCSV[Save to batch_audio_features.csv]\n    end\n\n    WriteCSV --&gt; Step2_Start\n\n    subgraph &quot;Step 2: Visualization (image.py)&quot;\n        Step2_Start[Read batch_audio_features.csv] --&gt; CreateDir[Create 'audio_feature_plots' dir]\n        CreateDir --&gt; LoopRows{For Each Song}\n        LoopRows -- Next Row --&gt; CreateSubDir[Create Song Subdirectory]\n        CreateSubDir --&gt; PlotMFCC[Generate MFCC Bar Chart]\n        PlotMFCC --&gt; PlotChroma[Generate Chroma Bar Chart]\n        PlotChroma --&gt; PlotContrast[Generate Spectral Contrast Bar Chart]\n        PlotContrast --&gt; SaveImages[Save .png Files]\n        SaveImages --&gt; LoopRows\n        LoopRows -- Done --&gt; End([End])\n    end\n</code></pre>\n<h2>資料夾結構說明（Folder Structure）</h2>\n<pre><code>Musical-Emotion/\n├── 1_抓取特徵/               # 第一階段：特徵提取模組\n│   ├── get_features.py      # 主要特徵提取腳本\n│   ├── batch_audio_features.csv # 輸出的特徵數據 (CSV)\n│   └── 音檔/                 #存放原始音訊檔案的目錄 (Input)\n├── 2_視覺化/                 # 第二階段：資料視覺化模組\n│   ├── image.py             # 視覺化繪圖腳本\n│   ├── batch_audio_features.csv # 需將提取的 CSV 複製至此或直接讀取\n│   └── audio_feature_plots/ # 輸出的圖表結果目錄 (Output)\n└── README.md                # 專案說明文件\n</code></pre>\n<h3>模組關係圖</h3>\n<pre><code class=\"language-mermaid\">classDiagram\n    class FeatureExtractor {\n        +Input: Audio Files\n        +Output: CSV File\n        +Library: librosa\n        +Function: extract_mfcc()\n        +Function: extract_chroma()\n        +Function: extract_spectral_contrast()\n    }\n\n    class Visualizer {\n        +Input: CSV File\n        +Output: PNG Images\n        +Library: matplotlib\n        +Function: plot_mfcc()\n        +Function: plot_chroma()\n        +Function: plot_contrast()\n    }\n\n    class DataStore {\n        +File: batch_audio_features.csv\n        +Columns: Filename, MFCC1-13, Chroma1-12, Contrast1-7\n    }\n\n    FeatureExtractor --&gt; DataStore : Writes\n    Visualizer &lt;-- DataStore : Reads\n</code></pre>\n<h2>核心模組與重要檔案（Key Modules &amp; Files）</h2>\n<h3>1. <code>1_抓取特徵/get_features.py</code></h3>\n<ul>\n<li><strong>職責</strong>：批量讀取音訊檔案，提取聲學特徵，並將結果儲存為 CSV。</li>\n<li><strong>關鍵邏輯</strong>：<ul>\n<li>使用 <code>librosa.load</code> 讀取前 30 秒音訊。</li>\n<li>計算特徵的平均值（Mean）以代表整首曲目。</li>\n<li>處理異常並略過錯誤檔案。</li>\n</ul>\n</li>\n</ul>\n<h3>2. <code>2_視覺化/image.py</code></h3>\n<ul>\n<li><strong>職責</strong>：讀取特徵 CSV，為每一首曲目生成獨立的特徵分佈圖。</li>\n<li><strong>產出</strong>：<ul>\n<li>每首歌一個獨立資料夾。</li>\n<li>包含 <code>mfcc.png</code>, <code>chroma.png</code>, <code>contrast.png</code> 三張圖表。</li>\n</ul>\n</li>\n</ul>\n<h2>安裝與環境需求（Installation &amp; Requirements）</h2>\n<h3>系統需求</h3>\n<ul>\n<li>Windows / macOS / Linux</li>\n<li>Python 3.x</li>\n</ul>\n<h3>相依套件</h3>\n<p>請確保安裝以下 Python 套件：</p>\n<pre><code class=\"language-bash\">pip install librosa numpy pandas matplotlib\n</code></pre>\n<p><em>(注意：<code>librosa</code> 依賴 <code>ffmpeg</code> 進行音訊解碼，請確保系統環境中有安裝 ffmpeg)</em></p>\n<h2>使用方式（How to Use）</h2>\n<h3>步驟 1：準備音檔與提取特徵</h3>\n<ol>\n<li>將音訊檔案（.wav, .mp3 等）放入 <code>1_抓取特徵/音檔/</code> 資料夾中。</li>\n<li>執行特徵提取腳本：\n   <code>bash\n   cd 1_抓取特徵\n   python get_features.py</code></li>\n<li>執行完畢後，會檢查目錄下是否生成 <code>batch_audio_features.csv</code>。</li>\n</ol>\n<h3>步驟 2：生成視覺化圖表</h3>\n<ol>\n<li>確保 <code>batch_audio_features.csv</code> 存在（若腳本在不同目錄執行，需確認路徑）。</li>\n<li>執行視覺化腳本：\n   <code>bash\n   cd ../2_視覺化\n   python image.py</code></li>\n<li>查看 <code>2_視覺化/audio_feature_plots/</code> 目錄下的結果。</li>\n</ol>\n<h2>設定說明（Configuration）</h2>\n<p>目前的設定直接寫在程式碼（Hardcoded）中，若需修改請直接編輯 Python 檔案：</p>\n<ul>\n<li><strong><code>get_features.py</code></strong>:</li>\n<li><code>audio_folder = '音檔'</code>: 修改輸入資料夾名稱。</li>\n<li><code>duration=30</code>: <code>librosa.load</code> 的參數，預設僅讀取前 30 秒。</li>\n<li>\n<p><code>audio_extensions</code>: 定義支援的副檔名。</p>\n</li>\n<li>\n<p><strong><code>image.py</code></strong>:</p>\n</li>\n<li><code>output_root = \"audio_feature_plots\"</code>: 修改輸出圖片的根目錄名稱。</li>\n</ul>\n<h2>開發者指南（Developer Guide）</h2>\n<ul>\n<li><strong>擴充建議</strong>：<ul>\n<li>若要新增特徵（如 Zero Crossing Rate），請在 <code>get_features.py</code> 的特徵提取區塊新增計算邏輯，並同步更新 DataFrame 的欄位定義。</li>\n<li>若要修改圖表樣式，請編輯 <code>image.py</code> 中的 <code>plt</code> 相關設定。</li>\n</ul>\n</li>\n</ul>\n<h2>已知限制與待辦事項（Limitations &amp; TODO）</h2>\n<ul>\n<li><strong>限制</strong>：<ul>\n<li>音訊讀取長度固定為 30 秒 (<code>duration=30</code>)，無法完整分析長曲目。</li>\n<li>特徵僅計算平均值 (<code>np.mean</code>)，遺失了時間序列上的變化資訊。</li>\n<li>路徑設定多為相對路徑，執行時需注意當前工作目錄（CWD）。</li>\n</ul>\n</li>\n<li><strong>TODO</strong>：<ul>\n<li>[ ] 將參數（如資料夾路徑、時間長度）提取為設定檔或命令列參數。</li>\n<li>[ ] 支援時間序列特徵的圖表繪製（不僅僅是平均值）。</li>\n<li>[ ] 增加錯誤處理日誌（Logging）。</li>\n</ul>\n</li>\n</ul>\n<h2>補充說明（Notes）</h2>\n<ul>\n<li><code>get_features.py</code> 產生的 CSV 檔案包含檔名與所有數值特徵，可用於後續的機器學習模型訓練。</li>\n<li><code>image.py</code> 依賴 <code>batch_audio_features.csv</code> 的欄位名稱（如 <code>MFCC1</code>, <code>Chroma1</code> 等），修改提取腳本時需保持欄位名稱一致。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "Musical-Emotion-Analysis-Project", "generated_at": "2026-02-28T16:29:52.954947+00:00", "head": "eab92556dc28fb37e7eb90bc34087a0718e062f9"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"1_\\346\\212\\223\\345\\217\\226\\347\\211\\271\\345\\276\\265", "children": [{"type": "dir", "name": "\\351\\237\\263\\346\\252\\224", "children": [{"type": "file", "name": "anxious-test-1.MP3\""}, {"type": "file", "name": "anxious-test-2.MP3\""}, {"type": "file", "name": "anxious-test-3.MP3\""}, {"type": "file", "name": "anxious-test-4.MP3\""}, {"type": "file", "name": "anxious-test-5.mp3\""}, {"type": "file", "name": "clam-test-1.mp3\""}, {"type": "file", "name": "clam-test-2.mp3\""}, {"type": "file", "name": "clam-test-3.mp3\""}, {"type": "file", "name": "clam-test-4.mp3\""}, {"type": "file", "name": "clam-test-5.mp3\""}, {"type": "file", "name": "depressed test-1.MP3\""}, {"type": "file", "name": "depressed test-2.MP3\""}, {"type": "file", "name": "depressed test-3.MP3\""}, {"type": "file", "name": "depressed test-4.MP3\""}, {"type": "file", "name": "depressed test-5.MP3\""}, {"type": "file", "name": "energizing test-1.MP3\""}, {"type": "file", "name": "energizing test-2.MP3\""}, {"type": "file", "name": "energizing test-3.MP3\""}, {"type": "file", "name": "energizing test-4.MP3\""}, {"type": "file", "name": "energizing test-5.MP3\""}, {"type": "file", "name": "fear-test-1.mp3\""}, {"type": "file", "name": "fear-test-2.mp3\""}, {"type": "file", "name": "fear-test-3.mp3\""}, {"type": "file", "name": "fear-test-4.mp3\""}, {"type": "file", "name": "fear-test-5.mp3\""}, {"type": "file", "name": "happy-test.1.MP3\""}, {"type": "file", "name": "happy-test.2.MP3\""}, {"type": "file", "name": "happy-test.3.MP3\""}, {"type": "file", "name": "happy-test.4.MP3\""}, {"type": "file", "name": "happy-test.5.MP3\""}, {"type": "file", "name": "peaceful test.MP3\""}, {"type": "file", "name": "peaceful-test.1.MP3\""}, {"type": "file", "name": "peaceful-test.2.mp3\""}, {"type": "file", "name": "peaceful-test.3.mp3\""}, {"type": "file", "name": "peaceful-test.4.mp3\""}, {"type": "file", "name": "peaceful-test.5.mp3\""}, {"type": "file", "name": "sad-test.1.MP3\""}, {"type": "file", "name": "sad-test.2.MP3\""}, {"type": "file", "name": "sad-test.3.MP3\""}, {"type": "file", "name": "sad-test.4.MP3\""}, {"type": "file", "name": "sad-test.5.MP3\""}]}, {"type": "file", "name": "batch_audio_features.csv\""}, {"type": "file", "name": "get_features.py\""}]}, {"type": "dir", "name": "\"2_\\350\\246\\226\\350\\246\\272\\345\\214\\226", "children": [{"type": "dir", "name": "audio_feature_plots", "children": [{"type": "dir", "name": "anxious-test-1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "clam-test-1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "depressed test-1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "energizing test-1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "fear-test-1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "happy-test.1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "peaceful-test.1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}, {"type": "dir", "name": "sad-test.1", "children": [{"type": "file", "name": "chroma.png\""}, {"type": "file", "name": "contrast.png\""}, {"type": "file", "name": "mfcc.png\""}]}]}, {"type": "file", "name": "batch_audio_features.csv\""}, {"type": "file", "name": "image.py\""}]}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__MusicLDM-Video-Audio-Processor": {"readme": "<h1>MusicLDM Video Audio Processor</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案為一個基於 MusicLDM 擴散模型的影片音訊風格轉換處理工具。\n其主要目的是自動從輸入影片中提取音訊，透過 Latent Diffusion Model (LDM) 進行加噪 (Add Noise) 與降噪 (Denoise) 重建，最後將處理後的音訊合併回影片中。\n此工具適用於需要對影片配樂進行風格化處理或音訊重生成的開發者與研究人員。\n本專案性質為：Tool / Script。</p>\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統主要由三個 Python 腳本協同運作：<code>process_video.py</code> 作為核心控制器，負責檔案管理與流程調度；<code>add_noise.py</code> 負責將原始音訊轉換為 Noisy Latent；<code>denoise.py</code> 負責從 Noisy Latent 生成新的目標音訊。\n系統依賴 FFmpeg 進行多媒體格式轉換與合併，並使用 <code>diffusers</code> 套件載入 <code>ucsd-reach/musicldm</code> 模型進行推理。</p>\n<p>資料流向為：影片檔 -&gt; 原始 WAV -&gt; 切分片段 -&gt; 加噪 (Latent) -&gt; 降噪 (WAV) -&gt; 合併 WAV -&gt; 輸出影片。</p>\n<pre><code class=\"language-mermaid\">graph TD\n    User[User] --&gt;|Input Video| InputDir[video_input/]\n    User --&gt;|Execute| ProcessVideo[process_video.py]\n\n    ProcessVideo --&gt;|Extract Audio| FFmpeg1[FFmpeg System]\n    FFmpeg1 --&gt;|Raw WAV| TempAudio[output/temp_audio/]\n\n    ProcessVideo --&gt;|Call| AddNoise[add_noise.py]\n    TempAudio --&gt;|Read WAV| AddNoise\n    AddNoise --&gt;|Load| Model[MusicLDM Pipeline]\n    AddNoise --&gt;|Save Latent| NoisyLatents[output/noisy_latents/]\n\n    ProcessVideo --&gt;|Call| Denoise[denoise.py]\n    NoisyLatents --&gt;|Read Latent| Denoise\n    Denoise --&gt;|Inference| Model\n    Denoise --&gt;|Save Processed WAV| DenoisedParts[output/denoised_parts/]\n\n    ProcessVideo --&gt;|Concat Audio| FinalAudio[Final Merged WAV]\n    ProcessVideo --&gt;|Merge Audio/Video| FFmpeg2[FFmpeg System]\n    InputDir --&gt;|Original Video Stream| FFmpeg2\n    FinalAudio --&gt; FFmpeg2\n    FFmpeg2 --&gt;|Result| OutputDir[output/video/]\n</code></pre>\n<h2>系統流程說明 (System Flow)</h2>\n<p>主要執行流程由 <code>process_video.py</code> 控制，針對每個輸入影片執行完整的 ETL (Extract, Transform, Load) 流程。\n關鍵步驟包含音訊長度切分 (Chunking)，以符合 MusicLDM 對輸入長度的限制 (約 10.24 秒)。</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start([Start]) --&gt; CheckEnv{Check FFmpeg}\n    CheckEnv -- No --&gt; Error[Print Error &amp; Exit]\n    CheckEnv -- Yes --&gt; ScanDir[Scan video_input/]\n\n    ScanDir --&gt; HasFiles{Files Found?}\n    HasFiles -- No --&gt; End([End])\n    HasFiles -- Yes --&gt; LoopVideo[For Each Video]\n\n    LoopVideo --&gt; Extract[Extract Audio via FFmpeg]\n    Extract --&gt; LoadSplit[Load &amp; Split into 10.24s Chunks]\n\n    LoadSplit --&gt; LoopChunk[For Each Chunk]\n    LoopChunk --&gt; SaveTemp[Save Temp WAV]\n    SaveTemp --&gt; CallAddNoise[Call add_noise.py]\n    CallAddNoise --&gt; GenLatent[Generate Noisy Latent .pt]\n    GenLatent --&gt; CallDenoise[Call denoise.py]\n    CallDenoise --&gt; GenAudio[Generate Denoised WAV]\n    GenAudio --&gt; StorePart[Store in List]\n\n    StorePart --&gt; LoopChunk\n    LoopChunk -- All Chunks Done --&gt; MergeParts[Concatenate Audio Parts]\n    MergeParts --&gt; MuxAV[Merge Video &amp; New Audio via FFmpeg]\n    MuxAV --&gt; LoopVideo\n\n    LoopVideo -- All Videos Done --&gt; Finish([Finish])\n</code></pre>\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<ul>\n<li><code>./</code> (專案根目錄)<ul>\n<li><code>process_video.py</code>: 主程式入口，負責批次處理影片與流程控制。</li>\n<li><code>add_noise.py</code>: 功能模組，負責將音訊轉換為 Latent 並添加噪音。</li>\n<li><code>denoise.py</code>: 功能模組，負責從 Latent 執行擴散降噪生成音訊。</li>\n<li><code>MusicLDM/</code>: 包含專案相關庫或原始碼的目錄。</li>\n<li><code>musicldm_environment.yml</code>: Conda 環境設定檔。</li>\n<li><code>video_input/</code>: <strong>[輸入]</strong> 使用者需將待處理的影片檔案 (.mp4, .avi 等) 放入此處。</li>\n<li><code>output/</code>: <strong>[輸出]</strong> 系統執行產生的所有輸出檔案。<ul>\n<li><code>video/</code>: 最終合成的結果影片。</li>\n<li><code>temp_audio/</code>: 提取出的原始音訊與暫存片段。</li>\n<li><code>noisy_latents/</code>: 中間產物，加噪後的 Latent tensor (.pt)。</li>\n<li><code>denoised_parts/</code>: 中間產物，分段處理後的音訊 (.wav)。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">檔案名稱</th>\n<th style=\"text-align: left;\">類型</th>\n<th style=\"text-align: left;\">功能職責</th>\n<th style=\"text-align: left;\">關鍵依賴</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>process_video.py</code></td>\n<td style=\"text-align: left;\">Controller</td>\n<td style=\"text-align: left;\">檢查環境、掃描檔案、調用 ffmpeg、切分音訊、整合子模組。</td>\n<td style=\"text-align: left;\"><code>subprocess</code>, <code>torchaudio</code>, <code>numpy</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>add_noise.py</code></td>\n<td style=\"text-align: left;\">Processor</td>\n<td style=\"text-align: left;\">載入音訊、重取樣、執行 SDEdit 的加噪步驟 (Forward Process)。</td>\n<td style=\"text-align: left;\"><code>diffusers.MusicLDMPipeline</code>, <code>torch</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>denoise.py</code></td>\n<td style=\"text-align: left;\">Processor</td>\n<td style=\"text-align: left;\">載入 Noisy Latent、執行 SDEdit 的降噪步驟 (Reverse Process)。</td>\n<td style=\"text-align: left;\"><code>diffusers.MusicLDMPipeline</code>, <code>torch</code></td>\n</tr>\n</tbody>\n</table>\n<p>模組關係圖：</p>\n<pre><code class=\"language-mermaid\">classDiagram\n    class ProcessVideo {\n        +VIDEO_INPUT_DIR : str\n        +process_video(video_path)\n        +extract_audio()\n        +merge_audio_video()\n    }\n    class AddNoise {\n        +add_noise_to_audio()\n        +load_audio()\n        +steps : int\n    }\n    class Denoise {\n        +denoise_audio()\n        +prompt : str\n        +guidance_scale : float\n    }\n\n    ProcessVideo ..&gt; AddNoise : Imports &amp; Calls\n    ProcessVideo ..&gt; Denoise : Imports &amp; Calls\n    AddNoise ..&gt; HuggingFace : Uses MusicLDMPipeline\n    Denoise ..&gt; HuggingFace : Uses MusicLDMPipeline\n\n    class HuggingFace {\n        diffusers\n        ucsd-reach/musicldm\n    }\n</code></pre>\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li>OS: Windows / Linux / macOS</li>\n<li>Python: 3.8+ (建議)</li>\n<li>CUDA 支援 (建議用於加速 PyTorch 與 MusicLDM 推理)</li>\n</ul>\n<h3>外部工具</h3>\n<ul>\n<li><strong>FFmpeg</strong>: 必須安裝並設定於系統 PATH 環境變數中。用於音訊提取與影片合成。</li>\n</ul>\n<h3>Python 套件</h3>\n<p>主要依賴 (參考 <code>musicldm_environment.yml</code>):\n*   <code>torch</code>, <code>torchaudio</code>\n*   <code>diffusers</code>\n*   <code>transformers</code> (diffusers 依賴)\n*   <code>scipy</code>, <code>numpy</code></p>\n<h3>安裝步驟 (範例)</h3>\n<pre><code class=\"language-bash\"># 若使用 Conda\nconda env create -f musicldm_environment.yml\nconda activate musicldm\n\n# 或手動安裝 pip 套件\npip install torch torchaudio diffusers transformers scipy numpy\n</code></pre>\n<h2>使用方式 (How to Use)</h2>\n<ol>\n<li><strong>準備影片</strong>: 將您的影片檔案 (.mp4, .avi, .mov, .mkv) 放入 <code>video_input/</code> 資料夾中。若資料夾不存在請自行建立。</li>\n<li><strong>調整設定 (可選)</strong>: 開啟 <code>process_video.py</code> 修改開頭的設定區塊 (如 <code>PROMPT</code>, <code>NOISE_LEVEL</code>)。</li>\n<li><strong>執行程式</strong>:\n    <code>bash\n    python process_video.py</code></li>\n<li><strong>查看結果</strong>: 處理完成後，前往 <code>output/video/</code> 查看生成的 <code>_processed.mp4</code> 影片。</li>\n</ol>\n<h2>設定說明 (Configuration)</h2>\n<p>所有可調整參數皆位於 Python 腳本開頭的「設定區塊」全域變數中。</p>\n<p><strong><code>process_video.py</code> 主要設定:</strong>\n*   <code>NOISE_LEVEL</code> (float): 預設 <code>0.3</code>。決定保留多少原始音訊特徵。值越高變化越大。\n*   <code>STEPS</code> (int): 預設 <code>200</code>。擴散模型的採樣步數。\n*   <code>PROMPT</code> (str): 預設 <code>\"High quality music\"</code>。引導生成風格的文字提示。\n*   <code>NEGATIVE_PROMPT</code> (str): 預設 <code>\"noise, low quality\"</code>。\n*   <code>GUIDANCE_SCALE</code> (float): 預設 <code>1.5</code>。Classifier-Free Guidance 強度。\n*   <code>MODEL_ID</code> (str): 預設 <code>\"ucsd-reach/musicldm\"</code>。\n*   <code>SEED</code> (int): 預設 <code>42</code>。固定種子以確保結果可重現。</p>\n<p><strong>注意</strong>: <code>add_noise.py</code> 與 <code>denoise.py</code> 內亦有相同參數設定，若單獨執行這兩個腳本時需注意參數同步。但在透過 <code>process_video.py</code> 執行時，其參數主要由 <code>process_video.py</code> 定義與控制 (雖然代碼中目前是各個檔案獨立定義變數，修改時建議三者同步確認)。</p>\n<h2>開發者指南 (Developer Guide)</h2>\n<h3>建議閱讀順序</h3>\n<ol>\n<li><code>process_video.py</code>: 理解整體 ETL 流程與 FFmpeg 指令操作。</li>\n<li><code>add_noise.py</code>: 理解如何使用 <code>MusicLDMPipeline</code> 取得 VAE Latent 並手動加噪。</li>\n<li><code>denoise.py</code>: 理解如何將 Latent 傳回 Pipeline 並使用 <code>latents</code> 參數進行 SDEdit。</li>\n</ol>\n<h3>修改注意事項</h3>\n<ul>\n<li><strong>音訊長度</strong>: MusicLDM 模型通常針對 10.24 秒 (16k 取樣率) 進行訓練。<code>process_video.py</code> 中的 <code>chunk_samples</code> 設定與此相關，修改時需謹慎。</li>\n<li><strong>記憶體使用</strong>: 載入 Diffusion Model 需要較大 VRAM。若遇 OOM (Out of Memory)，可嘗試降低 <code>chunk_samples</code> 或使用 CPU (但速度會極慢)。</li>\n<li><strong>同步性</strong>: 目前 <code>add_noise.py</code> 和 <code>denoise.py</code> 的參數是寫死在各自檔案開頭的，<code>process_video.py</code> 雖然有定義常數但實際呼叫時並未完全覆蓋所有子模組的預設值 (除了透過函式參數傳遞的部分)。建議在 <code>process_video.py</code> 統一管理並傳遞所有參數。</li>\n</ul>\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<h3>限制</h3>\n<ul>\n<li><strong>音訊接縫</strong>: 由於採用切塊分別處理 (Chunking)，合併後的音訊在切分點可能會有不連續或爆音 (Clipping) 的聽感。</li>\n<li><strong>執行速度</strong>: 依賴 GPU 運算，處理長影片會非常耗時。</li>\n<li><strong>參數同步</strong>: 部分參數分散在三個檔案中，維護上較為不便。</li>\n</ul>\n<h3>TODO</h3>\n<ul>\n<li>[ ] 實作 Overlap-Add 機制以消除音訊切分處的接縫。</li>\n<li>[ ] 將所有參數提取至獨立的 <code>config.yaml</code> 或 <code>config.py</code> 統一管理。</li>\n<li>[ ] 增加批次處理時的進度條顯示 (tqdm)。</li>\n<li>[ ] 支援更多音訊格式輸入。</li>\n</ul>\n<h2>補充說明 (Notes)</h2>\n<ul>\n<li>本專案生成的 <code>output/</code> 資料夾可能會佔用大量磁碟空間 (尤其是 Latent 檔案)，建議定期清理。</li>\n<li>若遇到 FFmpeg 錯誤，請優先檢查 FFmpeg 版本與系統環境變數設定。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "MusicLDM-Video-Audio-Processor", "generated_at": "2026-02-28T16:29:52.965914+00:00", "head": "6c4915bb031d3d0c79ada0ed3038e51730d1193e"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "MusicLDM", "children": [{"type": "file", "name": "MusicLDM.txt"}]}, {"type": "file", "name": "add_noise.py"}, {"type": "file", "name": "denoise.py"}, {"type": "file", "name": "process_video.py"}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__NTCU-Student-Association-Integration-Project": {"readme": "<h1>國立臺中教育大學學生會官網整合專案</h1>\n<p>(NTCU Student Association Integration Project)</p>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案整合了國立臺中教育大學學生會的官方網站前端展示與後端資料分析工具。主要用途為提供學生校園資訊、特約商店查詢，並具備針對學生言論進行情緒分析與關鍵字視覺化的後端工具。</p>\n<ul>\n<li><strong>解決的問題</strong>：整合分散的公告資訊、提供直觀的特約商店地圖、自動化分析學生意見回饋（言論自由牆）。</li>\n<li><strong>使用對象</strong>：全校師生（前端）、學生會幹部與工程師（後端分析工具）。</li>\n<li><strong>專案性質</strong>：混合型專案，包含靜態網站 (Web Client) 與 本機 Python 自動化工具 (Local Automation Tools)。</li>\n</ul>\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統分為「前端展示層」與「後端分析層」。</p>\n<ul>\n<li><strong>前端展示層</strong>：由純 HTML/CSS/JS 構成，直接部署於靜態伺服器。資料面透過 JSONP 與 iframe 技術，直接與 Google Sheets 和 Google Maps 串接，不依賴傳統後端資料庫，降低維護成本。</li>\n<li><strong>後端分析層</strong>：由 Python 腳本組成的本機工具箱。針對 Excel 格式的原始資料進行處理，並串接 Google Gemini API 進行 AI 情緒判讀，或使用 Jieba 進行斷詞生成文字雲。</li>\n</ul>\n<pre><code class=\"language-mermaid\">graph TD\n    User[&quot;使用者 (Browser)&quot;]\n    Admin[&quot;管理者 (Local)&quot;]\n\n    subgraph Frontend [前端展示系統]\n        Main[&quot;Main_page (官網入口)&quot;]\n        Affiliate[&quot;特約 (特約店家子站)&quot;]\n        NewsJS[&quot;news.js (公告邏輯)&quot;]\n    end\n\n    subgraph External [雲端服務]\n        GSheet[&quot;Google Sheets (資料庫/CMS)&quot;]\n        GMap[&quot;Google Maps (地圖服務)&quot;]\n        Gemini[&quot;Google Gemini API (AI 模型)&quot;]\n    end\n\n    subgraph LocalBackend [本機資料分析工具]\n        EmotionPy[&quot;emotion_analyzer.py (情緒分析)&quot;]\n        CloudPy[&quot;wordcloud_generator.py (文字雲生成)&quot;]\n        RawData[Excel 原始資料]\n        ResultData[分析結果 / 圖片]\n    end\n\n    User --&gt; Main\n    User --&gt; Affiliate\n    Main --&gt; NewsJS\n    NewsJS --JSONP 請求--&gt; GSheet\n    Affiliate --Iframe 嵌入--&gt; GSheet\n    Affiliate --Iframe 嵌入--&gt; GMap\n\n    Admin --&gt; RawData\n    RawData --&gt; EmotionPy\n    RawData --&gt; CloudPy\n\n    EmotionPy --API 請求--&gt; Gemini\n    Gemini --回傳分析--&gt; EmotionPy\n    EmotionPy --&gt; ResultData\n\n    CloudPy --&gt; ResultData\n</code></pre>\n<h2>系統流程說明 (System Flow)</h2>\n<h3>1. 前端公告載入流程</h3>\n<p>網站採用 Client-Side Rendering (CSR) 模式載入公告，利用 Google Sheets 作為輕量級 CMS。</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant User as 使用者\n    participant Browser as 瀏覽器\n    participant JS as news.js\n    participant GSheet as Google Sheets API\n\n    User-&gt;&gt;Browser: 開啟 index.html\n    Browser-&gt;&gt;JS: 載入 news.js\n    JS-&gt;&gt;JS: 定義 JSONP Callback\n    JS-&gt;&gt;GSheet: 發送 Script Tag 請求 (GET)\n    GSheet--&gt;&gt;JS: 回傳 JavaScript (包含 JSON 資料)\n    JS-&gt;&gt;JS: 執行 Callback 解析資料\n    JS-&gt;&gt;JS: 轉換資料格式 (Date, Title, Link)\n    JS-&gt;&gt;Browser: 動態生成 HTML 插入 DOM\n    Browser--&gt;&gt;User: 顯示最新公告\n</code></pre>\n<h3>2. 情緒分析工具執行流程</h3>\n<p>管理者在本地端執行 Python 腳本進行輿情分析。</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start[開始] --&gt; LoadConfig[讀取 api.json 設定]\n    LoadConfig --&gt; ScanFiles[掃描目錄下 .xlsx 檔案]\n    ScanFiles --&gt; Check{有檔案?}\n    Check --無--&gt; End[結束]\n    Check --有--&gt; ReadExcel[讀取 Excel 內容]\n\n    ReadExcel --&gt; DetectCol[自動偵測文字欄位]\n    DetectCol --&gt; LoopRow{逐行處理}\n\n    LoopRow --API請求--&gt; Gemini[Gemini AI]\n    Gemini --回傳 1/0/-1--&gt; SaveResult[暫存結果]\n    SaveResult --&gt; LoopRow\n\n    LoopRow --全部完成--&gt; GenReport[生成統計報告 .txt]\n    GenReport --&gt; End\n</code></pre>\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<pre><code class=\"language-text\">Web/SA/\n├── README.md               # 本文件\n├── Main_page/              # [前端] 官網主系統\n│   ├── css/                # 樣式表\n│   ├── img/                # 圖片資源\n│   ├── js/                 # 腳本邏輯\n│   │   └── news.js         # 核心公告載入邏輯\n│   ├── index.html          # 首頁\n│   ├── all_news.html       # 所有公告頁\n│   ├── news_detail.html    # 公告詳情頁\n│   └── calendar.html       # 行事曆頁\n│\n├── 特約/                   # [前端] 特約店家獨立子頁面\n│   ├── SA_food.html        # 特約店家首頁\n│   ├── script.js           # 簡單的導覽列互動邏輯\n│   └── styles.css          # 特約頁面專屬樣式\n│\n└── 言論自由牆/             # [後端] 資料分析專案\n    ├── code/\n    │   ├── 情緒分類/       # 情緒分析模組\n    │   │   ├── emotion_analyzer.py  # 主程式\n    │   │   └── api.json             # API 金鑰設定 (需自行建立)\n    │   └── 文字雲/         # 文字雲模組\n    │       ├── wordcloud_generator.py # 主程式\n    │       └── stopwords.txt          # 停用詞庫\n    ├── file/               # 原始資料存放區\n    └── result/             # 分析結果產出區\n</code></pre>\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<h3>前端核心</h3>\n<ul>\n<li><strong><code>Main_page/js/news.js</code></strong>: </li>\n<li><strong>職責</strong>: 負責與 Google Sheets 溝通。</li>\n<li><strong>機制</strong>: 使用 JSONP 避開跨域 (CORS) 限制，將試算表資料轉換為網頁公告。</li>\n<li>\n<p><strong>重要變數</strong>: <code>SHEET_ID</code> (指向資料來源試算表)。</p>\n</li>\n<li>\n<p><strong><code>Main_page/index.html</code></strong>:</p>\n</li>\n<li><strong>職責</strong>: 網站入口，包含 Hero Section、最新公告區塊、行事曆嵌入。</li>\n</ul>\n<h3>後端核心 (Python)</h3>\n<ul>\n<li><strong><code>emotion_analyzer.py</code></strong>:</li>\n<li><strong>職責</strong>: 讀取 Excel，呼叫 Google Gemini API 判斷文本情緒 (正向/中性/負向)。</li>\n<li>\n<p><strong>特性</strong>: 具備斷點續傳、自動重試 (Retry) 機制、由 api.json 讀取金鑰。</p>\n</li>\n<li>\n<p><strong><code>wordcloud_generator.py</code></strong>:</p>\n</li>\n<li><strong>職責</strong>: 使用 <code>jieba</code> 進行中文斷詞，移除停用詞後，繪製高解析度文字雲圖片。</li>\n<li><strong>特性</strong>: 支援自訂停用詞、自動偵測目錄下 Excel 檔。</li>\n</ul>\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>1. 網站前端</h3>\n<ul>\n<li><strong>需求</strong>: 任意現代瀏覽器 (Chrome, Edge, Safari)。</li>\n<li><strong>啟動</strong>: 直接雙擊開啟 <code>.html</code> 檔案，或使用 Live Server 預覽。</li>\n</ul>\n<h3>2. Python 分析工具</h3>\n<ul>\n<li><strong>語言版本</strong>: Python 3.8+</li>\n<li><strong>必要套件</strong>:\n  <code>bash\n  pip install pandas requests openpyxl jieba wordcloud matplotlib numpy pillow</code></li>\n<li><strong>環境變數</strong>: 需在 <code>言論自由牆/code/情緒分類/</code> 目錄下建立 <code>api.json</code>：\n  <code>json\n  {\n      \"api_key\": \"YOUR_GEMINI_API_KEY\"\n  }</code></li>\n</ul>\n<h2>使用方式 (How to Use)</h2>\n<h3>瀏覽網站</h3>\n<ol>\n<li>進入 <code>Main_page</code> 資料夾。</li>\n<li>開啟 <code>index.html</code> 即可瀏覽首頁。</li>\n<li>公告資料會自動從 Google Sheets 載入（需連網）。</li>\n</ol>\n<h3>執行情緒分析</h3>\n<ol>\n<li>將含有文字資料的 <code>.xlsx</code> 檔案放入 <code>言論自由牆/code/情緒分類/</code> 資料夾。</li>\n<li>確認 <code>api.json</code> 已設定。</li>\n<li>開啟終端機 (Terminal) 切換至該目錄。</li>\n<li>執行指令：\n   <code>bash\n   python emotion_analyzer.py</code></li>\n<li>程式會自動分析並產生 <code>_情緒分析結果.xlsx</code> 與 <code>_統計報告.txt</code>。</li>\n</ol>\n<h3>產生文字雲</h3>\n<ol>\n<li>將 <code>.xlsx</code> 檔案放入 <code>言論自由牆/code/文字雲/</code> 資料夾。</li>\n<li>執行指令：\n   <code>bash\n   python wordcloud_generator.py</code></li>\n<li>程式將輸出 <code>_文字雲.png</code> 圖片檔。</li>\n</ol>\n<h2>設定說明 (Configuration)</h2>\n<table>\n<thead>\n<tr>\n<th>設定檔</th>\n<th>位置</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>api.json</strong></td>\n<td><code>code/情緒分類/</code></td>\n<td>儲存 Google Gemini API Key，格式為 JSON。</td>\n</tr>\n<tr>\n<td><strong>stopwords.txt</strong></td>\n<td><code>code/文字雲/</code></td>\n<td>定義文字雲排除詞彙（如：的、了、是），一行一詞。</td>\n</tr>\n<tr>\n<td><strong>SHEET_ID</strong></td>\n<td><code>Main_page/js/news.js</code></td>\n<td>第 6 行，指定公告資料來源的 Google Sheet ID。</td>\n</tr>\n</tbody>\n</table>\n<h2>開發者指南 (Developer Guide)</h2>\n<ol>\n<li><strong>修改公告來源</strong>: 若要更換公告試算表，請確保新試算表權限開啟為「知道連結者皆可檢視」，並更新 <code>news.js</code> 中的 <code>SHEET_ID</code>。</li>\n<li><strong>擴充 AI 模型</strong>: 在 <code>emotion_analyzer.py</code> 中可修改 <code>self.current_model</code> 變數來切換不同版本的 Gemini 模型 (如 pro/flash)。</li>\n<li><strong>文字雲字體</strong>: <code>wordcloud_generator.py</code> 預設使用 Windows 系統字體 (<code>msjh.ttc</code>)，若在 Mac/Linux 執行需修改字體路徑。</li>\n</ol>\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<ul>\n<li><strong>[LIMITATION] CORS</strong>: 前端使用 JSONP 抓取 Google Sheets 資料是較舊的技術，未來若 Google 停用相關 API 可能失效，建議遷移至 Google Apps Script 或正式後端。</li>\n<li><strong>[LIMITATION] API Quota</strong>: 免費版 Gemini API 有每分鐘請求限制，大量資料分析時程式會自動暫停等待，處理速度較慢。</li>\n<li><strong>[TODO]</strong>: <code>特約</code> 頁面的 Google Map 目前為空 iframe，需填入實際 <code>src</code> 連結。</li>\n<li><strong>[TODO]</strong>: <code>all_news.html</code> 的分頁功能尚未實作，目前會列出所有資料。</li>\n</ul>\n<h2>補充說明 (Notes)</h2>\n<ul>\n<li>系統中的 <code>小詠</code>、<code>大詠</code> 為校內宿舍名稱，可能會在 AI 分析時被誤判，提示詞中已加入相關背景知識修正。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "NTCU-Student-Association-Integration-Project", "generated_at": "2026-02-28T16:29:52.976077+00:00", "head": "cdfe810f68a3406c741fdd0a21d5e58f6b85a92a"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"\\347\\211\\271\\347\\264\\204", "children": [{"type": "dir", "name": "Design", "children": [{"type": "file", "name": "pencil-new.pen\""}]}, {"type": "dir", "name": "web_image", "children": [{"type": "file", "name": "icon.jpg\""}]}, {"type": "file", "name": "index.html\""}, {"type": "file", "name": "script.js\""}, {"type": "file", "name": "styles.css\""}]}, {"type": "dir", "name": "\"\\350\\250\\200\\350\\253\\226\\350\\207\\252\\347\\224\\261\\347\\211\\206", "children": [{"type": "dir", "name": "code", "children": [{"type": "dir", "name": "\\346\\203\\205\\347\\267\\222\\345\\210\\206\\351\\241\\236", "children": [{"type": "file", "name": "api.json\""}, {"type": "file", "name": "emotion_analyzer.py\""}]}, {"type": "dir", "name": "\\346\\226\\207\\345\\255\\227\\351\\233\\262", "children": [{"type": "file", "name": "stopwords.txt\""}, {"type": "file", "name": "wordcloud_generator.py\""}]}]}, {"type": "dir", "name": "file", "children": [{"type": "file", "name": "20250908.xlsx\""}, {"type": "file", "name": "20251021.xlsx\""}]}, {"type": "dir", "name": "result", "children": [{"type": "dir", "name": "20250908", "children": [{"type": "file", "name": "20250908_\\346\\203\\205\\347\\267\\222\\345\\210\\206\\346\\236\\220\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "20250908_\\346\\226\\207\\345\\255\\227\\351\\233\\262.png\""}, {"type": "file", "name": "20250908_\\347\\265\\261\\350\\250\\210\\345\\240\\261\\345\\221\\212.txt\""}]}, {"type": "dir", "name": "20251021", "children": [{"type": "file", "name": "20251021_\\346\\203\\205\\347\\267\\222\\345\\210\\206\\346\\236\\220\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "20251021_\\346\\226\\207\\345\\255\\227\\351\\233\\262.png\""}, {"type": "file", "name": "20251021_\\347\\265\\261\\350\\250\\210\\345\\240\\261\\345\\221\\212.txt\""}]}]}]}, {"type": "dir", "name": "\"Main_page", "children": [{"type": "dir", "name": "img", "children": [{"type": "file", "name": "\\345\\255\\270\\347\\224\\237\\346\\234\\203\\346\\234\\203\\345\\276\\275.png\""}, {"type": "file", "name": "\\345\\260\\217\\346\\262\\271\\345\\235\\221\\351\\242\\250\\346\\231\\257\\347\\205\\247\\345\\216\\237\\347\\250\\277.jpg\""}]}]}, {"type": "dir", "name": "Main_page", "children": [{"type": "dir", "name": "js", "children": [{"type": "file", "name": "news.js"}]}, {"type": "file", "name": "all_news.html"}, {"type": "file", "name": "calendar.html"}, {"type": "file", "name": "index.css"}, {"type": "file", "name": "index.html"}, {"type": "file", "name": "news_detail.html"}]}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__Sentiment-Analysis-System": {"readme": "<h1>情緒分析系統 (Sentiment Analysis System)</h1>\n<h2>專案總覽（Project Overview）</h2>\n<p>本專案旨在解決大規模文本情緒分類的問題（正面/負面），主要用於處理 <strong>CT活動（運算思維活動）</strong> 的相關文本數據。</p>\n<p>系統透過 Python 腳本串接 LLM API（如 Gemma, Llama3, Phi-4），自動批次處理評論資料，預測其情緒傾向（0 為負面，1 為正面），並與原始標籤進行比對以計算準確率。這是一個 <strong>Tool / Analysis System</strong> 性質的專案。</p>\n<h2>系統架構說明（Architecture Overview）</h2>\n<p>本系統採用 <strong>Client-Server</strong> 架構。前端為 Python 自動化腳本，負責資料前處理、API請求與結果記錄；後端為託管於區域網路或本機的 LLM 推論服務（相容 OpenAI Chat API 格式）。</p>\n<h3>模組職責：</h3>\n<ol>\n<li><strong>Data Loader</strong>: 讀取 Excel/CSV 原始數據 (<code>pandas</code>)。</li>\n<li><strong>Processor</strong>: <ul>\n<li>建構 Prompt（提示詞工程）。</li>\n<li>批次發送 HTTP 請求至 LLM API。</li>\n<li>錯誤處理與重試機制。</li>\n</ul>\n</li>\n<li><strong>Evaluator</strong>: 比對預測結果與真實標籤 (<code>count.py</code>)。</li>\n<li><strong>LLM Service</strong>: 外部依賴，負責生成情緒判斷結果（支援 Gemma, Llama3, Phi-4 等模型）。</li>\n</ol>\n<pre><code class=\"language-mermaid\">graph TD\n    subgraph &quot;Client Side (Local Machine)&quot;\n        Input[(&quot;Input Data\\n(.xlsx / .csv)&quot;)]\n        Script[&quot;Analysis Script\\n(Python)&quot;]\n        Tokenizer[&quot;Tokenizer / Preprocessor\\n(llama-cpp / pandas)&quot;]\n        Output[(&quot;Output Results\\n(results.csv)&quot;)]\n        Input --&gt; Tokenizer\n        Tokenizer --&gt; Script\n        Script --&gt; Output\n    end\n\n    subgraph &quot;Server Side (LLM API)&quot;\n        API_Endpoint[&quot;API Endpoint\\n(/v1/chat/completions)&quot;]\n        Model[&quot;LLM Engine\\n(Gemma / Llama3 / Phi-4)&quot;]\n        API_Endpoint &lt;--&gt; Model\n    end\n\n    Script -- &quot;POST Request (JSON)&quot; --&gt; API_Endpoint\n    API_Endpoint -- &quot;Response (Sentiment)&quot; --&gt; Script\n</code></pre>\n<h2>系統流程說明（System Flow）</h2>\n<p>以下流程描述系統如何處理單一批次的文字資料。</p>\n<ol>\n<li><strong>初始化</strong>：設定 API URL、模型名稱、輸入/輸出檔案路徑。</li>\n<li><strong>斷點續傳檢查</strong>：檢查輸出檔案是否存在，若存在則從上次中斷處繼續。</li>\n<li><strong>資料預處理</strong>：讀取 Excel，計算 Token 長度（Version 1）。</li>\n<li><strong>批次處理迴圈</strong>：<ul>\n<li>將資料分塊（Chunking）。</li>\n<li>逐筆建構 Prompt。</li>\n<li>呼叫 LLM API 進行推論。</li>\n<li>解析 JSON 回傳值 (0 或 1)。</li>\n<li>寫入 CSV 結果檔。</li>\n<li>即時計算當前準確率。</li>\n</ul>\n</li>\n</ol>\n<pre><code class=\"language-mermaid\">flowchart TD\n    Start([開始 Start]) --&gt; Init[初始化參數 &amp; 檢查斷點]\n    Init --&gt; ReadData[讀取輸入資料 Excel]\n    ReadData --&gt; LoopStart{還有未處理的區塊?}\n\n    LoopStart -- Yes --&gt; ChunkData[取出下一個區塊]\n    ChunkData --&gt; RowLoop{遍歷區塊內每一列}\n\n    RowLoop -- Yes --&gt; GenPrompt[建構 Prompt]\n    GenPrompt --&gt; CallAPI[呼叫 LLM API]\n    CallAPI --&gt; CheckRes{API 回應成功?}\n\n    CheckRes -- No --&gt; LogError[記錄錯誤至 CSV]\n    CheckRes -- Yes --&gt; ParseJSON[解析 JSON 取得 0/1]\n    ParseJSON --&gt; SaveRow[暫存結果]\n    LogError --&gt; RowLoop\n    SaveRow --&gt; RowLoop\n\n    RowLoop -- No --&gt; WriteFile[寫入 results.csv]\n    WriteFile --&gt; CalcAcc[計算並顯示目前準確率]\n    CalcAcc --&gt; LoopStart\n\n    LoopStart -- No --&gt; End([結束 End])\n</code></pre>\n<h2>資料夾結構說明（Folder Structure）</h2>\n<pre><code>Kapibala/\n├── CT活動_文字情緒_全LSTM_1/       # [Version 1] 包含本地 Token 計算邏輯的版本\n│   ├── gemma-2-27b-it/           # Gemma 模型專用執行目錄\n│   ├── CT活動_文字情緒_全LSTM.xlsx # 原始資料集\n│   └── ...\n├── CT活動_文字情緒_全LSTM_2/       # [Version 2] 簡化版，支援多模型，直接使用英文資料\n│   ├── gemma-2-27b-it/           # Gemma 模型實驗目錄\n│   ├── llama3_70B/               # Llama3 模型實驗目錄\n│   ├── phi-4/                    # Phi-4 模型實驗目錄\n│   ├── CT_Dataset2.xlsx          # 原始資料集 (V2)\n│   └── CT_Dataset2_translated.xlsx # 翻譯後資料集\n├── tool/                         # 共用工具與資料集\n│   ├── tool.py                   # IMDB 資料下載與轉檔工具\n│   └── imdb_reviews.csv          # 下載後的 IMDB 資料集\n└── ...\n</code></pre>\n<h2>核心模組與重要檔案（Key Modules &amp; Files）</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">檔案路徑 (範例)</th>\n<th style=\"text-align: left;\">模組/檔案</th>\n<th style=\"text-align: left;\">功能職責</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>*/gemma-2-27b-it.py</code></td>\n<td style=\"text-align: left;\"><strong>主執行腳本</strong></td>\n<td style=\"text-align: left;\">負責主要的 ETL 流程、API 互動與錯誤處理。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>*/count.py</code></td>\n<td style=\"text-align: left;\"><strong>統計模組</strong></td>\n<td style=\"text-align: left;\">用於讀取 CSV 結果檔，計算並輸出當前的分類準確率 (Accuracy)。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>tool/tool.py</code></td>\n<td style=\"text-align: left;\"><strong>資料工具</strong></td>\n<td style=\"text-align: left;\">使用 <code>keras.datasets</code> 下載 IMDB 數據並轉換為 CSV 格式供模型訓練或測試使用。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CT_Dataset*.xlsx</code></td>\n<td style=\"text-align: left;\"><strong>資料源</strong></td>\n<td style=\"text-align: left;\">包含 <code>review</code> (評論內容) 與 <code>label</code> (情緒標籤) 的輸入資料。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>results.csv</code></td>\n<td style=\"text-align: left;\"><strong>輸出檔案</strong></td>\n<td style=\"text-align: left;\">程式執行後生成的結果，包含 <code>預測情緒</code>, <code>準確性</code>, <code>標籤</code>, <code>評論</code>。</td>\n</tr>\n</tbody>\n</table>\n<h2>安裝與環境需求（Installation &amp; Requirements）</h2>\n<h3>系統需求</h3>\n<ul>\n<li>Windows / Linux / macOS</li>\n<li>Python 3.8+</li>\n<li>可存取的 LLM API 服務 (如 LM Studio 架設的 Local Server)</li>\n</ul>\n<h3>相依套件</h3>\n<p>本專案依賴以下 Python 套件，請使用 pip 安裝：</p>\n<pre><code class=\"language-bash\">pip install pandas requests openpyxl\n</code></pre>\n<p><em>註：若使用 Version 1 的本地 Token 計算功能，需額外安裝 <code>llama-cpp-python</code>。</em></p>\n<h2>使用方式（How to Use）</h2>\n<h3>1. 準備環境</h3>\n<p>確認 LLM API 服務已啟動並可供連線（預設為 <code>http://210.240.194.41:1234/v1/chat/completions</code>）。</p>\n<h3>2. 執行分析</h3>\n<p>進入對應模型的資料夾（以 Version 2 Gemma 為例）並執行 Python 腳本：</p>\n<pre><code class=\"language-bash\">cd CT活動_文字情緒_全LSTM_2/gemma-2-27b-it\npython gemma-2-27b-it.py\n</code></pre>\n<h3>3. 查看結果</h3>\n<p>程式執行過程中會即時在 Terminal 顯示當前區塊的進度與準確率。執行完成後，結果保存在同目錄下的 <code>results.csv</code>。</p>\n<h2>設定說明（Configuration）</h2>\n<p>主要設定位於 Python 腳本 (<code>gemma-2-27b-it.py</code>) 的 <code>if __name__ == \"__main__\":</code> 區塊中，可直接修改程式碼進行調整：</p>\n<ul>\n<li><strong>API 設定</strong>：</li>\n<li><code>api_url</code>: LLM API 的完整 URL。</li>\n<li><code>model</code>: 呼叫 API 時指定的模型名稱 (如 <code>\"gemma-2-27b-it\"</code>)。</li>\n<li><strong>檔案路徑</strong>：</li>\n<li><code>input_file</code>: 輸入的 Excel 檔案路徑。</li>\n<li><code>output_file</code>: 輸出結果 CSV 檔名。</li>\n<li><strong>執行參數</strong>：</li>\n<li><code>chunk_size</code>: 每次批次處理的資料筆數（預設 10）。</li>\n<li><code>prompt</code>: 位於迴圈內的 Prompt 模板，可修改以調整 AI 指令。</li>\n</ul>\n<h2>開發者指南（Developer Guide）</h2>\n<ol>\n<li><strong>新增模型支援</strong>：複製現有的模型資料夾（如 <code>gemma-2-27b-it</code>），重新命名資料夾，並修改 <code>.py</code> 檔中的 <code>model</code> 變數即可。</li>\n<li><strong>修改 Prompt</strong>：在主迴圈中的 <code>prompt</code> 變數定義了給 AI 的指令。若需改變分析邏輯（如增加中立情緒），請修此處及 <code>analyze_sentiment</code> 中的解析邏輯。</li>\n<li><strong>錯誤處理</strong>：所有 API 錯誤或解析失敗會被記錄在 <code>prediction_failures.csv</code>，建議定期檢查此檔案以優化 Prompt 或系統穩定性。</li>\n</ol>\n<h2>已知限制與待辦事項（Limitations &amp; TODO）</h2>\n<ul>\n<li><strong>限制</strong>：</li>\n<li>目前僅支援二元分類（0/1），對於中立或複雜情緒無法精確表達。</li>\n<li>依賴外部 API 的穩定性，若 API 逾時或斷線會導致單筆資料失敗（但有記錄機制）。</li>\n<li>Token 計算邏輯在 Version 2 中被移除，若輸入文本過長可能會被截斷或導致 API 錯誤。</li>\n<li><strong>TODO</strong>：</li>\n<li>[ ] 將 API URL 與模型參數抽離至獨立的 <code>config.json</code> 設定檔，避免硬編碼。</li>\n<li>[ ] 實作多執行緒 (Multi-threading) 請求以提升處理速度。</li>\n<li>[ ] 統一 Version 1 與 Version 2 的程式邏輯。</li>\n</ul>\n<h2>補充說明（Notes）</h2>\n<ul>\n<li><strong>Version 1 vs Version 2</strong>：</li>\n<li>Version 1 包含 <code>llama_cpp</code> 本地 Token 計算，適合對 Context Window 控制較嚴格的場景。</li>\n<li>Version 2 架構較簡單，直接依賴 API 處理，且資料夾結構已針對多模型實驗進行優化。</li>\n<li><strong>工具腳本</strong>：<code>tool/tool.py</code> 是一個獨立的工具，用於從 Keras 下載 IMDB 數據集，與主情緒分析流程無直接依賴關係，但可用於準備測試數據。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "Sentiment-Analysis-System", "generated_at": "2026-02-28T16:29:52.987539+00:00", "head": "65179392b2315865d7547806bb3e5d9bf7dd5177"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "\"\\350\\263\\207\\346\\226\\231\\351\\233\\206", "children": [{"type": "file", "name": "CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM.xlsx\""}, {"type": "file", "name": "CT_Dataset2_translated.xlsx\""}, {"type": "file", "name": "imdb_reviews.csv\""}, {"type": "file", "name": "online_shopping_10_cats.csv\""}]}, {"type": "dir", "name": "\"CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM_1", "children": [{"type": "dir", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207", "children": [{"type": "file", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207.py\""}]}, {"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM.xlsx\""}, {"type": "file", "name": "gemma-2-27b-it.py\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "token_lengths.csv\""}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM.xlsx\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "llama3_70B.py\""}, {"type": "file", "name": "token_lengths.csv\""}]}, {"type": "dir", "name": "LSTM", "children": [{"type": "file", "name": "\\346\\203\\205\\347\\267\\222\\351\\240\\220\\346\\270\\254\\347\\265\\220\\346\\236\\234.xlsx\""}, {"type": "file", "name": "ct.py\""}, {"type": "file", "name": "CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM.xlsx\""}, {"type": "file", "name": "sentiment_analysis_lstm.h5\""}, {"type": "file", "name": "sentiment_analysis_lstm.keras\""}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM.xlsx\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "phi-4.py\""}, {"type": "file", "name": "token_lengths.csv\""}]}]}, {"type": "dir", "name": "\"CT\\346\\264\\273\\345\\213\\225_\\346\\226\\207\\345\\255\\227\\346\\203\\205\\347\\267\\222_\\345\\205\\250LSTM_2", "children": [{"type": "dir", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207", "children": [{"type": "file", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207.py\""}, {"type": "file", "name": "gemma-2-27b-it.csv\""}, {"type": "file", "name": "gemma-2-27b-it\\346\\267\\267\\346\\267\\206\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "llama3_70B.csv\""}, {"type": "file", "name": "llama3_70B\\346\\267\\267\\346\\267\\206\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "phi-4.csv\""}, {"type": "file", "name": "phi-4\\346\\267\\267\\346\\267\\206\\347\\237\\251\\351\\231\\243.png\""}]}, {"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "gemma-2-27b-it.py\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "prediction_failures.csv\""}, {"type": "file", "name": "results.csv\""}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "meta-llama-3-70b-instruct.py\""}, {"type": "file", "name": "prediction_failures.csv\""}, {"type": "file", "name": "results.csv\""}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc\""}]}, {"type": "file", "name": "count.py\""}, {"type": "file", "name": "image.png\""}, {"type": "file", "name": "phi-4.py\""}, {"type": "file", "name": "prediction_failures.csv\""}, {"type": "file", "name": "results.csv\""}]}, {"type": "file", "name": "CT_Dataset2.xlsx\""}, {"type": "file", "name": "CT_Dataset2_translated.xlsx\""}]}, {"type": "dir", "name": "\"imdb_reviews", "children": [{"type": "dir", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207", "children": [{"type": "file", "name": "\\346\\267\\267\\346\\267\\206\\347\\237\\251\\351\\231\\243.png\""}, {"type": "file", "name": "\\346\\272\\226\\347\\242\\272\\347\\216\\207.py\""}, {"type": "file", "name": "gemma-2-27b-it.csv\""}]}, {"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}]}, {"type": "dir", "name": "\"online_shopping_10_cats", "children": [{"type": "dir", "name": "deepseek_r1", "children": [{"type": "file", "name": "\\346\\257\\224\\345\\260\\215\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\351\\214\\257\\350\\252\\244.csv\""}]}, {"type": "dir", "name": "deepseekV3", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "granite-3.1-8b-instruct", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "llama3.1", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "llama3_chinese", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "file", "name": "\\350\\231\\225\\347\\220\\206\\347\\265\\220\\346\\236\\234.csv\""}, {"type": "file", "name": "\\351\\240\\220\\346\\270\\254\\345\\244\\261\\346\\225\\227\\350\\263\\207\\346\\226\\231.csv\""}]}]}, {"type": "dir", "name": "\"result", "children": [{"type": "file", "name": "\\346\\250\\241\\345\\236\\213\\346\\272\\226\\347\\242\\272\\347\\216\\207.docx\""}]}, {"type": "dir", "name": "imdb_reviews", "children": [{"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "gemma-2-27b-it.py"}, {"type": "file", "name": "imdb_reviews.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "imdb_reviews.csv"}, {"type": "file", "name": "llama3_70B.py"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "imdb_reviews.csv"}, {"type": "file", "name": "phi-4.py"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "result", "children": [{"type": "file", "name": "Deepseek_R1.csv"}, {"type": "file", "name": "gemma-2-27b-it.csv"}, {"type": "file", "name": "granite-3.1-8b-instruct.csv"}, {"type": "file", "name": "llama3.1.csv"}, {"type": "file", "name": "llama3_70B.csv"}, {"type": "file", "name": "llama3_chinese.csv"}, {"type": "file", "name": "phi-4.csv"}]}, {"type": "file", "name": "imdb_reviews.csv"}]}, {"type": "dir", "name": "online_shopping_10_cats", "children": [{"type": "dir", "name": "deepseek_r1", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "deepseek_r1.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "split.py"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "deepseekV3", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "api_key.json"}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "deepseekV3.py"}, {"type": "file", "name": "online_shopping_10_cats.csv"}]}, {"type": "dir", "name": "gemma-2-27b-it", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "gemma-2-27b-it.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "gpt", "children": [{"type": "file", "name": "count.py"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "test.py"}]}, {"type": "dir", "name": "granite-3.1-8b-instruct", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "granite-3.1-8b-instruct.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "llama3.1", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "llama3.py"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "llama3_70B", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "llama3_70B.py"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "llama3_chinese", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "llama3_chinese.py"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "token_lengths.csv"}]}, {"type": "dir", "name": "phi-4", "children": [{"type": "dir", "name": "__pycache__", "children": [{"type": "file", "name": "count.cpython-310.pyc"}]}, {"type": "file", "name": "count.py"}, {"type": "file", "name": "image.png"}, {"type": "file", "name": "online_shopping_10_cats.csv"}, {"type": "file", "name": "phi-4.py"}, {"type": "file", "name": "token_lengths.csv"}]}]}, {"type": "dir", "name": "result", "children": [{"type": "dir", "name": "online_shopping_10_cats", "children": [{"type": "file", "name": "Deepseek_R1.csv"}, {"type": "file", "name": "gemma-2-27b-it.csv"}, {"type": "file", "name": "granite-3.1-8b-instruct.csv"}, {"type": "file", "name": "llama3.1.csv"}, {"type": "file", "name": "llama3_70B.csv"}, {"type": "file", "name": "llama3_chinese.csv"}, {"type": "file", "name": "phi-4.csv"}]}]}, {"type": "dir", "name": "tool", "children": [{"type": "file", "name": "-1.py"}, {"type": "file", "name": "imdb_reviews.csv"}, {"type": "file", "name": "tool.py"}]}, {"type": "file", "name": "README.md"}]}}, "gkwang4912__VibeCodingLab": {"readme": "<h1>VibeCodingLab (Python 智能診斷平台)</h1>\n<h2>專案總覽 (Project Overview)</h2>\n<p>本專案是一個基於 Python Flask 的 Web 應用程式，旨在提供學生一個互動式的 Python 程式練習環境。系統結合了 OpenAI 的大型語言模型 (LLM)，能針對學生的程式碼提供即時的執行結果、錯誤分析、評分與優化建議。</p>\n<ul>\n<li><strong>解決的問題</strong>：提供初學者即時且具體的程式碼回饋，解決自學時缺乏指導的痛點。</li>\n<li><strong>使用對象</strong>：Python 程式語言初學者、程式設計課程學生。</li>\n<li><strong>專案性質</strong>：Web Application (前後端分離架構)。</li>\n</ul>\n<p>前端畫面演示：\n<img width=\"1951\" height=\"1097\" alt=\"image\" src=\"https://github.com/user-attachments/assets/74512cfd-da6d-4f0d-8ae5-c6f78ebfd1c6\" />\n深色模式：\n<img width=\"1947\" height=\"1099\" alt=\"image\" src=\"https://github.com/user-attachments/assets/deffe7d8-93d2-4ce1-a23a-fea5e8bfacf7\" /></p>\n<p>演示影片：</p>\n<p><a href=\"https://www.youtube.com/watch?v=K4EG9JZTvEc\"><img alt=\"演示影片\" src=\"https://img.youtube.com/vi/K4EG9JZTvEc/maxresdefault.jpg\" /></a></p>\n<h2>系統架構說明 (Architecture Overview)</h2>\n<p>本系統採用前後端分離設計。後端使用 Flask 框架處理 API 請求、程式碼安全性檢查與執行；前端使用純 HTML/CSS/JS 構建。外部依賴包括 OpenAI API (用於代碼分析) 與 Google Sheets (用於題目管理與成績記錄)。</p>\n<h3>系統架構圖</h3>\n<pre><code class=\"language-mermaid\">flowchart TD\n    User[&quot;使用者 (Browser)&quot;] &lt;--&gt;|HTTP/JSON| Frontend[&quot;前端介面 (HTML/JS)&quot;]\n    Frontend &lt;--&gt;|REST API| Backend[&quot;後端伺服器 (Flask)&quot;]\n\n    subgraph Backend_System [後端系統]\n        Backend --&gt;|1. 驗證與執行| Sandbox[&quot;安全執行沙箱 (Safe Exec)&quot;]\n        Backend --&gt;|2. 題目管理| QuestionLoader[&quot;題目讀取模組 (Fetch Questions)&quot;]\n        Backend --&gt;|3. 成績處理| ScoreManager[&quot;成績管理模組&quot;]\n    end\n\n    subgraph External_Services [外部服務]\n        Backend &lt;--&gt;|分析請求| OpenAI[&quot;OpenAI API&quot;]\n        QuestionLoader &lt;--&gt;|讀取 CSV| GSheets[&quot;Google Sheets (題目資料庫)&quot;]\n        ScoreManager --&gt;|寫入成績| GWebApp[&quot;Google Apps Script (成績記錄)&quot;]\n    end\n\n    ScoreManager --&gt;|備份| LocalFile[&quot;本地 JSON 檔案&quot;]\n</code></pre>\n<h2>系統流程說明 (System Flow)</h2>\n<p>主要流程包含：題目載入、程式碼執行、AI 分析與成績提交。</p>\n<h3>核心運作流程圖</h3>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant U as 使用者\n    participant F as 前端介面\n    participant S as Flask Server\n    participant AI as OpenAI API\n    participant DB as Google Sheets\n\n    Note over U, DB: 1. 題目載入流程\n    U-&gt;&gt;F: 開啟頁面\n    F-&gt;&gt;S: GET /api/questions\n    alt 快取有效\n        S--&gt;&gt;F: 回傳 tool/questions.json 快取\n    else 快取過期\n        S-&gt;&gt;DB: 讀取題目 CSV\n        DB--&gt;&gt;S: 回傳資料\n        S-&gt;&gt;S: 解析並更新快取\n        S--&gt;&gt;F: 回傳新題目列表\n    end\n\n    Note over U, DB: 2. 程式執行與分析流程\n    U-&gt;&gt;F: 撰寫程式碼並執行\n    F-&gt;&gt;S: POST /api/execute/interactive\n    S-&gt;&gt;S: 安全性檢查 (AST Parse)\n    alt 檢查通過\n        S-&gt;&gt;S: 在沙箱中執行程式\n        S--&gt;&gt;F: 回傳執行結果 (Output)\n\n        U-&gt;&gt;F: 請求 AI 分析\n        F-&gt;&gt;S: POST /api/ai/analyze\n        S-&gt;&gt;AI: 發送程式碼與結果\n        AI--&gt;&gt;S: 回傳評分與建議 (JSON)\n        S--&gt;&gt;F: 顯示分析結果\n    else 檢查失敗\n        S--&gt;&gt;F: 回傳安全性錯誤\n    end\n\n    Note over U, DB: 3. 成績提交流程\n    U-&gt;&gt;F: 提交成績\n    F-&gt;&gt;S: POST /api/scores/submit\n    par 雙重寫入\n        S-&gt;&gt;DB: 呼叫 Google Apps Script 寫入\n        S-&gt;&gt;S: 寫入 tool/scores_backup.json (本地備份)\n    end\n    S--&gt;&gt;F: 回傳提交狀態\n</code></pre>\n<h2>資料夾結構說明 (Folder Structure)</h2>\n<pre><code>VibeCodingLab/14/\n├── frontend/                  # 前端靜態資源\n│   ├── index.html             # 主頁面\n│   ├── styles.css             # 樣式表\n│   ├── app.js                 # 主要邏輯 (Vue/Vanilla JS)\n│   ├── api.js                 # API 封裝\n│   ├── config.js              # 前端設定\n│   └── lib/                   # 第三方函式庫\n├── tool/                      # 工具與資料模組\n│   ├── fetch_questions.py     # Google Sheets 題目抓取邏輯\n│   ├── prompts.json           # AI 提示詞模板設定\n│   ├── questions.json         # 題目資料快取\n│   └── scores_backup.json     # 成績本地備份\n├── server.py                  # 後端核心程式 (Flask App)\n├── config.json                # 後端設定檔 (API Keys 等)\n├── requirements.txt           # Python 套件依賴清單\n└── service-account.json       # Google 服務帳號憑證 (選用)\n</code></pre>\n<h2>核心模組與重要檔案 (Key Modules &amp; Files)</h2>\n<h3>1. <code>server.py</code> (後端核心)</h3>\n<ul>\n<li><strong>職責</strong>：啟動 Web Server，處理所有 API 路由。</li>\n<li><strong>關鍵功能</strong>：</li>\n<li><code>validate_code_safety(code)</code>: 使用 AST (抽象語法樹) 檢查程式碼，禁止危險函數 (如 <code>open</code>, <code>eval</code>, <code>os</code> 等)。</li>\n<li><code>execute_with_timeout</code>: 在獨立執行緒中執行學生程式碼，防止無窮迴圈 (預設 5 秒超時)。</li>\n<li><code>start_interactive_execution</code>: 處理互動式程式執行 (支援 <code>input()</code> 函數)。</li>\n<li><code>/api/ai/*</code>: 處理與 OpenAI 的串接，包含分析、檢查與建議。</li>\n</ul>\n<h3>2. <code>tool/fetch_questions.py</code> (題目載入器)</h3>\n<ul>\n<li><strong>職責</strong>：從 Google Sheets CSV 匯出連結讀取題目資料。</li>\n<li><strong>邏輯</strong>：</li>\n<li>解析 CSV 格式，處理用雙引號包夾的欄位。</li>\n<li>自動判斷題目難度與學習目標。</li>\n<li>將資料結構化並儲存為 JSON。</li>\n</ul>\n<h3>3. <code>frontend/app.js</code> (前端邏輯)</h3>\n<ul>\n<li><strong>職責</strong>：管理使用者介面互動。</li>\n<li><strong>功能</strong>：</li>\n<li>程式碼編輯器 (CodeMirror/Monaco) 初始化。</li>\n<li>調用後端 API 執行程式並顯示結果。</li>\n<li>渲染 Markdown 格式的 AI 回饋。</li>\n</ul>\n<h2>安裝與環境需求 (Installation &amp; Requirements)</h2>\n<h3>系統需求</h3>\n<ul>\n<li>Python 3.8 或以上版本</li>\n<li>網路連線 (需存取 Google Sheets 與 OpenAI API)</li>\n</ul>\n<h3>相依套件</h3>\n<p>請參考 <code>requirements.txt</code>：</p>\n<pre><code class=\"language-text\">flask\nflask-cors\nopenai\nrequests\ngspread\ngoogle-auth\n</code></pre>\n<h3>安裝步驟</h3>\n<ol>\n<li>建立虛擬環境 (建議)：\n   <code>bash\n   python -m venv venv\n   source venv/bin/activate  # Windows: venv\\Scripts\\activate</code></li>\n<li>安裝套件：\n   <code>bash\n   pip install -r requirements.txt</code></li>\n</ol>\n<h2>使用方式 (How to Use)</h2>\n<h3>1. 啟動伺服器</h3>\n<p>在專案根目錄執行：</p>\n<pre><code class=\"language-bash\">python server.py\n</code></pre>\n<p>成功啟動後，控制台會顯示：</p>\n<pre><code>[Vibe] Python 診斷平台 - OpenAI 版 (Model: gpt-4o-mini)\n * Running on http://0.0.0.0:5000/\n</code></pre>\n<h3>2. 操作介面</h3>\n<ul>\n<li>打開瀏覽器訪問 <code>http://localhost:5000</code> (或 <code>index.html</code> 直接打開，視前端配置而定)。</li>\n<li>選擇左側題目列表。</li>\n<li>在中央編輯器輸入 Python 程式碼。</li>\n<li>點擊「執行程式」查看輸出。</li>\n<li>點擊「AI 分析」獲取評分與建議。</li>\n</ul>\n<h2>設定說明 (Configuration)</h2>\n<h3>後端設定 (<code>config.json</code>)</h3>\n<p>此檔案需自行建立，格式如下：</p>\n<pre><code class=\"language-json\">{\n  &quot;openai_api_key&quot;: &quot;sk-proj-...&quot;,\n  &quot;model_name&quot;: &quot;gpt-4o-mini&quot;\n}\n</code></pre>\n<h3>提示詞設定 (<code>tool/prompts.json</code>)</h3>\n<p>定義 AI 分析時使用的 System Prompt 與 User Prompt 模板，可熱更新。</p>\n<ul>\n<li><code>analyze_prompt</code>: 用於 <code>/api/ai/analyze</code></li>\n<li><code>suggest_prompt</code>: 用於 <code>/api/ai/suggest</code></li>\n</ul>\n<h2>開發者指南 (Developer Guide)</h2>\n<h3>修改建議</h3>\n<ol>\n<li>\n<p><strong>安全性調整</strong>：</p>\n</li>\n<li>\n<p>若需開放更多 Python 模組，請修改 <code>server.py</code> 中的 <code>ALLOWED_MODULES</code> 集合。</p>\n</li>\n<li><strong>警告</strong>：請勿隨意移除 <code>validate_code_safety</code> 中的檢查，以免造成伺服器安全風險。</li>\n<li>\n<p><strong>題目來源</strong>：</p>\n</li>\n<li>\n<p>目前指向特定的 Google Sheet URL (在 <code>tool/fetch_questions.py</code> 中定義)。</p>\n</li>\n<li>若需更換題庫，請修改 <code>SHEET_URL</code> 常數。</li>\n</ol>\n<h3>擴充功能</h3>\n<ul>\n<li><strong>新增 API</strong>：在 <code>server.py</code> 中使用 <code>@app.route</code> 裝飾器新增路由。</li>\n<li><strong>前端調整</strong>：主要修改 <code>frontend/app.js</code> 與 <code>frontend/index.html</code>。</li>\n</ul>\n<h2>已知限制與待辦事項 (Limitations &amp; TODO)</h2>\n<ul>\n<li>\n<p><strong>安全性限制</strong>：</p>\n</li>\n<li>\n<p>目前僅支援標準函式庫的子集 (math, random, datetime 等)。</p>\n</li>\n<li>無法執行需要檔案系統讀寫的操作。</li>\n<li><code>input()</code> 互動功能在某些瀏覽器環境下可能會有延遲。</li>\n<li>\n<p><strong>TODO</strong>：</p>\n</li>\n<li>\n<p>[ ] 實作使用者登入系統。</p>\n</li>\n<li>[ ] 將成績儲存改為真正的資料庫 (如 SQLite/PostgreSQL)，而非依賴 Google Sheets。</li>\n<li>[ ] 增強沙箱隔離機制 (考慮使用 Docker 或更底層的隔離)。</li>\n</ul>\n<h2>補充說明 (Notes)</h2>\n<ul>\n<li><strong>成績備份機制</strong>：系統會優先嘗試寫入 Google Apps Script Web App。若失敗，會自動降級並寫入 <code>tool/scores_backup.json</code>，確保資料不丟失。</li>\n<li><strong>快取機制</strong>：題目資料預設快取 30 分鐘 (<code>server.py</code> 中的 <code>CACHE_EXPIRE_MINUTES</code>)，可透過 <code>/api/questions/refresh</code> 強制更新。</li>\n</ul>", "meta": {"owner": "gkwang4912", "repo": "VibeCodingLab", "generated_at": "2026-02-28T16:29:52.997146+00:00", "head": "3a2ab0d63a2e66bafc3a8d05401f93d0739a9194"}, "tree": {"type": "dir", "name": "", "children": [{"type": "dir", "name": "design", "children": [{"type": "file", "name": "pencil-new.pen"}]}, {"type": "dir", "name": "frontend", "children": [{"type": "dir", "name": "lib", "children": [{"type": "file", "name": "editor.js"}, {"type": "file", "name": "github.min.css"}, {"type": "file", "name": "highlight.min.js"}, {"type": "file", "name": "marked.min.js"}, {"type": "file", "name": "python.min.js"}, {"type": "file", "name": "split.min.js"}]}, {"type": "file", "name": "api.js"}, {"type": "file", "name": "app.js"}, {"type": "file", "name": "config.js"}, {"type": "file", "name": "index.html"}, {"type": "file", "name": "styles.css"}]}, {"type": "dir", "name": "tool", "children": [{"type": "file", "name": "fetch_questions.py"}, {"type": "file", "name": "prompts.json"}, {"type": "file", "name": "questions.json"}, {"type": "file", "name": "scores_backup.json"}]}, {"type": "file", "name": "config.json"}, {"type": "file", "name": "README.md"}, {"type": "file", "name": "requirements.txt"}, {"type": "file", "name": "scores_backup.json"}, {"type": "file", "name": "server.py"}]}}}};